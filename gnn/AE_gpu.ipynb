{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['store', 'double', 'TMP_VAR(INFUNCTION_VAR)', 'TMP_VAR', ';', 'load', 'TMP_VAR', 'double', 'TMP_VAR(INFUNCTION_VAR)', ';', 'assignment', 'TMP_POINTER_MEMBER', 'TMP_VAR', ';', 'assignment', 'TMP_VAR', 'TMP_POINTER_MEMBER', ';', 'math_op', 'TMP_VAR', 'TMP_NUMBER', '/', 'TMP_VAR', ';', 'function_call', 'INFUNCTION_VAR', 'TMP_FUNCTION_ARG_1', 'TMP_FUNCTION_ARG_2', ';', 'function_call', 'INFUNCTION_VAR', 'TMP_FUNCTION_ARG_1', 'TMP_FUNCTION_ARG_2', 'TMP_FUNCTION_ARG_3', 'TMP_FUNCTION_ARG_4', ';', 'math_op', 'TMP_VAR', 'TMP_VAR', '+', 'TMP_NUMBER', ';', 'assignment', 'INFUNCTION_VAR', 'TMP_VAR', ';', 'phi', ';']]\n"
     ]
    }
   ],
   "source": [
    "from model import AutoEncoder_gnnrnn, AutoEncoder_rnn\n",
    "from data import prepare_data_vocab, live_feat, batch_gnn_for_gpu, split_pp_into_sublists, split_train_test, count_occurrences\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "from torch.optim import lr_scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_to_idx, idx_to_word, data, data_emb = prepare_data_vocab(\"data\", func=live_feat, function_num=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GNN LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#return grad_input.min(), grad_input.min(), grad_input.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def register_hooks(model):\n",
    "    hooks = []\n",
    "    for layer in model.modules():\n",
    "        if isinstance(layer, nn.Linear):\n",
    "            hooks.append(layer.register_full_backward_hook(get_gradient))\n",
    "    return hooks\n",
    "\n",
    "def get_gradient(module, grad_input, grad_output):\n",
    "    #print('Gradient Input:', grad_input)  # Gradients with respect to inputs\n",
    "    #return grad_input\n",
    "    #print('Gradient Output:', grad_output)  # Gradients with respect to outputs\n",
    "    global total_gradients, total_parameters, dict_grad\n",
    "    for name, param in module.named_parameters():\n",
    "        if param.grad is not None:\n",
    "            grad = param.grad\n",
    "            dict_grad[name] = total_gradients\n",
    "            total_gradients += grad.abs().sum().item()\n",
    "            total_parameters += grad.numel()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "bidir          = True\n",
    "dir            = 2 if bidir else 1 \n",
    "batch_size     = 64\n",
    "num_layers_enc = 2\n",
    "hidden_dim_enc = 64\n",
    "num_layers_dec = 2\n",
    "hidden_dim_dec = 32\n",
    "emb_dim        = 64\n",
    "N_max          = len(word_to_idx)+1\n",
    "layer_dims_gnn = [32, 16]\n",
    "\n",
    "dataset = split_pp_into_sublists(data_emb, batch_size)\n",
    "(train, test) = split_train_test(dataset)\n",
    "\n",
    "ae = AutoEncoder_gnnrnn(batch_size     = batch_size,\n",
    "            bidir          = True,\n",
    "            num_layers_enc = num_layers_enc,\n",
    "            hidden_dim_enc = hidden_dim_enc,\n",
    "            num_layers_dec = num_layers_dec,\n",
    "            hidden_dim_dec = hidden_dim_dec,\n",
    "            layer_dims_gnn = layer_dims_gnn,\n",
    "            emb_dim        = emb_dim,\n",
    "            N_max          = N_max)\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")  # Or \"cuda:0\" for the first GPU\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "\n",
    "#device = torch.device(\"cpu\")\n",
    "ae.to(device)\n",
    "\n",
    "\n",
    "train_gpu = batch_gnn_for_gpu(train, device, len(word_to_idx))\n",
    "test_gpu = batch_gnn_for_gpu(test, device, len(word_to_idx))\n",
    "weight = count_occurrences(train, word_to_idx, device)\n",
    "\n",
    "\n",
    "criterion = nn.CrossEntropyLoss(ignore_index=len(word_to_idx), weight=weight)\n",
    "#data_emb_device = [(edge_index.to(device), [bb.to(device) for bb in node_embs ]) for (edge_index, node_embs) in data_emb] \n",
    "optimizer = optim.Adam(ae.parameters(), lr=0.01)\n",
    "\n",
    "hooks = register_hooks(ae)\n",
    "# Before the training loop\n",
    "total_gradients = 0.0\n",
    "total_parameters = 0\n",
    "\n",
    "#scheduler = lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.1) \n",
    "\n",
    "#optimizer = optim.SGD(ae.parameters(), lr=0.1, momentum=0.9)\n",
    "#scheduler = lr_scheduler.CyclicLR(optimizer, base_lr=0.01, max_lr=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0003645151784952697\n",
      "For 54116 Tokens List in Train set: Epoch 1/100, Average Loss: 2.20049, Acuuracy: 11.07483\n",
      "For 13607 Tokens List in Test set: Epoch 1/100, Average Loss: 2.59770, Acuuracy: 7.44449\n",
      "-----------------------------------------------------------------------------------\n",
      "0.0003063206550115309\n",
      "0.0002826351602610464 in Train set: Epoch 2/100, Average Loss: 1.29945, Acuuracy: 27.26814\n",
      "0.00026632757143269165in Train set: Epoch 3/100, Average Loss: 1.10295, Acuuracy: 33.18889\n",
      "0.00025184079546105355in Train set: Epoch 4/100, Average Loss: 1.04587, Acuuracy: 35.13862\n",
      "0.0002409991146532671 in Train set: Epoch 5/100, Average Loss: 0.89751, Acuuracy: 40.75826\n",
      "For 54116 Tokens List in Train set: Epoch 6/100, Average Loss: 0.84801, Acuuracy: 42.82681\n",
      "For 13607 Tokens List in Test set: Epoch 6/100, Average Loss: 2.25915, Acuuracy: 10.44395\n",
      "-----------------------------------------------------------------------------------\n",
      "0.00023283904478343763\n",
      "0.00022459329157708144in Train set: Epoch 7/100, Average Loss: 0.82479, Acuuracy: 43.83278\n",
      "0.00021598808625044352in Train set: Epoch 8/100, Average Loss: 0.77501, Acuuracy: 46.07008\n",
      "0.00020939182467152455in Train set: Epoch 9/100, Average Loss: 0.73832, Acuuracy: 47.79168\n",
      "0.00020375417955901973in Train set: Epoch 10/100, Average Loss: 0.69418, Acuuracy: 49.94830\n",
      "For 54116 Tokens List in Train set: Epoch 11/100, Average Loss: 0.69842, Acuuracy: 49.73706\n",
      "For 13607 Tokens List in Test set: Epoch 11/100, Average Loss: 1.95353, Acuuracy: 14.17730\n",
      "-----------------------------------------------------------------------------------\n",
      "0.0001977291411443062\n",
      "0.00019243019667540914in Train set: Epoch 12/100, Average Loss: 0.62968, Acuuracy: 53.27611\n",
      "0.00018871343827583893in Train set: Epoch 13/100, Average Loss: 0.62294, Acuuracy: 53.63635\n",
      "0.00018579806082793157in Train set: Epoch 14/100, Average Loss: 0.63680, Acuuracy: 52.89798\n",
      "0.00018173250388040657in Train set: Epoch 15/100, Average Loss: 0.62481, Acuuracy: 53.53612\n",
      "For 54116 Tokens List in Train set: Epoch 16/100, Average Loss: 0.57409, Acuuracy: 56.32159\n",
      "For 13607 Tokens List in Test set: Epoch 16/100, Average Loss: 1.98558, Acuuracy: 13.73012\n",
      "-----------------------------------------------------------------------------------\n",
      "0.0001787045189109729\n",
      "0.0001759012690373763 in Train set: Epoch 17/100, Average Loss: 0.58729, Acuuracy: 55.58296\n",
      "0.0001729076778952794 in Train set: Epoch 18/100, Average Loss: 0.58366, Acuuracy: 55.78529\n",
      "0.00017005990639456175in Train set: Epoch 19/100, Average Loss: 0.55570, Acuuracy: 57.36698\n",
      "0.00016706112382011324in Train set: Epoch 20/100, Average Loss: 0.54635, Acuuracy: 57.90602\n",
      "For 54116 Tokens List in Train set: Epoch 21/100, Average Loss: 0.53969, Acuuracy: 58.29283\n",
      "For 13607 Tokens List in Test set: Epoch 21/100, Average Loss: 1.91950, Acuuracy: 14.66800\n",
      "-----------------------------------------------------------------------------------\n",
      "0.00016375087078407508\n",
      "0.00016069492416436262in Train set: Epoch 22/100, Average Loss: 0.50227, Acuuracy: 60.51526\n",
      "0.00015925356681606578in Train set: Epoch 23/100, Average Loss: 0.48504, Acuuracy: 61.56743\n",
      "0.00015700648895129618in Train set: Epoch 24/100, Average Loss: 0.55474, Acuuracy: 57.42198\n",
      "For 54116 Tokens List in Train set: Epoch 25/100, Average Loss: 0.52647, Acuuracy: 59.06857\r"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [42], line 23\u001b[0m\n\u001b[1;32m     21\u001b[0m j \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39msum(lengths)\n\u001b[1;32m     22\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m---> 23\u001b[0m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     24\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m     25\u001b[0m \u001b[38;5;66;03m#scheduler.step()\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/_tensor.py:522\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    512\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    513\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    514\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    515\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    520\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    521\u001b[0m     )\n\u001b[0;32m--> 522\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    523\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    524\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/autograd/__init__.py:266\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    261\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    263\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[1;32m    264\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    265\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 266\u001b[0m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    267\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    268\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    269\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    270\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    271\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    272\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    273\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    274\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "epoch_num = 100\n",
    "loss_train = []\n",
    "accu_train = []\n",
    "loss_test = []\n",
    "accu_test = []\n",
    "grad_avg = []\n",
    "for epoch in range(epoch_num):\n",
    "    total_loss = 0\n",
    "    j = 0\n",
    "    cntBatch = 0\n",
    "    for (padded_seq, padded_seq_dec, lengths, edge_index) in train_gpu:\n",
    "        cntBatch += 1\n",
    "        #print(\"seq ->\", padded_seq.shape)\n",
    "        #print(\"lengths -> \", min(lengths), \":\", max(lengths))\n",
    "        out = ae(padded_seq, padded_seq_dec, lengths, edge_index, mode=\"mix\", ratio=0.5, ratio_mix=0.5)\n",
    "        #print(out[:,-1,:])\n",
    "        loss = criterion(out.flatten(0).reshape(-1,N_max), padded_seq.flatten())\n",
    "        #print(out.flatten(0).reshape(-1,N_max).argmax(dim=1).to(\"cpu\").tolist())\n",
    "        #print(padded_seq.flatten().to(\"cpu\").tolist())\n",
    "        #print(\"-------------------------------------------------\")\n",
    "        total_loss  += loss.item()\n",
    "        j += np.sum(lengths)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        #scheduler.step()\n",
    "    for hook in hooks:\n",
    "        hook.remove()  # Remove previous hooks\n",
    "    hooks = register_hooks(ae)\n",
    "    grad_avg.append(total_gradients/total_parameters)\n",
    "    #print(hooks[0])\n",
    "    # Optionally, you can print the learning rate to monitor its changes\n",
    "        #print(\"Learning Rate:\", optimizer.param_groups[0]['lr'])\n",
    "    if epoch%5==0 or (epoch+1)==epoch_num:\n",
    "        print(f'For {j} Tokens List in Train set: Epoch {epoch+1}/{epoch_num}, Average Loss: {total_loss/cntBatch:.5f}, Acuuracy: {np.exp(-total_loss/cntBatch)*100:.5f}', end='\\n')\n",
    "        cntBatch_test = 0\n",
    "        total_loss_test = 0\n",
    "        j_test = 0\n",
    "        for (padded_seq, padded_seq_dec, lengths, edge_index) in test_gpu:\n",
    "            j_test += np.sum(lengths)\n",
    "            cntBatch_test += 1\n",
    "            out = ae(padded_seq, padded_seq_dec, lengths, edge_index, mode=\"recursive\", ratio=1)\n",
    "            loss = criterion(out.flatten(0).reshape(-1,N_max), padded_seq.flatten())\n",
    "            total_loss_test  += loss.item()\n",
    "        loss_test.append(total_loss_test/cntBatch_test)\n",
    "        accu_test.append(np.exp(-total_loss_test/cntBatch_test)*100)\n",
    "        print(f'For {j_test} Tokens List in Test set: Epoch {epoch+1}/{epoch_num}, Average Loss: {total_loss_test/cntBatch_test:.5f}, Acuuracy: {np.exp(-total_loss_test/cntBatch_test)*100:.5f}', end='\\n')\n",
    "        print(\"-----------------------------------------------------------------------------------\")\n",
    "    else:\n",
    "        print(f'For {j} Tokens List in Train set: Epoch {epoch+1}/{epoch_num}, Average Loss: {total_loss/cntBatch:.5f}, Acuuracy: {np.exp(-total_loss/cntBatch)*100:.5f}', end='\\r')\n",
    "    loss_train.append(total_loss/cntBatch)\n",
    "    accu_train.append(np.exp(-total_loss/cntBatch)*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for hook in hooks:\n",
    "    hook.remove()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "enc.weight_ih_l0\n",
      "Parameter containing:\n",
      "tensor([[-0.7218,  0.3673,  0.3925,  ..., -0.1274, -0.1911, -0.0575],\n",
      "        [-0.5486, -0.2140,  0.3919,  ..., -0.0996, -0.2331,  0.3569],\n",
      "        [ 0.2631,  0.4226,  0.2895,  ..., -0.8137,  0.4365, -0.6244],\n",
      "        ...,\n",
      "        [ 0.7515,  0.2327, -0.2643,  ..., -0.1543, -0.0575, -0.4267],\n",
      "        [ 0.1540, -0.1479, -0.2918,  ...,  0.0502, -0.7872,  0.3232],\n",
      "        [ 0.7401,  0.2447, -1.1955,  ...,  0.0285,  0.2472, -1.1198]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "-------------------------------\n",
      "enc.weight_hh_l0\n",
      "Parameter containing:\n",
      "tensor([[-0.1510, -0.7207, -0.2121,  ..., -0.4485, -0.2166,  0.1380],\n",
      "        [ 0.1814,  0.1122, -0.0619,  ...,  0.6065,  0.9286, -0.9765],\n",
      "        [ 0.0046, -0.2300, -0.2010,  ..., -0.1728,  0.0884, -0.3822],\n",
      "        ...,\n",
      "        [-0.5066,  0.6278,  0.0760,  ...,  0.3865,  0.5576,  0.1224],\n",
      "        [ 0.0628,  0.2472,  0.3245,  ..., -0.3430,  0.3996,  0.4059],\n",
      "        [-0.1887,  0.2664,  0.1258,  ..., -0.2920, -0.0320, -0.6751]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "-------------------------------\n",
      "enc.bias_ih_l0\n",
      "Parameter containing:\n",
      "tensor([-4.8389e-01,  8.2881e-02, -3.8207e-01,  4.4332e-01, -3.2483e-01,\n",
      "        -7.8185e-02, -3.0806e-01, -4.6396e-01, -2.1718e-01,  4.1093e-01,\n",
      "         1.3333e-01,  2.4285e-01,  2.8502e-01, -2.2726e-01,  7.2728e-02,\n",
      "        -4.9105e-01,  7.2341e-02, -3.4462e-01, -3.3767e-01,  2.1206e-01,\n",
      "         3.2130e-01,  2.1061e-01, -3.2669e-01,  9.0678e-01,  7.3729e-02,\n",
      "         4.6676e-01,  9.9978e-02,  5.5648e-01, -9.5831e-02, -4.9597e-01,\n",
      "         2.8017e-01,  1.1521e-01, -2.5551e-01,  4.7266e-01, -1.3377e-02,\n",
      "        -3.7578e-01,  2.1428e-01,  2.3068e-01, -2.0636e-01,  1.5082e-01,\n",
      "         1.4460e-01,  4.2657e-01,  5.1029e-01,  5.7829e-02, -8.7195e-02,\n",
      "        -2.4873e-01, -5.9561e-03,  5.8422e-02,  3.5471e-01,  7.4801e-01,\n",
      "        -3.9762e-01,  1.9162e-01, -4.5150e-01, -4.2109e-01,  1.6971e-01,\n",
      "         3.5557e-01, -2.0040e-01, -1.4702e-01, -2.8032e-01, -3.3446e-01,\n",
      "        -1.4945e-01,  2.3025e-01,  2.5059e-01,  3.9980e-01, -3.5897e-01,\n",
      "        -4.6796e-01, -3.7261e-03, -2.8677e-01, -1.5846e-01, -1.6563e-01,\n",
      "         2.0030e-01, -1.0343e-01, -1.4091e-01, -1.5194e-02,  2.8979e-02,\n",
      "         1.5852e-01,  9.4336e-02, -3.9171e-01, -2.5012e-01,  9.5326e-04,\n",
      "        -1.4471e-01,  4.4263e-02, -6.5740e-01,  2.4684e-01,  3.2474e-02,\n",
      "        -3.0107e-02,  6.5244e-01,  7.2835e-01, -1.6442e-01, -1.4596e-01,\n",
      "        -3.7385e-01,  3.6701e-01, -2.9348e-01, -1.5597e-01,  1.3644e-01,\n",
      "         9.8253e-01,  9.3718e-01,  8.2383e-01,  4.8072e-01,  3.5727e-02,\n",
      "        -2.7325e-01,  9.6628e-01, -2.8828e-01,  2.6735e-01, -2.7662e-01,\n",
      "        -2.8214e-02, -4.2594e-02, -2.0874e-01,  3.7875e-01, -1.8358e-01,\n",
      "         2.5115e-01,  1.1283e+00,  4.2771e-01,  5.3281e-03,  6.1675e-02,\n",
      "        -1.2410e-01,  3.1333e-01, -4.2607e-01, -1.4248e-02,  4.2064e-01,\n",
      "        -6.3183e-02,  6.4006e-01, -2.8191e-01, -1.7717e-01,  2.2225e-01,\n",
      "         2.9688e-01,  1.1485e+00,  4.5597e-01, -9.8475e-02,  4.1020e-01,\n",
      "         5.2616e-02, -3.7696e-02, -9.5235e-02, -1.6612e-01,  1.5378e-01,\n",
      "        -1.5273e-01, -1.6774e-01, -9.7627e-02,  5.1073e-01, -1.2690e-01,\n",
      "         8.2958e-02,  1.8709e-01, -1.8997e-01,  5.1317e-02,  1.5406e-01,\n",
      "        -1.6057e-01, -9.8162e-02,  4.6003e-01, -5.3467e-02,  5.4592e-01,\n",
      "        -4.4459e-01, -8.5868e-02,  2.7993e-01,  1.7772e-01, -1.7690e-01,\n",
      "        -3.6931e-01,  2.4912e-04,  4.2981e-02, -7.9061e-03,  3.6878e-01,\n",
      "        -3.2700e-01, -4.7736e-01, -3.6664e-01, -7.3004e-02, -3.3916e-01,\n",
      "        -2.3897e-02,  5.2029e-02, -2.6987e-01, -1.5510e-02, -7.4365e-02,\n",
      "         4.0611e-01, -2.6338e-01, -3.7567e-01,  1.6286e-02,  4.2988e-02,\n",
      "        -5.4443e-01,  2.2851e-01, -2.4328e-02, -3.2397e-02, -9.5638e-02,\n",
      "        -3.7676e-01,  1.1522e-01, -7.5797e-02,  3.5133e-01, -1.3450e-01,\n",
      "         9.7633e-02, -1.7760e-01,  5.8909e-02,  2.6302e-01,  9.5501e-02,\n",
      "         1.5423e-01, -1.2758e-01,  4.1119e-02, -1.8289e-02,  8.3405e-02,\n",
      "        -3.8759e-01, -3.8623e-01, -4.8196e-01, -2.5113e-01, -3.5282e-01,\n",
      "        -1.9604e-01, -2.8947e-02,  4.7903e-01,  1.4094e-01, -3.3746e-01,\n",
      "        -1.1885e-01,  1.4919e-01, -2.0547e-01,  3.3034e-01, -2.6169e-01,\n",
      "         2.4764e-01,  8.1492e-03, -1.1170e-01,  3.8946e-01, -1.0129e-01,\n",
      "        -4.9132e-02, -2.9026e-01, -4.5054e-01,  8.2290e-02,  1.7325e-01,\n",
      "         7.3676e-02,  2.2151e-01,  1.1270e-01, -2.3134e-01,  6.9990e-01,\n",
      "         3.5635e-01, -1.0059e-01, -2.8188e-01,  1.6655e-01, -3.0925e-01,\n",
      "         3.0757e-01,  1.0454e+00, -1.5048e-01,  3.5342e-01,  4.5527e-01,\n",
      "         4.7768e-01,  1.2429e-01,  1.9292e-01,  4.5212e-01,  3.2898e-01,\n",
      "        -1.7951e-01,  3.9927e-01,  2.2286e-01,  2.7036e-01, -2.5575e-01,\n",
      "        -1.9413e-01,  1.5772e-01,  3.8251e-01,  1.1231e-01,  1.7260e-01,\n",
      "         6.2736e-03,  1.9722e-01,  3.5260e-01,  7.5168e-01,  2.6116e-01,\n",
      "         4.4442e-01], device='cuda:0', requires_grad=True)\n",
      "-------------------------------\n",
      "enc.bias_hh_l0\n",
      "Parameter containing:\n",
      "tensor([-4.8662e-01,  2.0459e-01, -2.5097e-01,  3.2731e-01, -2.5736e-01,\n",
      "         6.6678e-02, -4.0301e-01, -2.9516e-01, -1.1191e-01,  4.1244e-01,\n",
      "         2.8762e-01,  2.0517e-01,  3.8445e-01, -4.5355e-01,  4.7294e-02,\n",
      "        -5.2102e-01,  5.3049e-02, -2.2364e-01, -3.2852e-01,  1.3385e-01,\n",
      "         3.1532e-01,  2.8749e-01, -3.4096e-01,  8.1011e-01,  4.9028e-02,\n",
      "         4.4047e-01,  2.9997e-01,  4.5347e-01, -6.1297e-02, -5.4571e-01,\n",
      "         2.8632e-01,  6.4386e-02, -4.0102e-01,  6.0494e-01,  1.2916e-01,\n",
      "        -3.5905e-01,  2.3348e-01,  3.5049e-01, -1.1058e-01,  1.7277e-01,\n",
      "         1.4726e-01,  4.3194e-01,  6.5240e-01,  3.3265e-02,  9.3383e-03,\n",
      "        -3.2331e-01,  1.2666e-01, -1.5338e-01,  4.6113e-01,  6.4082e-01,\n",
      "        -5.1219e-01,  1.1281e-01, -6.6504e-01, -3.2370e-01,  9.0184e-02,\n",
      "         2.4670e-01, -3.4231e-03, -6.6455e-02, -1.6968e-01, -5.4684e-01,\n",
      "        -1.2757e-01,  2.2817e-01,  2.7844e-01,  4.4895e-01, -2.1825e-01,\n",
      "        -3.5332e-01,  9.2474e-02, -3.4038e-01, -3.7052e-02, -3.6473e-01,\n",
      "         3.0050e-01, -1.3753e-01, -2.6564e-01,  1.8846e-01, -9.6562e-02,\n",
      "         2.5794e-01,  4.2722e-02, -3.3873e-01, -4.7352e-02,  5.7421e-02,\n",
      "         3.3477e-02, -1.3832e-01, -6.4176e-01,  2.7403e-01,  2.3809e-01,\n",
      "        -4.2562e-02,  6.7592e-01,  6.7120e-01, -5.1817e-03, -3.9242e-02,\n",
      "        -2.7914e-01,  2.7211e-01, -2.9670e-01,  4.2452e-02,  7.0573e-02,\n",
      "         1.1082e+00,  9.3975e-01,  9.7231e-01,  5.9728e-01,  1.7891e-01,\n",
      "        -8.8182e-02,  8.0547e-01, -1.0819e-01,  2.8013e-01, -3.8173e-01,\n",
      "        -3.0889e-02, -4.7959e-02, -3.9898e-01,  3.7593e-01, -1.2160e-01,\n",
      "         4.5565e-01,  1.0357e+00,  3.4882e-01,  1.4811e-01,  2.6077e-01,\n",
      "        -2.7666e-01,  2.6835e-01, -6.0059e-01,  9.1212e-02,  2.7834e-01,\n",
      "        -5.5073e-02,  7.7214e-01, -2.2136e-01, -6.4629e-02,  2.6879e-01,\n",
      "         2.6395e-01,  1.0138e+00,  5.7248e-01,  9.6058e-02,  4.2078e-01,\n",
      "        -7.0947e-02, -1.3208e-01, -1.3922e-01, -3.1506e-01,  6.4626e-02,\n",
      "         4.2373e-02, -2.8102e-01,  9.3240e-02,  4.7599e-01, -3.2742e-01,\n",
      "         1.6177e-02,  2.3824e-01, -3.7347e-02, -1.9548e-02,  1.5293e-01,\n",
      "        -2.2597e-01, -1.2993e-01,  3.7136e-01, -1.6061e-01,  7.0894e-01,\n",
      "        -3.6901e-01, -4.8040e-02,  1.8505e-01,  3.0882e-01, -1.2110e-01,\n",
      "        -3.5571e-01, -7.6374e-04, -1.2364e-01,  2.7037e-02,  2.5890e-01,\n",
      "        -5.2708e-01, -3.3500e-01, -2.5915e-01, -6.8721e-02, -3.1553e-01,\n",
      "        -1.2929e-01, -1.4205e-02, -1.5709e-01,  1.2493e-01, -1.0976e-01,\n",
      "         3.6743e-01, -1.1351e-01, -3.1263e-01,  2.3748e-01, -1.0333e-02,\n",
      "        -4.8246e-01,  3.3747e-01,  6.5066e-02, -4.4440e-03, -2.1658e-01,\n",
      "        -4.6968e-01,  2.6185e-02, -2.7576e-01,  3.1143e-01, -1.9727e-01,\n",
      "         1.0847e-01, -2.1117e-01, -5.0268e-02,  4.6855e-01, -1.9302e-02,\n",
      "         4.9556e-02, -8.0582e-02,  5.6540e-02, -3.1057e-02,  1.2980e-01,\n",
      "        -3.9673e-01, -2.0452e-01, -4.5854e-01, -2.4135e-01, -4.0057e-01,\n",
      "        -1.6760e-01,  1.7769e-02,  3.7670e-01,  2.1060e-01, -4.4364e-01,\n",
      "        -1.7641e-01,  1.7623e-01, -2.6960e-01,  3.2410e-01, -3.7553e-01,\n",
      "         4.0064e-01, -9.8893e-03,  4.7117e-02,  4.0115e-01,  6.1178e-02,\n",
      "         4.0816e-02, -4.5527e-01, -3.6363e-01, -1.2893e-01,  1.4147e-01,\n",
      "         1.9640e-01,  1.7269e-01,  3.2674e-02, -2.1208e-01,  6.2094e-01,\n",
      "         2.6212e-01, -2.5325e-01, -3.2530e-01,  5.8912e-02, -3.6657e-01,\n",
      "         2.5308e-01,  8.5596e-01, -1.0066e-01,  3.2240e-01,  5.2845e-01,\n",
      "         4.0047e-01,  7.1074e-02,  2.7200e-01,  4.8960e-01,  4.8925e-01,\n",
      "        -6.5871e-02,  2.9822e-01,  1.7707e-01,  1.7002e-01, -2.7816e-01,\n",
      "        -1.4127e-01,  2.6975e-01,  3.7191e-01,  1.0020e-01,  2.4705e-01,\n",
      "        -2.0246e-02,  3.1328e-01,  3.2252e-01,  9.6365e-01,  2.2181e-01,\n",
      "         3.7186e-01], device='cuda:0', requires_grad=True)\n",
      "-------------------------------\n",
      "enc.weight_ih_l0_reverse\n",
      "Parameter containing:\n",
      "tensor([[ 1.1068,  0.1766, -0.1076,  ..., -0.6331, -0.2345, -0.7149],\n",
      "        [ 0.1212, -0.4137, -0.1050,  ...,  0.1651, -0.4451,  0.2012],\n",
      "        [ 0.3408,  0.4866, -0.1299,  ..., -0.5818,  0.0336, -0.4585],\n",
      "        ...,\n",
      "        [ 0.4521,  0.4930,  0.2402,  ..., -0.1881, -0.0895, -0.4134],\n",
      "        [ 0.8622,  1.0386, -0.3759,  ...,  0.3634,  0.5337, -0.0194],\n",
      "        [ 0.7303, -0.3328,  0.0810,  ...,  0.2822,  0.3209,  0.5134]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "-------------------------------\n",
      "enc.weight_hh_l0_reverse\n",
      "Parameter containing:\n",
      "tensor([[ 0.7510, -0.9309, -0.7007,  ...,  0.5327,  0.0280, -0.1641],\n",
      "        [-0.3208,  0.4064,  0.2406,  ...,  0.8423,  0.1088, -0.5685],\n",
      "        [-0.6550, -0.1253, -0.2821,  ...,  0.2845, -0.0340, -0.0500],\n",
      "        ...,\n",
      "        [-0.0094, -0.4058,  0.3821,  ...,  0.0860,  0.3251,  0.1126],\n",
      "        [-0.2793, -0.2957,  0.4148,  ...,  0.1091, -0.3475, -0.0724],\n",
      "        [-0.7223,  0.4595,  0.6268,  ..., -0.1721,  0.6415, -0.2123]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "-------------------------------\n",
      "enc.bias_ih_l0_reverse\n",
      "Parameter containing:\n",
      "tensor([ 5.5849e-01,  7.0605e-01, -1.5425e-01,  2.2385e-01,  7.3351e-04,\n",
      "         3.9095e-01,  7.5587e-01,  3.6574e-01,  1.6737e-01,  1.1513e-01,\n",
      "         1.4496e-01,  5.3686e-01,  1.1202e-01,  3.5934e-01, -1.2450e-01,\n",
      "         2.6200e-01,  4.5783e-01, -2.3512e-01, -4.1535e-01,  2.9772e-01,\n",
      "        -1.9530e-01,  5.0131e-01,  6.4693e-01,  3.0118e-01,  9.0276e-01,\n",
      "         1.9523e-01, -6.1548e-02,  3.6175e-01,  2.8301e-01, -2.9246e-01,\n",
      "        -4.5672e-02,  1.9062e-01,  4.4095e-01,  4.6001e-01, -1.9553e-01,\n",
      "         5.9999e-01,  6.2549e-01,  1.3591e-01, -2.4235e-02,  1.2567e-01,\n",
      "        -3.2706e-01,  1.5715e-01,  4.3034e-01,  6.6464e-02,  4.0290e-01,\n",
      "        -3.6872e-01,  2.2364e-01,  4.5248e-01,  5.7970e-01,  4.4921e-01,\n",
      "         4.5585e-01, -1.6705e-01,  3.3646e-01,  3.5713e-01,  9.0438e-01,\n",
      "         5.1417e-02,  8.0618e-02, -1.9298e-01,  2.8683e-01,  4.7236e-01,\n",
      "         1.8532e-01, -4.0140e-01, -3.9121e-01,  8.5642e-01,  8.2294e-02,\n",
      "        -1.2558e-01,  1.3652e-01,  6.0551e-01, -1.3309e-01,  3.3287e-01,\n",
      "         4.7663e-01, -1.2338e-01,  6.9560e-01,  7.2484e-01,  1.9682e-01,\n",
      "         9.4523e-02,  1.7633e-01,  3.8358e-01,  2.0715e-02,  2.5763e-01,\n",
      "         3.4558e-01, -2.4704e-01, -2.3799e-01,  3.4802e-01,  4.6406e-01,\n",
      "         1.4773e-01,  6.0307e-01,  6.9092e-01,  4.9228e-01, -2.8109e-01,\n",
      "        -2.7829e-01, -8.8304e-02,  2.7030e-01, -9.1636e-02,  7.8610e-02,\n",
      "        -4.0285e-02,  4.3192e-02,  2.7393e-01,  8.0403e-01, -1.3621e-01,\n",
      "        -1.7580e-01,  8.1562e-01,  4.3578e-01, -4.2074e-02, -2.6319e-01,\n",
      "        -2.3546e-02,  5.1199e-01,  2.9724e-01,  3.7737e-01,  4.7537e-02,\n",
      "        -1.0631e-01,  2.2563e-01,  1.5869e-01, -2.0125e-01,  8.0684e-02,\n",
      "         1.4096e-01, -4.0034e-02, -4.4021e-01, -1.3114e-01,  4.4194e-01,\n",
      "        -5.5628e-01,  5.0091e-01,  3.6038e-01,  2.1152e-01,  5.8566e-02,\n",
      "        -2.3994e-01,  1.0689e-01,  5.2345e-01,  5.2123e-01, -5.1956e-01,\n",
      "        -5.0334e-01,  9.8245e-03,  2.7334e-01,  2.1125e-01,  6.5165e-02,\n",
      "        -1.1655e-01,  7.8797e-02, -4.2543e-01, -5.8664e-01, -1.8785e-01,\n",
      "         1.5987e-01,  8.9930e-02,  1.6020e-01, -9.6463e-02,  5.7174e-02,\n",
      "        -9.9705e-02,  5.0236e-02,  4.2702e-02, -2.0278e-01,  1.0285e-01,\n",
      "        -7.1459e-02,  2.1268e-01, -4.1295e-02, -1.1338e-01,  3.0051e-01,\n",
      "         8.4603e-02,  7.4294e-02, -4.6779e-01, -2.7201e-01, -1.1412e-01,\n",
      "        -4.2062e-01,  4.8268e-02, -6.2315e-01,  2.2258e-01, -2.0742e-01,\n",
      "         2.9244e-01, -7.5739e-02,  4.1355e-02, -4.1110e-01,  2.7543e-01,\n",
      "         1.6514e-01, -2.7142e-01, -1.9488e-01, -1.0898e-01, -2.7223e-01,\n",
      "         5.1418e-03, -2.5102e-01, -1.1541e-01, -2.3867e-01, -2.6596e-01,\n",
      "        -2.5309e-01,  6.0726e-02,  8.9820e-02, -6.3785e-02,  5.6697e-01,\n",
      "         3.0573e-02, -6.9470e-02, -2.5402e-01,  5.7213e-01,  1.4770e-01,\n",
      "         2.5231e-01, -5.6113e-01,  3.5464e-01,  9.8610e-02, -6.7559e-02,\n",
      "        -8.4097e-02,  4.1712e-01, -2.9881e-01,  3.9012e-01, -2.8435e-01,\n",
      "         8.8699e-02, -8.4075e-02,  1.6253e-01,  8.2054e-01,  8.8999e-02,\n",
      "        -3.8187e-01, -9.6419e-01,  9.6108e-02,  5.7641e-01,  2.0112e-01,\n",
      "        -5.8012e-02,  2.7432e-01,  3.9255e-01, -1.4881e-01, -7.6776e-02,\n",
      "         6.2931e-01, -1.8210e-01,  3.2196e-01,  1.2330e-01, -2.5100e-01,\n",
      "         3.7777e-01, -3.4192e-01, -3.0736e-01, -6.1304e-02,  3.3996e-01,\n",
      "         5.0032e-01,  2.0830e-01,  1.2998e-01,  7.8657e-01, -3.4538e-02,\n",
      "        -3.8607e-01,  6.9502e-02, -8.5422e-02, -1.7993e-01, -1.2323e-01,\n",
      "         4.8825e-01,  4.3087e-01, -2.2568e-01, -1.8771e-01, -1.2143e-01,\n",
      "         2.1968e-01, -2.7769e-02,  6.5450e-01, -2.8179e-01, -7.1070e-02,\n",
      "        -3.4165e-01,  1.6568e-01,  4.6748e-01, -1.4864e-01,  2.8350e-02,\n",
      "        -4.7381e-02, -1.7590e-01,  3.2355e-01, -1.8141e-01,  3.2487e-01,\n",
      "         2.0150e-01], device='cuda:0', requires_grad=True)\n",
      "-------------------------------\n",
      "enc.bias_hh_l0_reverse\n",
      "Parameter containing:\n",
      "tensor([ 6.9200e-01,  5.6002e-01, -9.2024e-02,  2.5244e-01,  1.2192e-01,\n",
      "         1.6211e-01,  5.9231e-01,  3.9266e-01,  1.6631e-01,  1.2665e-01,\n",
      "         1.5396e-01,  6.4749e-01,  1.1268e-01,  3.3726e-01,  5.6777e-03,\n",
      "         2.3658e-01,  4.7910e-01, -1.3557e-01, -5.8073e-01,  2.3247e-01,\n",
      "        -3.1969e-01,  6.1642e-01,  6.2218e-01,  2.6296e-01,  9.4691e-01,\n",
      "         3.1452e-01,  9.3645e-02,  2.9739e-01,  2.9006e-01, -1.9322e-01,\n",
      "         5.2255e-03,  1.8346e-01,  5.9876e-01,  5.2779e-01, -2.7725e-01,\n",
      "         4.8574e-01,  6.2893e-01,  2.6414e-01,  1.4331e-02,  1.5733e-02,\n",
      "        -2.6852e-01,  2.3515e-01,  6.3697e-01,  5.1662e-05,  3.5157e-01,\n",
      "        -2.1436e-01,  2.2808e-01,  3.2727e-01,  6.8703e-01,  2.7311e-01,\n",
      "         5.3076e-01, -3.3042e-01,  3.2636e-01,  3.3130e-01,  8.0160e-01,\n",
      "        -1.2088e-01, -1.5923e-02, -2.1595e-01,  2.7669e-01,  5.0390e-01,\n",
      "        -4.0216e-02, -3.5072e-01, -1.8507e-01,  9.1200e-01,  1.1987e-01,\n",
      "        -2.2904e-02,  1.6348e-01,  6.9015e-01, -1.2237e-01,  4.2805e-01,\n",
      "         5.1096e-01,  6.5198e-02,  5.1569e-01,  6.7353e-01,  1.6326e-01,\n",
      "         6.7396e-02,  5.8131e-02,  3.4792e-01,  1.1717e-01,  1.6923e-01,\n",
      "         2.2913e-01, -6.6839e-02, -2.1617e-01,  1.3693e-01,  3.5076e-01,\n",
      "         2.0329e-01,  6.2005e-01,  5.4672e-01,  6.6817e-01, -4.8211e-01,\n",
      "        -2.7039e-01, -2.6273e-01,  2.2633e-01, -1.9933e-01,  3.2191e-01,\n",
      "        -1.0969e-01,  1.6123e-01,  2.2337e-01,  7.8112e-01, -1.2956e-01,\n",
      "        -2.1505e-01,  6.8957e-01,  3.9083e-01, -1.7850e-01, -3.2274e-01,\n",
      "         8.1076e-02,  5.3043e-01,  2.8534e-01,  4.2164e-01, -1.5624e-01,\n",
      "        -2.0244e-01,  4.1193e-01,  2.1525e-01, -2.0820e-01, -6.7085e-03,\n",
      "         3.0581e-01,  8.1408e-02, -5.1037e-01, -1.7440e-01,  4.5148e-01,\n",
      "        -5.3181e-01,  3.5158e-01,  4.5697e-01,  1.7196e-01,  5.4318e-02,\n",
      "        -3.2318e-02,  1.3909e-01,  5.4064e-01,  3.9810e-01, -3.5160e-01,\n",
      "        -7.2990e-01, -2.0023e-01,  3.3815e-01,  3.1439e-01, -6.8052e-02,\n",
      "        -1.3607e-01,  5.6762e-02, -5.4166e-01, -4.7873e-01, -1.7725e-01,\n",
      "         1.6705e-03, -3.4946e-02, -2.7027e-02, -1.5605e-01,  1.4322e-01,\n",
      "         2.6476e-02,  1.8077e-02,  4.7808e-02, -7.7649e-02,  1.3659e-01,\n",
      "         8.6095e-03,  2.6361e-01, -2.3021e-01, -2.6370e-02,  2.5108e-01,\n",
      "         4.9343e-02,  1.9568e-01, -4.2410e-01, -3.1610e-01,  1.0615e-01,\n",
      "        -3.8436e-01,  5.0206e-02, -5.4677e-01,  1.9845e-01, -2.4937e-01,\n",
      "         1.9596e-01,  1.9516e-02,  1.1967e-01, -4.2112e-01,  3.0106e-01,\n",
      "         6.5144e-02, -1.1961e-01, -3.0425e-01, -1.7353e-01, -1.2312e-01,\n",
      "         1.3013e-01, -3.4483e-01, -2.8389e-02, -1.3368e-01, -4.4101e-02,\n",
      "        -3.5034e-01,  1.0555e-01,  3.1864e-02,  9.4677e-02,  4.5965e-01,\n",
      "         9.3446e-02, -6.8281e-02, -4.7660e-01,  4.7662e-01,  1.5531e-01,\n",
      "         2.8568e-01, -3.9125e-01,  3.5617e-01, -3.2361e-02,  3.1135e-02,\n",
      "        -8.0209e-02,  5.7974e-01, -3.7820e-01,  3.1696e-01, -1.7726e-01,\n",
      "         7.0186e-02, -5.1789e-02,  3.5279e-01,  7.9480e-01,  4.3402e-03,\n",
      "        -3.9232e-01, -9.7633e-01,  4.8859e-02,  5.7760e-01,  1.0728e-01,\n",
      "        -2.1359e-02,  1.9317e-01,  4.7589e-01, -1.1308e-01, -2.1206e-01,\n",
      "         7.6104e-01, -2.2210e-01,  3.5744e-01,  2.1341e-01, -5.9547e-02,\n",
      "         3.6843e-01, -3.5690e-01, -1.5974e-01,  1.1845e-01,  2.1711e-01,\n",
      "         4.2487e-01,  9.6384e-02,  1.0424e-01,  7.7237e-01, -9.7093e-02,\n",
      "        -4.4344e-01,  1.8398e-01,  3.5982e-02, -1.1293e-01,  1.3060e-02,\n",
      "         5.2989e-01,  6.4247e-01, -3.3082e-01, -9.3413e-02, -1.0781e-01,\n",
      "         4.1099e-01, -2.5298e-01,  8.4117e-01, -2.1414e-01,  8.2380e-02,\n",
      "        -2.3672e-01,  2.2162e-01,  5.8302e-01, -2.6472e-02, -5.8427e-03,\n",
      "         1.9753e-02, -1.9757e-01,  3.1471e-01, -1.5087e-01,  1.2929e-01,\n",
      "         7.8937e-02], device='cuda:0', requires_grad=True)\n",
      "-------------------------------\n",
      "enc.weight_ih_l1\n",
      "Parameter containing:\n",
      "tensor([[-0.4111, -0.4241,  0.1220,  ..., -0.4045, -0.3345,  0.3567],\n",
      "        [-0.2155, -0.1945,  0.0522,  ...,  0.3207, -0.4646,  0.2503],\n",
      "        [-0.4769, -0.3568,  0.1538,  ..., -0.5640, -0.2447,  0.5761],\n",
      "        ...,\n",
      "        [ 0.1105,  0.1233,  0.5152,  ...,  0.6185, -0.0517,  0.0279],\n",
      "        [-0.4690, -0.4248, -0.4284,  ..., -0.0926, -0.0018,  0.1567],\n",
      "        [-0.4832, -0.6455, -0.1287,  ..., -0.4578, -0.6232,  0.2624]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "-------------------------------\n",
      "enc.weight_hh_l1\n",
      "Parameter containing:\n",
      "tensor([[ 0.1927, -0.1183,  0.1111,  ...,  0.3173, -0.0574,  0.0937],\n",
      "        [ 0.0303, -0.0876,  0.0791,  ...,  0.0399, -0.1953,  0.1513],\n",
      "        [ 0.6148, -0.2671, -0.4880,  ...,  0.8347, -0.0265, -0.0336],\n",
      "        ...,\n",
      "        [-0.1791, -0.2108,  0.4280,  ..., -0.1874, -0.0754, -0.3806],\n",
      "        [-0.0018, -0.3811,  0.1361,  ...,  0.2277, -0.3824,  0.2653],\n",
      "        [-0.9184, -0.3105, -0.0846,  ...,  0.2108, -0.2229, -0.2759]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "-------------------------------\n",
      "enc.bias_ih_l1\n",
      "Parameter containing:\n",
      "tensor([-0.2093, -0.2134, -0.1264, -0.3952, -0.4506, -0.4611, -0.2122, -0.9813,\n",
      "        -0.2748, -0.7843, -0.2734, -0.6319, -0.1239, -0.3419, -0.2696, -0.4084,\n",
      "        -0.4204, -0.1223, -0.3413, -0.1740, -1.0820, -0.1612, -0.1105, -0.4274,\n",
      "        -0.2338,  0.0718, -0.2389, -0.2061, -0.5496, -0.4556, -0.2384,  0.2128,\n",
      "         0.2585,  0.1548, -0.3971, -0.1758,  0.1358, -0.2862, -0.4801, -0.2069,\n",
      "        -0.4028,  0.0470, -0.5041, -0.7722, -0.3001, -0.1858, -0.2574, -0.7625,\n",
      "         0.0630, -0.2375, -0.3767, -0.2168, -0.4899, -0.4932, -1.1354, -0.4704,\n",
      "        -0.5146, -0.1880, -0.3698, -0.3052, -0.8131, -0.0206, -0.4755, -0.3857,\n",
      "        -0.4088, -0.0634, -0.1599,  0.1872, -0.0552, -0.4457, -0.5995, -0.5826,\n",
      "        -0.0958,  0.0862, -0.1944,  0.0403, -0.3311, -0.3351, -0.5953, -0.3006,\n",
      "        -0.1675,  0.3095, -0.1870, -0.4134, -0.5112, -0.1733, -0.2976,  0.0048,\n",
      "        -0.2752, -0.0371, -0.3501, -0.5821, -0.1879, -0.0520, -0.3953, -0.2651,\n",
      "        -0.3612, -0.2898, -0.8318, -0.3709, -0.2643, -0.3248, -0.4093, -0.4470,\n",
      "        -0.2734, -0.4489, -0.3509,  0.3438, -0.6843, -0.5810, -0.4918, -0.4161,\n",
      "        -0.1887, -0.1194,  0.1343, -0.3219, -0.8412, -0.3275,  0.0600,  0.0257,\n",
      "        -0.1520, -0.4278, -0.4340, -0.0628, -0.5287, -0.3764, -0.0256, -0.2398,\n",
      "         0.3007, -0.2687,  0.2460,  0.1931, -0.1290, -0.3217,  0.0169,  0.2159,\n",
      "        -0.5778,  0.2406, -0.0518, -0.0315, -0.1326, -0.1466,  0.1110, -0.1225,\n",
      "         0.2883, -0.0433,  0.2321, -0.2244,  0.0656,  0.2228,  0.0986, -0.5187,\n",
      "         0.0366, -0.0495,  0.3990,  0.2322,  0.1260, -0.0224, -0.0966, -0.0557,\n",
      "         0.1866,  0.2065,  0.1111,  0.2358, -0.0308, -0.1872, -0.2325,  0.2913,\n",
      "         0.1650, -0.2610, -0.2066,  0.0469, -0.1946, -0.2886, -0.1372,  0.3718,\n",
      "         0.2280, -0.1467,  0.0987, -0.1735,  0.2479, -0.0181, -0.0655,  0.0404,\n",
      "         0.0673, -0.2737, -0.0524, -0.0986,  0.0652, -0.2723, -0.0570,  0.2518,\n",
      "        -0.7102, -0.1748, -0.1784, -0.2051,  0.2550, -0.0624, -0.4379,  0.2310,\n",
      "        -0.4122, -0.3322, -0.5593,  0.2206, -0.6691, -0.2793, -0.1511, -0.2435,\n",
      "         0.0727,  0.0425, -0.6019, -0.2021, -0.5540, -0.3553,  0.4376, -0.0942,\n",
      "        -0.0747,  0.8320, -0.2997, -0.2556, -0.2514,  0.1634, -0.1295, -0.0522,\n",
      "        -0.4898,  0.1485, -0.3110, -0.0804, -0.2650,  0.3684, -0.4771,  0.8086,\n",
      "        -0.1238,  0.1696, -0.5032, -0.0329, -0.1926,  0.0968, -0.5081,  0.0742,\n",
      "        -0.0909,  0.6003, -0.1793, -0.3000, -0.4204, -0.0422, -0.5175,  0.2489,\n",
      "        -0.4372,  0.1315, -0.4551, -0.2461, -0.5033,  0.7183, -0.5618, -0.6142],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "-------------------------------\n",
      "enc.bias_hh_l1\n",
      "Parameter containing:\n",
      "tensor([-0.2299, -0.1733, -0.3151, -0.2389, -0.2925, -0.3984, -0.1920, -0.7564,\n",
      "        -0.2828, -0.7743, -0.2017, -0.7106, -0.1052, -0.3276, -0.3272, -0.3369,\n",
      "        -0.3623, -0.1383, -0.3455, -0.3003, -0.9432, -0.3182, -0.0226, -0.4340,\n",
      "        -0.4043,  0.0656, -0.2747, -0.1743, -0.3297, -0.6048, -0.0710,  0.3169,\n",
      "         0.1789,  0.0568, -0.3973, -0.3471,  0.1327, -0.1843, -0.3965, -0.1302,\n",
      "        -0.5006,  0.0853, -0.4691, -0.8106, -0.2218, -0.2235, -0.3517, -0.8594,\n",
      "         0.0391, -0.3999, -0.2119, -0.2294, -0.6417, -0.4280, -1.0139, -0.3145,\n",
      "        -0.6090, -0.2774, -0.4222, -0.2792, -0.6637, -0.0579, -0.6927, -0.5459,\n",
      "        -0.5991, -0.2968, -0.0187,  0.2334, -0.0261, -0.4963, -0.4213, -0.5726,\n",
      "         0.0591,  0.0498, -0.3176,  0.1242, -0.2516, -0.3331, -0.5882, -0.2432,\n",
      "        -0.2467,  0.1621, -0.2075, -0.2951, -0.4433, -0.2574, -0.3126, -0.0228,\n",
      "        -0.2456, -0.0555, -0.3732, -0.6094, -0.1030,  0.0508, -0.3151, -0.1890,\n",
      "        -0.3359, -0.5027, -0.6643, -0.2795, -0.3953, -0.3318, -0.3255, -0.6044,\n",
      "        -0.3407, -0.3373, -0.4203,  0.4377, -0.5392, -0.5393, -0.3976, -0.2856,\n",
      "        -0.1424, -0.3192,  0.0304, -0.0809, -0.9749, -0.2182,  0.1275, -0.1772,\n",
      "        -0.1585, -0.4505, -0.4796, -0.1394, -0.4706, -0.3965, -0.0209, -0.1944,\n",
      "         0.0856, -0.2255,  0.2774,  0.1625, -0.0135, -0.2500, -0.0682,  0.3035,\n",
      "        -0.4909,  0.3436, -0.0891, -0.0917,  0.0224, -0.2231, -0.0235, -0.2895,\n",
      "         0.3496,  0.1305,  0.1263, -0.3266, -0.0494,  0.1701, -0.0470, -0.5270,\n",
      "         0.1537, -0.0339,  0.4107,  0.1589,  0.1545, -0.1314, -0.2073, -0.1142,\n",
      "         0.2911,  0.2029, -0.1083,  0.2935, -0.1415, -0.2797, -0.0495,  0.0968,\n",
      "         0.1889, -0.2675, -0.2213,  0.0012, -0.1673, -0.1234, -0.1853,  0.2592,\n",
      "         0.2803, -0.1178,  0.0043, -0.1482,  0.4127, -0.0684, -0.1606, -0.1013,\n",
      "        -0.0335, -0.3844, -0.0130, -0.0895, -0.1294, -0.1662,  0.1486,  0.2101,\n",
      "        -0.6914, -0.0152, -0.1266, -0.1984,  0.3927, -0.2504, -0.2883,  0.2648,\n",
      "        -0.4123, -0.2556, -0.6009,  0.1164, -0.8143, -0.2713, -0.2358, -0.2298,\n",
      "         0.1291,  0.0237, -0.5063, -0.2531, -0.6839, -0.3789,  0.2660, -0.0462,\n",
      "        -0.0502,  0.8079, -0.3195, -0.3362, -0.1134,  0.0784, -0.0156, -0.0813,\n",
      "        -0.3593,  0.2636, -0.1812, -0.1238, -0.1692,  0.3571, -0.3721,  0.8192,\n",
      "        -0.2509, -0.0265, -0.6296,  0.1491, -0.1094,  0.2262, -0.5181, -0.1193,\n",
      "        -0.2694,  0.3987, -0.2727, -0.3410, -0.4288,  0.1568, -0.3601,  0.1466,\n",
      "        -0.3922,  0.1029, -0.3036, -0.0593, -0.4652,  0.6403, -0.5186, -0.5702],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "-------------------------------\n",
      "enc.weight_ih_l1_reverse\n",
      "Parameter containing:\n",
      "tensor([[ 0.2158, -0.1073,  1.0257,  ...,  0.2868,  0.6239,  0.0053],\n",
      "        [-0.0760, -0.3953,  0.0429,  ...,  0.3693, -0.2725,  0.0753],\n",
      "        [-0.2614,  0.1626, -0.2603,  ...,  0.0567,  0.3007, -0.2752],\n",
      "        ...,\n",
      "        [-0.4251,  0.0731, -0.1030,  ..., -0.5993,  0.2100, -0.0259],\n",
      "        [-0.2315, -0.1939, -0.2808,  ..., -0.1761, -0.1491,  0.4545],\n",
      "        [-0.1148, -0.0941, -0.1962,  ...,  0.0627, -0.2793, -0.1129]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "-------------------------------\n",
      "enc.weight_hh_l1_reverse\n",
      "Parameter containing:\n",
      "tensor([[-0.7801,  0.7691,  0.4236,  ...,  0.5246, -0.4502, -1.5744],\n",
      "        [ 0.2174,  0.0321,  0.2153,  ..., -0.3631, -0.1185,  0.5839],\n",
      "        [-0.3679,  0.5856,  0.5138,  ...,  0.4185, -0.3571, -1.3711],\n",
      "        ...,\n",
      "        [ 0.0654,  0.7209,  0.6748,  ..., -0.4467, -0.2606, -0.5343],\n",
      "        [-0.6546,  0.0367,  0.4663,  ..., -0.1681, -0.2629, -0.0729],\n",
      "        [ 0.4989, -0.3455,  0.1980,  ..., -0.0062,  0.0247,  0.9077]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "-------------------------------\n",
      "enc.bias_ih_l1_reverse\n",
      "Parameter containing:\n",
      "tensor([ 0.3223, -0.7315,  0.3209, -0.5137, -0.2539, -0.4660, -0.4595, -0.5810,\n",
      "        -0.1148, -0.0245,  0.4401, -1.0557, -0.1827, -0.3635, -0.6384, -0.2071,\n",
      "        -0.1538, -0.2622, -0.5164, -0.2107, -0.5662, -0.0929, -0.9872, -0.9596,\n",
      "        -0.0419, -0.3882, -0.4150, -0.4200, -0.3426, -0.0960, -0.0687, -0.2197,\n",
      "        -0.2519, -1.0257, -0.8427, -0.4775, -0.2283, -0.3833, -0.4584, -0.2514,\n",
      "        -0.3751, -0.1062, -0.3253, -0.4362,  0.4958, -0.5570, -0.7951, -0.3524,\n",
      "        -0.5074, -0.4938,  0.4186, -0.2489, -0.4533, -0.7737, -0.5410, -0.3583,\n",
      "        -0.4135, -1.0218, -0.2099, -0.3086, -0.0679,  0.0624, -0.3644, -0.0045,\n",
      "         0.0095, -0.3959, -0.0575,  0.0995,  0.1908,  0.7456,  0.9271,  0.0639,\n",
      "         0.1447,  0.2318, -0.3720, -0.3042, -0.3502, -0.3103, -0.5121,  0.3116,\n",
      "        -0.2327, -0.2635, -0.2204, -0.5149, -0.0124,  0.3790, -0.1443, -0.2404,\n",
      "         0.6293, -0.0786,  0.0109, -0.2958,  0.3070,  0.5930,  0.3525,  0.2781,\n",
      "        -0.3519, -0.2412, -0.4911,  0.0428, -0.0066,  0.3625, -0.2881, -0.3510,\n",
      "        -0.3068, -0.4575, -0.1894,  1.0269,  0.1629, -0.0754, -0.3015, -0.4085,\n",
      "        -0.4955, -0.6258, -0.4613,  0.6722, -0.1612, -0.1075,  0.3609, -0.2788,\n",
      "        -0.0057, -0.1990, -0.3992,  0.3142, -0.3676,  0.0114,  0.1389, -0.3140,\n",
      "         0.3387,  0.0177, -0.2666, -0.1912,  0.4088,  0.3158, -0.0371,  0.1876,\n",
      "         0.2094, -0.2348,  0.5602, -0.3319, -0.0475,  0.0528, -0.2750, -0.2434,\n",
      "        -0.2781, -0.3214, -0.2719, -0.0495,  0.0828,  0.2089, -0.3476,  0.0271,\n",
      "        -0.2354, -0.1096, -0.1628, -0.1811, -0.4664,  0.0199,  0.0504,  0.2841,\n",
      "        -0.3726, -0.0347, -0.3060, -0.6180,  0.0063,  0.2268,  0.1698, -0.1331,\n",
      "        -0.5666, -0.0150,  0.2106, -0.5379, -0.1136,  0.1943, -0.3931,  0.0404,\n",
      "        -0.2159,  0.1144,  0.7406, -0.1860, -0.1135, -0.0306, -0.0579,  0.2798,\n",
      "        -0.3744,  0.3296, -0.1534, -0.1581,  0.0540,  0.4134, -0.0787,  0.2378,\n",
      "         0.4858, -0.5436, -0.5428,  0.0389, -0.1554,  0.3643,  0.4241, -0.1698,\n",
      "        -0.3461,  0.0017, -0.2891,  0.4183, -0.4386, -0.2627, -0.0791,  0.3495,\n",
      "        -0.4399,  0.0902, -0.4372, -0.1478,  0.1393,  0.2044, -0.1412, -0.1663,\n",
      "         0.2076,  0.0846,  0.3448,  0.1744,  0.0657, -0.3443, -0.1222,  0.4408,\n",
      "        -0.1658,  0.0838, -0.1156, -0.5472, -0.5253, -0.2298, -0.1764, -0.1025,\n",
      "        -0.2111,  0.3754, -0.0041, -0.2211, -0.2932, -0.3449,  0.1821,  0.3522,\n",
      "        -0.5432, -0.4555,  0.2474, -0.5749,  0.1515, -0.3284, -0.1038, -0.6176,\n",
      "         0.4342, -0.3426, -0.1884,  0.2911,  0.0047,  0.2581, -0.0884,  0.1037],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "-------------------------------\n",
      "enc.bias_hh_l1_reverse\n",
      "Parameter containing:\n",
      "tensor([ 2.3740e-01, -7.5933e-01,  2.9293e-01, -3.7782e-01, -3.5374e-01,\n",
      "        -5.2952e-01, -4.3131e-01, -3.6757e-01, -2.7839e-01,  3.2101e-02,\n",
      "         3.5586e-01, -1.0015e+00, -2.0195e-01, -2.0649e-01, -5.8321e-01,\n",
      "        -1.9931e-01, -5.2144e-02, -1.6089e-01, -5.7856e-01, -2.8148e-01,\n",
      "        -4.6108e-01, -2.1657e-01, -1.0832e+00, -7.3717e-01, -6.5319e-02,\n",
      "        -3.3171e-01, -2.6549e-01, -4.1752e-01, -3.7406e-01, -9.4690e-02,\n",
      "        -1.1945e-01, -2.0506e-01, -4.1846e-01, -1.1104e+00, -8.9557e-01,\n",
      "        -5.9055e-01, -1.8844e-01, -4.4268e-01, -5.2264e-01, -1.9558e-01,\n",
      "        -4.5248e-01, -2.5948e-01, -2.7502e-01, -4.2305e-01,  4.6345e-01,\n",
      "        -6.4899e-01, -5.9411e-01, -2.4604e-01, -5.1527e-01, -5.1690e-01,\n",
      "         3.5257e-01, -1.4835e-01, -5.1069e-01, -9.0316e-01, -5.3144e-01,\n",
      "        -3.3187e-01, -3.9540e-01, -1.0611e+00, -7.5341e-02, -2.5631e-01,\n",
      "        -1.3712e-02,  1.5763e-01, -4.3245e-01, -1.0518e-02,  1.7879e-01,\n",
      "        -3.9362e-01,  5.7298e-02,  3.9283e-03,  2.5978e-01,  9.2377e-01,\n",
      "         7.7147e-01,  1.1795e-03,  1.7722e-01,  1.0348e-01, -3.7002e-01,\n",
      "        -3.8616e-01, -3.6564e-01, -5.2529e-01, -3.2397e-01,  3.4760e-01,\n",
      "        -2.3308e-01, -1.9693e-01, -2.8358e-01, -4.9210e-01,  9.3508e-02,\n",
      "         2.0807e-01, -1.1105e-01, -3.3393e-01,  5.6628e-01, -1.5584e-01,\n",
      "         5.1285e-02, -3.1200e-01,  2.5751e-01,  7.1116e-01,  4.5250e-01,\n",
      "         1.4507e-01, -2.6958e-01, -1.1759e-01, -4.4074e-01,  2.4358e-01,\n",
      "        -1.1999e-02,  3.7661e-01, -3.4054e-01, -2.9925e-01, -3.8686e-01,\n",
      "        -4.9530e-01, -2.8139e-01,  9.5439e-01, -9.8369e-03, -1.1842e-01,\n",
      "        -3.9862e-01, -4.2832e-01, -4.2556e-01, -4.9592e-01, -5.7684e-01,\n",
      "         6.0659e-01, -1.9921e-01,  1.4387e-02,  1.4081e-01, -3.5073e-01,\n",
      "        -8.7041e-02, -2.8312e-01, -4.0066e-01,  3.5411e-01, -3.4953e-01,\n",
      "        -3.9691e-04,  5.5921e-02, -3.4986e-01,  3.3932e-01, -5.2840e-02,\n",
      "        -1.0398e-01, -1.9110e-01,  4.2997e-01,  3.3594e-01,  3.4200e-02,\n",
      "         2.8888e-01,  3.0199e-01, -2.6770e-01,  4.9831e-01, -5.1007e-01,\n",
      "         4.4916e-02,  4.1817e-02, -4.2686e-01, -1.6536e-01, -2.6067e-01,\n",
      "        -5.0479e-01, -1.8243e-01, -3.6030e-03,  6.5977e-02,  3.8565e-01,\n",
      "        -2.1864e-01,  4.8962e-02, -1.7050e-01, -8.2833e-02, -5.8835e-02,\n",
      "        -9.0027e-02, -3.4077e-01,  2.0199e-01,  2.2186e-01,  3.2279e-01,\n",
      "        -4.1872e-01, -7.2921e-02, -3.3595e-01, -6.2571e-01, -8.0735e-02,\n",
      "         3.7413e-02,  1.6954e-01,  1.9668e-02, -4.5375e-01,  1.3020e-01,\n",
      "         2.5627e-01, -6.4337e-01, -2.1037e-02,  1.2189e-01, -4.4318e-01,\n",
      "         1.3029e-01, -2.1592e-01,  1.2487e-01,  6.7458e-01, -2.5613e-01,\n",
      "        -1.0496e-01, -2.3594e-01, -1.4983e-02,  2.9184e-01, -2.9183e-01,\n",
      "         4.5662e-01, -1.0635e-02, -2.5668e-01, -2.9916e-03,  4.3499e-01,\n",
      "         4.6512e-03,  1.9581e-01,  4.4511e-01, -4.2924e-01, -4.6290e-01,\n",
      "        -4.3932e-02, -1.8085e-01,  3.3634e-01,  2.7496e-01, -4.3152e-02,\n",
      "        -3.4271e-01, -1.7846e-01, -2.1797e-01,  3.8907e-01, -2.5730e-01,\n",
      "        -1.5156e-01, -7.8589e-02,  2.7888e-01, -6.0182e-01, -3.7961e-02,\n",
      "        -6.0439e-01, -1.7016e-01,  2.0492e-01,  2.7470e-01, -1.8386e-01,\n",
      "        -1.5330e-01,  1.9966e-01,  1.7736e-01,  3.0300e-01, -3.6047e-02,\n",
      "         4.7231e-02, -1.9768e-01,  3.9695e-02,  2.4866e-01, -1.6019e-01,\n",
      "        -2.3788e-02, -1.0913e-01, -3.1809e-01, -4.9213e-01, -3.9329e-01,\n",
      "        -1.8654e-01, -1.1552e-01, -1.8646e-01,  1.8360e-01, -9.8029e-02,\n",
      "        -5.1269e-02, -3.0308e-01, -3.2415e-01,  1.3097e-01,  3.9406e-01,\n",
      "        -4.1664e-01, -4.6553e-01,  4.7591e-01, -4.4255e-01,  7.7745e-03,\n",
      "        -4.7213e-01, -6.5833e-02, -5.8862e-01,  2.8110e-01, -3.3345e-01,\n",
      "         9.4100e-03,  1.5569e-01,  3.4044e-02,  3.6980e-01, -3.2829e-01,\n",
      "         1.2043e-01], device='cuda:0', requires_grad=True)\n",
      "-------------------------------\n",
      "dec.weight_ih_l0\n",
      "Parameter containing:\n",
      "tensor([[-0.4401,  0.1097,  0.2615,  ..., -0.1229, -0.5957, -0.8849],\n",
      "        [ 0.0860,  0.0479,  0.2113,  ..., -0.3145, -0.0012, -0.3908],\n",
      "        [-0.1900, -0.1709,  0.1172,  ..., -0.0540, -0.0690,  0.0533],\n",
      "        ...,\n",
      "        [-0.0679, -0.1314,  0.2565,  ...,  0.4285, -0.2360,  0.0284],\n",
      "        [-0.2422,  0.6149,  0.1674,  ..., -0.0373,  0.0663, -0.0275],\n",
      "        [-0.0649, -0.1421, -0.0516,  ..., -0.5090, -0.0564, -0.2315]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "-------------------------------\n",
      "dec.weight_hh_l0\n",
      "Parameter containing:\n",
      "tensor([[-0.8147,  0.6254, -0.0446,  ..., -0.1260,  0.3658, -0.7926],\n",
      "        [-0.1522, -0.0892, -0.0796,  ...,  0.1645, -0.3486,  0.1427],\n",
      "        [-0.1782,  0.7134,  0.2132,  ..., -0.1186, -0.2285,  0.0181],\n",
      "        ...,\n",
      "        [-0.0091,  0.2523, -0.0725,  ...,  0.1247, -0.2371,  0.4630],\n",
      "        [ 0.1200,  0.0470,  0.0548,  ..., -0.0426,  0.3042,  0.1417],\n",
      "        [-0.3950, -0.5531, -0.0399,  ...,  0.2887, -0.9991,  0.3832]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "-------------------------------\n",
      "dec.bias_ih_l0\n",
      "Parameter containing:\n",
      "tensor([-0.2424,  0.0337, -0.8814,  0.4771,  0.5280,  0.2118, -0.2384,  0.1282,\n",
      "         0.5155, -0.0313,  0.1566,  0.0436,  0.3827,  0.1013, -0.0198, -0.0157,\n",
      "         0.1456, -0.1888,  0.5492,  0.4462,  0.0998,  0.4907, -0.0699,  0.2662,\n",
      "        -0.4414,  0.5363,  0.1799,  0.1317, -0.2295, -0.0051,  0.3687,  0.1808,\n",
      "         0.1999, -0.6102, -0.2623, -0.3012, -0.0387,  0.2800,  0.0545,  0.2820,\n",
      "        -0.3198,  0.1615,  0.3832,  0.7291,  0.1548,  0.3248,  0.5329, -0.1490,\n",
      "         0.0262,  0.5668,  0.8036,  0.3532, -0.1900, -0.0628,  0.4917,  0.0638,\n",
      "        -0.0366,  0.1013,  0.0079,  0.1825, -0.2945, -0.0660,  0.1401,  0.1036,\n",
      "        -0.1176, -0.7017,  0.1048, -0.7599, -0.3485,  0.2044,  0.4686,  0.0601,\n",
      "        -0.5058, -0.8178, -0.7239, -0.4720, -0.8633, -0.7037,  0.6055, -0.1960,\n",
      "        -0.0554, -0.7786, -0.1806, -0.1987, -0.4621, -0.1547,  0.1491, -0.2612,\n",
      "        -0.0381,  0.0134, -0.1077,  0.0013, -0.4029, -0.4268, -0.1547, -0.0126,\n",
      "        -0.3437,  0.0697,  0.4831,  0.0637, -0.2364,  0.1019, -0.1940, -0.0747,\n",
      "        -0.0057, -0.6216, -0.5279, -0.2336, -0.0518,  0.7753, -0.4101, -0.7029,\n",
      "         0.6186, -0.3778, -0.2782, -0.3331, -0.4043,  0.2466, -0.2373, -0.2169,\n",
      "        -0.1098, -0.7801,  0.4661, -0.4243, -0.0640, -0.5407, -0.2711, -0.4322,\n",
      "        -0.3516,  0.1728,  0.0358, -0.1077,  0.0453, -0.0735,  0.0731, -0.3845,\n",
      "         0.1299, -0.1138,  0.3935, -0.2667,  0.0614,  0.2038, -0.2226, -0.3157,\n",
      "         0.1117,  0.0907,  0.3432, -0.3549, -0.0565,  0.1534, -0.0375, -0.1938,\n",
      "        -0.0667,  0.1684, -0.0961, -0.1666, -0.1420,  0.5011,  0.5093,  0.0274,\n",
      "         0.0685, -0.0687,  0.1058,  0.1546,  0.2536,  0.0182,  0.0911, -0.0950,\n",
      "         0.2455,  0.0166, -0.0713, -0.0125, -0.0230,  0.1554,  0.0385,  0.1845,\n",
      "        -0.0539, -0.3458,  0.1142, -0.0274,  0.0309, -0.1217,  0.3847, -0.1538,\n",
      "         0.3232, -0.0159,  0.1511, -0.1291,  0.2166,  0.3048, -0.2547,  0.4814,\n",
      "        -0.1808, -0.3260, -0.2112,  0.1556,  0.4634,  0.0895,  1.0325, -0.4172,\n",
      "        -0.3879, -0.1638,  0.5175,  0.1198,  0.0634,  0.0012, -0.6681, -0.3316,\n",
      "        -0.4131, -0.2523, -0.4811, -0.0065,  0.0054, -0.6417, -0.3835, -0.1680,\n",
      "        -0.3274, -0.2741, -0.4048, -0.3631, -0.1881, -0.0964, -0.4831, -0.0077,\n",
      "        -0.2368,  0.1782, -0.4342, -0.0912, -0.1929,  0.1069, -0.2836,  0.0346,\n",
      "        -0.2926, -0.2963, -0.5859,  0.3358,  0.1279,  0.0158,  0.4355, -0.2252,\n",
      "         0.1763, -0.1062, -0.5769, -0.7068, -0.0971, -0.0339, -0.2111, -0.3659,\n",
      "        -0.2759, -0.4716, -0.1383, -0.0106, -0.4342, -0.0872, -0.3369, -0.0697],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "-------------------------------\n",
      "dec.bias_hh_l0\n",
      "Parameter containing:\n",
      "tensor([-0.0702,  0.1268, -0.9095,  0.4784,  0.6987,  0.2747, -0.1628,  0.1243,\n",
      "         0.4622,  0.0568, -0.0534, -0.0437,  0.4157,  0.1728,  0.0452, -0.1626,\n",
      "         0.2840, -0.0834,  0.5678,  0.4765,  0.0896,  0.4736, -0.1413,  0.3151,\n",
      "        -0.4534,  0.4911,  0.3065,  0.1834, -0.0992,  0.0408,  0.4232,  0.2820,\n",
      "         0.2013, -0.5663, -0.1590, -0.2907, -0.2867,  0.2210,  0.0075,  0.2798,\n",
      "        -0.3069,  0.0483,  0.4786,  0.7191,  0.3421,  0.3929,  0.4874, -0.1808,\n",
      "        -0.1199,  0.5774,  0.6584,  0.2852, -0.2084, -0.2187,  0.5411,  0.0904,\n",
      "        -0.1860,  0.2565, -0.0637,  0.2017, -0.1994, -0.1984,  0.1411, -0.0204,\n",
      "        -0.1686, -0.5280,  0.1396, -0.6457, -0.2401,  0.3035,  0.3371,  0.1168,\n",
      "        -0.5369, -0.8741, -0.6784, -0.3449, -0.7729, -0.6229,  0.5847, -0.2878,\n",
      "        -0.0898, -0.6554, -0.3690, -0.1684, -0.3448, -0.2112,  0.2966, -0.3149,\n",
      "         0.0779,  0.1253, -0.2188,  0.0428, -0.4867, -0.2674, -0.0337, -0.0205,\n",
      "        -0.4067, -0.0527,  0.4263, -0.1377, -0.2675,  0.0786,  0.0117, -0.1121,\n",
      "         0.0606, -0.6587, -0.4825, -0.3241, -0.0482,  0.7253, -0.6100, -0.5220,\n",
      "         0.6150, -0.2365, -0.1312, -0.3072, -0.5591,  0.0390, -0.2571, -0.1402,\n",
      "        -0.2217, -0.6993,  0.3700, -0.3378, -0.2086, -0.5187, -0.3185, -0.5044,\n",
      "        -0.1910,  0.0127, -0.0912, -0.2723,  0.0800, -0.0759,  0.1168, -0.4021,\n",
      "         0.1773, -0.2821,  0.3701, -0.3167, -0.0042,  0.2046, -0.0940, -0.2813,\n",
      "         0.1444,  0.0627,  0.3386, -0.4051, -0.0526,  0.0149,  0.0335, -0.1023,\n",
      "        -0.0328,  0.0529, -0.1034, -0.2267,  0.0964,  0.5661,  0.4817,  0.1616,\n",
      "         0.0423, -0.1861,  0.0366,  0.2736,  0.2418,  0.0320,  0.1502, -0.1433,\n",
      "         0.3472,  0.0071, -0.1821, -0.0211,  0.1037,  0.1785, -0.0772,  0.0762,\n",
      "        -0.1125, -0.3333,  0.0486, -0.1274, -0.1341, -0.0613,  0.1471, -0.0744,\n",
      "         0.1772, -0.0051,  0.0866, -0.1860,  0.2057,  0.4404, -0.3375,  0.4108,\n",
      "        -0.2654, -0.3920, -0.2090,  0.0851,  0.5400,  0.0424,  1.1441, -0.4214,\n",
      "        -0.4680, -0.2992,  0.5464,  0.0449, -0.1269, -0.0054, -0.7326, -0.2191,\n",
      "        -0.4500, -0.3942, -0.3998, -0.0180,  0.1011, -0.5946, -0.3655, -0.0445,\n",
      "        -0.2920, -0.2507, -0.4036, -0.2341, -0.2920, -0.1356, -0.3419, -0.1158,\n",
      "        -0.2737,  0.2265, -0.3909, -0.2615, -0.2375, -0.0052, -0.2483,  0.0636,\n",
      "        -0.2021, -0.0780, -0.4803,  0.2628,  0.1590,  0.0553,  0.2746, -0.0698,\n",
      "         0.1095,  0.0786, -0.5046, -0.6443, -0.1382, -0.0064, -0.1428, -0.3541,\n",
      "        -0.3502, -0.4140,  0.1009,  0.1137, -0.2585, -0.2139, -0.4146, -0.2185],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "-------------------------------\n",
      "dec.weight_ih_l0_reverse\n",
      "Parameter containing:\n",
      "tensor([[ 0.6608,  0.4130,  0.6704,  ...,  0.0871, -0.4929,  0.5013],\n",
      "        [ 0.0765,  0.3294, -0.0036,  ..., -0.0878, -0.7252, -0.1111],\n",
      "        [ 0.4798,  0.3363,  0.0858,  ..., -0.9169, -0.5502, -0.0900],\n",
      "        ...,\n",
      "        [-0.4903, -0.6699,  0.0583,  ...,  0.3394, -0.4587,  0.1719],\n",
      "        [ 0.0536,  0.3569,  0.1163,  ...,  0.5507, -0.0980,  0.0808],\n",
      "        [ 0.0660, -0.0391, -0.1031,  ...,  0.2015, -0.8226,  0.0269]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "-------------------------------\n",
      "dec.weight_hh_l0_reverse\n",
      "Parameter containing:\n",
      "tensor([[-0.4516,  0.5100, -0.3904,  ...,  0.0222,  0.2785,  0.2447],\n",
      "        [ 0.1652, -0.1449,  0.0428,  ..., -0.1166,  0.0629, -0.2287],\n",
      "        [-0.5152, -0.1492,  0.0237,  ...,  0.5502, -0.1277,  0.3570],\n",
      "        ...,\n",
      "        [ 0.5131, -0.3178,  0.0821,  ..., -0.1228,  0.2788, -0.0337],\n",
      "        [ 0.3275,  0.1462,  0.0558,  ..., -0.2587, -0.2218,  0.0085],\n",
      "        [ 0.1715,  0.4645, -0.1621,  ..., -0.8223, -0.1455, -0.6501]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "-------------------------------\n",
      "dec.bias_ih_l0_reverse\n",
      "Parameter containing:\n",
      "tensor([ 0.2017, -0.1931, -0.1084,  0.4607, -0.2195, -0.6568,  0.6704, -0.0210,\n",
      "        -0.4619,  0.4413,  0.0661, -0.2399,  0.2728,  0.7053,  0.6762,  0.4223,\n",
      "         0.3290, -0.0851,  0.2187,  0.1770, -0.0075, -0.2930,  0.0142,  0.0035,\n",
      "         0.1316,  0.0769, -0.4889,  0.8649,  0.2470,  0.4020,  0.5825, -0.1483,\n",
      "         0.5571,  0.2526,  0.7245,  0.2655,  0.1520,  0.0904,  0.1014,  0.2830,\n",
      "         0.0546,  0.0674,  0.1348,  0.2562,  0.0201, -0.2792,  0.1570,  0.2061,\n",
      "         0.2945, -0.0042, -0.1725, -0.3173, -0.4922,  0.3576, -0.2306,  0.6364,\n",
      "        -0.0244,  0.4138,  0.4366,  0.1876,  0.1564,  0.2533,  0.0421,  0.1268,\n",
      "        -0.2072, -0.4829, -0.4870, -0.4603, -0.3696,  0.2120, -0.3396,  0.1756,\n",
      "        -0.2813, -0.4401,  0.2050, -0.0226, -0.8500, -0.3677, -0.6500,  0.1660,\n",
      "        -0.3472, -0.6294, -0.1958, -0.6055, -0.4027, -0.1155, -0.6470, -0.5104,\n",
      "         0.0686, -0.4126,  0.1392, -0.4819, -0.1707, -0.4996, -0.2477, -0.2534,\n",
      "        -0.2010, -0.6497, -0.1052,  0.3499, -0.1566,  0.1585, -0.0942, -0.7959,\n",
      "        -0.6118, -0.4332, -0.2524, -0.0831, -0.0148, -0.3446, -0.5043,  0.1308,\n",
      "        -0.5428, -0.2862, -0.3367,  0.1388,  0.6636, -0.3045, -0.0059,  0.1138,\n",
      "        -0.1777, -0.1683,  0.0038, -0.0700, -0.2122, -0.4032,  0.3375,  0.2121,\n",
      "         0.1722, -0.2770, -0.0138, -0.1595,  0.0967, -0.0382,  0.4218, -0.2205,\n",
      "         0.4454,  0.0795,  0.2548,  0.0480,  0.2742, -0.3915,  0.0947,  0.2444,\n",
      "        -0.2319,  0.0972, -0.1908, -0.0133, -0.3070,  0.2685, -0.1180,  0.3743,\n",
      "         0.0287, -0.1544,  0.0373, -0.3711, -0.4282,  0.3715,  0.2524,  0.0660,\n",
      "        -0.1739,  0.1368,  0.4169, -0.0036, -0.2591, -0.2276,  0.4537, -0.2052,\n",
      "        -0.2424,  0.1270, -0.2304,  0.0641, -0.3202,  0.0376, -0.2340,  0.0614,\n",
      "        -0.2354,  0.2842, -0.1260, -0.1645,  0.0904, -0.0414,  0.2071, -0.5617,\n",
      "         0.0357, -0.2989,  0.0483, -0.3091,  0.3661,  0.1564,  0.6528,  0.3493,\n",
      "        -0.3727, -0.2184,  0.1198, -0.2944, -0.3525,  0.0964, -0.5314, -0.6020,\n",
      "        -0.4277, -0.3070, -0.6754, -0.2342,  0.4887,  0.2517,  0.5144, -0.1672,\n",
      "        -0.1001, -0.2011,  0.2366,  0.0937, -0.6135, -0.4519, -0.5429, -0.2855,\n",
      "        -0.3607, -0.4714,  0.0836, -0.5098, -0.5812,  0.2404,  0.3382, -0.6230,\n",
      "        -0.2976, -0.3393, -0.2890, -0.0720, -0.3452,  0.1629, -0.4750,  0.0200,\n",
      "        -0.0523,  0.0291,  0.1324, -0.4768, -0.2080, -0.5476, -0.0551, -0.2073,\n",
      "        -0.0610, -0.0022, -0.7252, -0.2499,  0.1486, -0.3154,  0.1590,  0.2355,\n",
      "         0.2043,  0.2486, -0.2675, -0.1344, -0.3997,  0.0327,  0.5864,  0.2481],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "-------------------------------\n",
      "dec.bias_hh_l0_reverse\n",
      "Parameter containing:\n",
      "tensor([ 3.8225e-01, -2.0589e-02, -1.7863e-01,  5.0588e-01, -1.2677e-01,\n",
      "        -5.8440e-01,  6.4223e-01,  1.2425e-01, -3.5735e-01,  2.6544e-01,\n",
      "         2.6706e-01, -2.2215e-01,  3.3396e-01,  8.3517e-01,  6.6595e-01,\n",
      "         4.9313e-01,  3.5411e-01, -8.8803e-02,  6.9551e-02,  2.8129e-01,\n",
      "        -4.3083e-02, -9.6771e-02, -1.1995e-02, -2.0182e-02,  2.8174e-01,\n",
      "        -6.6790e-02, -3.6053e-01,  7.0239e-01,  2.2032e-01,  2.8640e-01,\n",
      "         5.3705e-01, -1.6871e-01,  6.1836e-01,  3.6066e-01,  5.7528e-01,\n",
      "         3.6427e-01,  2.6524e-01,  8.5567e-02,  1.9257e-01,  3.7996e-01,\n",
      "        -3.5418e-04,  8.5131e-02, -6.2142e-03,  2.0001e-01,  4.1523e-03,\n",
      "        -3.3870e-01,  2.0671e-01,  1.9308e-01,  4.1624e-01, -5.4257e-02,\n",
      "        -7.4516e-02, -2.3936e-01, -3.5464e-01,  2.1155e-01, -2.3226e-01,\n",
      "         4.8266e-01,  6.1405e-02,  2.7202e-01,  5.1198e-01,  6.7122e-02,\n",
      "         8.0454e-02,  1.5413e-01,  7.2975e-02,  2.6248e-01, -7.4702e-02,\n",
      "        -3.2123e-01, -6.0349e-01, -5.3186e-01, -3.7526e-01,  1.9087e-01,\n",
      "        -2.2380e-01,  1.5668e-01, -1.3821e-01, -4.8586e-01,  3.9345e-01,\n",
      "        -9.9649e-02, -8.3196e-01, -2.5019e-01, -4.3214e-01,  2.7897e-01,\n",
      "        -3.2500e-01, -5.7797e-01, -4.6816e-02, -5.8235e-01, -3.5307e-01,\n",
      "        -1.3743e-01, -5.5906e-01, -3.8340e-01,  5.1730e-02, -2.9013e-01,\n",
      "         1.5913e-01, -5.5307e-01, -1.3911e-01, -5.1585e-01, -9.3839e-02,\n",
      "        -3.1740e-01, -1.4450e-01, -5.8454e-01, -6.1117e-02,  4.4685e-01,\n",
      "        -1.2624e-01, -6.7221e-02,  1.4450e-01, -6.9198e-01, -7.1379e-01,\n",
      "        -2.7580e-01, -4.0417e-01,  2.0734e-02, -1.6699e-01, -2.8587e-01,\n",
      "        -4.5941e-01,  1.2286e-01, -5.4680e-01, -1.8864e-01, -2.3654e-01,\n",
      "         1.8755e-01,  6.7049e-01, -2.7620e-01, -1.1153e-01,  2.4296e-01,\n",
      "        -1.7660e-01, -9.5134e-02,  1.7479e-01, -9.2708e-02, -2.6638e-01,\n",
      "        -3.5255e-01,  2.6711e-01,  2.1386e-01,  2.0182e-01, -2.3904e-01,\n",
      "        -3.7598e-02, -1.4532e-01,  2.1183e-01,  6.5664e-03,  2.5876e-01,\n",
      "        -3.0886e-01,  4.6329e-01, -6.1045e-02,  1.1153e-01,  1.5003e-01,\n",
      "         1.9532e-01, -4.3896e-01,  9.5532e-02,  2.1283e-01, -2.1817e-01,\n",
      "        -6.8223e-02, -3.5190e-02, -1.1559e-01, -2.9989e-01,  3.5688e-02,\n",
      "        -1.2336e-01,  4.9176e-01,  1.4076e-01, -1.0310e-01,  5.0200e-02,\n",
      "        -2.0139e-01, -4.0765e-01,  1.5977e-01,  1.7351e-01,  1.1099e-02,\n",
      "        -3.1285e-01, -2.0686e-02,  3.3984e-01,  1.2658e-01, -1.2074e-01,\n",
      "        -2.4252e-01,  3.3374e-01, -1.3894e-01, -1.7895e-01,  1.2089e-01,\n",
      "        -1.9441e-01,  3.3936e-02, -3.2886e-01,  2.5172e-01, -9.7039e-02,\n",
      "        -8.3461e-02, -7.7985e-03,  2.5490e-01, -1.7841e-01, -2.1173e-01,\n",
      "         1.8213e-01, -2.1784e-01,  7.5553e-02, -5.7916e-01, -3.2629e-03,\n",
      "        -3.8204e-01, -5.5019e-03, -1.2376e-01,  2.3464e-01,  1.3097e-01,\n",
      "         6.3425e-01,  3.5188e-01, -3.3642e-01, -2.4155e-01,  6.4842e-02,\n",
      "        -2.7670e-01, -3.3507e-01,  2.7636e-02, -4.5225e-01, -6.9041e-01,\n",
      "        -3.5560e-01, -3.5991e-01, -7.1874e-01, -2.6476e-01,  4.3462e-01,\n",
      "         1.9743e-01,  4.9755e-01, -9.5525e-02, -1.8213e-01, -1.4298e-01,\n",
      "         8.2495e-02,  1.5527e-02, -6.7830e-01, -4.6024e-01, -3.8519e-01,\n",
      "        -4.6733e-01, -4.6543e-01, -3.6747e-01, -2.0699e-02, -4.8659e-01,\n",
      "        -4.3926e-01,  1.2398e-01,  1.4666e-01, -5.8768e-01, -2.0873e-01,\n",
      "        -2.3456e-01, -2.9736e-01,  3.2834e-03, -4.9642e-01,  8.0557e-02,\n",
      "        -3.3743e-01,  5.5668e-02, -7.7785e-02,  1.0284e-01,  4.5058e-02,\n",
      "        -6.1356e-01, -1.1440e-01, -5.5216e-01,  6.4424e-02, -1.9543e-01,\n",
      "         5.6018e-02, -4.4901e-02, -6.5175e-01, -2.5368e-01,  1.4213e-01,\n",
      "        -2.5334e-01,  3.4783e-02,  5.0893e-02,  2.2588e-01,  1.9488e-01,\n",
      "        -9.6095e-02, -2.0257e-02, -4.1290e-01,  9.1764e-02,  7.1817e-01,\n",
      "         1.8638e-01], device='cuda:0', requires_grad=True)\n",
      "-------------------------------\n",
      "dec.weight_ih_l1\n",
      "Parameter containing:\n",
      "tensor([[-0.1785,  0.1996, -0.5517,  ..., -0.3745,  0.6613,  0.0235],\n",
      "        [-0.0863,  0.2381,  0.3677,  ...,  0.2771, -0.2556,  0.3643],\n",
      "        [-0.2950,  0.4220, -0.1136,  ..., -0.5106,  0.5182, -0.8104],\n",
      "        ...,\n",
      "        [-0.1640, -0.2386,  0.3003,  ...,  0.5264,  0.1286, -0.0042],\n",
      "        [-0.5170,  0.0794, -0.4772,  ..., -0.2137,  0.1485,  0.3340],\n",
      "        [-0.4643, -0.5377,  0.0999,  ..., -0.1114, -0.9858, -0.5528]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "-------------------------------\n",
      "dec.weight_hh_l1\n",
      "Parameter containing:\n",
      "tensor([[-0.5184, -0.8405,  0.3231,  ...,  1.0514,  0.2274,  0.4733],\n",
      "        [-0.1998, -0.2169,  0.3500,  ...,  0.7800,  0.4200,  0.2491],\n",
      "        [-0.6216,  0.3183,  1.3408,  ...,  0.0234,  0.8262,  0.5007],\n",
      "        ...,\n",
      "        [ 0.2553, -0.1950, -0.5326,  ...,  0.4675,  0.1475, -0.3362],\n",
      "        [-0.1634, -0.5716, -0.3451,  ...,  1.2402, -0.5705,  1.0071],\n",
      "        [-0.7272,  0.0120, -0.1062,  ...,  0.4457, -0.5730, -0.9701]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "-------------------------------\n",
      "dec.bias_ih_l1\n",
      "Parameter containing:\n",
      "tensor([ 0.2874,  0.1765, -0.0533,  0.0913,  0.1914,  0.0566,  0.1845,  0.6088,\n",
      "        -0.1450, -0.5653,  0.0813,  0.2823, -0.1772,  0.2214,  0.2492, -0.2431,\n",
      "         0.2684,  0.2549,  0.0648,  0.1238,  0.1165,  0.4452,  0.3490, -0.1594,\n",
      "         0.5945,  0.3069,  0.0894,  0.2950, -0.3685, -0.4054, -0.2401,  0.4435,\n",
      "        -0.4078,  0.4712, -0.3404,  0.3640,  0.4170, -0.1588,  0.0036, -0.1905,\n",
      "         0.1876,  0.2085,  0.3047, -0.0456,  0.0097,  0.1779,  0.1708,  0.1194,\n",
      "         0.1963, -0.8924, -0.5660,  0.1776,  0.0429,  0.6629,  0.0198, -0.3785,\n",
      "         0.1272,  0.2862,  0.4545, -0.3443,  0.2223, -0.8177,  0.5127, -0.3332,\n",
      "        -0.3445, -0.1135, -0.8021, -0.3779, -0.0055,  0.2364, -0.4764, -0.3744,\n",
      "        -0.0487, -0.2465, -0.0268,  0.4381, -0.0130,  0.1957, -0.3645, -0.3346,\n",
      "         0.3939,  0.4393,  0.1826, -0.3999,  0.3704, -0.5031, -0.3599,  0.2938,\n",
      "        -0.4201, -0.3646,  0.3072, -0.3455,  0.0265, -0.0717, -0.2795, -0.1556,\n",
      "         0.0823, -0.4308,  0.1749, -0.1094, -0.1628,  0.0752, -0.2803,  0.7408,\n",
      "        -0.3569,  0.7766, -0.0054,  0.3995, -0.0227, -0.0763, -0.0075,  0.0896,\n",
      "         0.3531, -0.0686,  0.4627,  0.2566,  0.1450, -0.1168,  0.0674, -0.0632,\n",
      "        -0.1373, -0.3030,  0.2841,  0.1508,  0.7169,  0.5781,  0.8244,  0.2943,\n",
      "        -0.2132, -0.2222,  0.0227, -0.0813,  0.1536,  0.0485, -0.1911,  0.1681,\n",
      "        -0.2798,  0.2358,  0.3925,  0.1214,  0.3053,  0.0735, -0.0491,  0.3709,\n",
      "         0.0308,  0.2679,  0.2141,  0.0553, -0.0037,  0.0611,  0.2336,  0.3094,\n",
      "        -0.0827,  0.0341, -0.3893, -0.1458, -0.3262, -0.1191,  0.3716, -0.1377,\n",
      "        -0.0961,  0.4652, -0.3497,  0.1360, -0.2084,  0.1044,  0.3078, -0.1465,\n",
      "         0.3656,  0.4847, -0.4930, -0.0723, -0.2230, -0.0597,  0.3243,  0.4731,\n",
      "         0.2471, -0.1875, -0.3371, -0.0453, -0.1738, -0.2566, -0.2838, -0.2079,\n",
      "        -0.1676, -0.1039, -0.1723,  0.2516,  0.2411, -0.1839,  0.2670,  0.0358,\n",
      "        -0.0377, -0.1561, -0.1198,  0.0474, -0.0122, -0.0836,  0.4301,  0.0262,\n",
      "         0.0771, -0.1923, -0.1362, -0.1832, -0.3448, -0.1890, -0.0310, -0.1369,\n",
      "        -0.5262, -0.0792, -0.1274,  0.0383, -0.2027, -0.2654,  0.0494, -0.1052,\n",
      "         0.0838,  0.2995, -0.0470,  0.0567, -0.1499, -0.1686,  0.0110, -0.0639,\n",
      "        -0.1943, -0.1198, -0.2179,  0.4974,  0.1015, -0.1054, -0.0919, -0.0246,\n",
      "         0.1622,  0.4653, -0.0846,  0.0888, -0.1465, -0.2210, -0.3480,  0.0114,\n",
      "        -0.2882,  0.1186, -0.0660,  0.1238, -0.0955,  0.0684, -0.2129,  0.0835,\n",
      "         0.1174,  0.1600, -0.2523,  0.1483,  0.1744,  0.2699,  0.5290,  0.0774],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "-------------------------------\n",
      "dec.bias_hh_l1\n",
      "Parameter containing:\n",
      "tensor([ 3.0921e-01,  1.3927e-01,  4.6453e-03,  2.6647e-01,  7.6260e-02,\n",
      "         1.1944e-01,  2.5916e-01,  5.6671e-01, -2.3834e-01, -4.5059e-01,\n",
      "         1.1748e-01,  4.2544e-01, -1.8400e-02,  9.9496e-02,  1.2960e-01,\n",
      "        -1.5345e-01,  5.7056e-02,  7.5545e-02,  1.0807e-01,  2.0170e-01,\n",
      "        -7.9095e-03,  4.2630e-01,  2.0206e-01, -2.7175e-01,  3.5362e-01,\n",
      "         1.3488e-01,  1.3584e-01,  3.0051e-01, -3.1346e-01, -3.8607e-01,\n",
      "        -1.9202e-01,  4.1905e-01, -5.2984e-01,  5.7464e-01, -1.8847e-01,\n",
      "         3.8299e-01,  4.9734e-01, -3.0222e-01, -3.5987e-02, -3.6717e-01,\n",
      "         3.3168e-01,  3.6662e-01,  3.1730e-01,  7.9932e-02, -9.7121e-02,\n",
      "         2.6570e-01,  2.6800e-01,  1.9931e-01,  1.9439e-01, -9.4984e-01,\n",
      "        -5.3682e-01, -3.7598e-02,  6.5660e-02,  4.4636e-01,  6.4867e-02,\n",
      "        -4.5070e-01,  1.8455e-01,  4.2037e-01,  4.0124e-01, -2.6328e-01,\n",
      "         2.3964e-01, -7.7045e-01,  4.8738e-01, -3.2508e-01, -4.0843e-01,\n",
      "        -6.3918e-02, -8.1725e-01, -4.4280e-01, -2.6404e-03,  2.6675e-01,\n",
      "        -5.9716e-01, -4.0522e-01,  1.8780e-01, -5.0205e-02,  6.0387e-02,\n",
      "         4.8887e-01, -4.9476e-02,  1.9407e-01, -3.6512e-01, -2.6535e-01,\n",
      "         3.5229e-01,  3.0103e-01,  2.1396e-01, -2.0805e-01,  3.1749e-01,\n",
      "        -4.5518e-01, -3.7795e-01,  4.3378e-01, -4.7218e-01, -3.9398e-01,\n",
      "         3.5270e-01, -3.5429e-01, -8.3546e-02, -1.2005e-01, -3.9331e-01,\n",
      "        -2.4453e-01, -9.6085e-02, -3.6662e-01,  7.7121e-02, -2.5655e-01,\n",
      "        -2.6836e-01,  5.7091e-04, -3.7208e-01,  8.0182e-01, -4.6960e-01,\n",
      "         6.9809e-01,  3.2598e-03,  3.4118e-01, -1.0411e-01,  4.3152e-02,\n",
      "        -7.9114e-02, -2.8845e-02,  3.6756e-01,  5.6005e-02,  4.7456e-01,\n",
      "         2.6247e-01,  2.3318e-01, -1.1385e-01,  6.8953e-02, -1.5244e-01,\n",
      "        -1.2692e-01, -3.1942e-01,  1.4680e-01,  9.3431e-02,  6.5407e-01,\n",
      "         5.5197e-01,  8.1855e-01,  1.8737e-01, -2.7429e-01, -2.2214e-01,\n",
      "        -1.2602e-01,  2.6506e-02,  1.6434e-01,  2.0675e-01, -7.5977e-02,\n",
      "         3.8759e-01, -2.6760e-01,  2.0722e-01,  3.0846e-01,  8.6469e-02,\n",
      "         1.3895e-01,  1.7341e-01,  1.1862e-01,  3.9386e-01,  1.4768e-02,\n",
      "         1.5126e-01,  1.0334e-01,  2.6033e-01, -1.7344e-01, -4.7475e-02,\n",
      "         2.9014e-01,  2.5626e-01, -1.3305e-02,  2.7388e-02, -2.9825e-01,\n",
      "        -3.1455e-02, -1.8704e-01, -5.1301e-02,  2.3789e-01, -1.1672e-01,\n",
      "        -1.8950e-01,  3.9621e-01, -2.9215e-01,  9.0338e-03, -1.7160e-01,\n",
      "         2.2639e-01,  2.9805e-01,  2.0954e-02,  2.1699e-01,  4.2765e-01,\n",
      "        -4.8922e-01, -8.7300e-02, -7.8869e-03, -2.3562e-01,  3.8267e-01,\n",
      "         4.3600e-01,  2.2090e-01, -2.2732e-01, -2.6371e-01,  9.2933e-03,\n",
      "        -4.1209e-02, -2.1214e-01, -3.1212e-01, -6.1540e-02, -9.4121e-02,\n",
      "        -9.9285e-02, -1.4270e-01,  2.6164e-01,  3.0238e-01, -1.7029e-01,\n",
      "         2.8678e-01, -1.3726e-01,  1.7427e-01, -1.3346e-01, -5.9486e-02,\n",
      "        -2.0077e-02,  3.1541e-02, -2.1071e-01,  3.2680e-01, -6.8839e-02,\n",
      "         4.0759e-02, -2.5879e-02, -3.5057e-02, -2.9618e-01, -3.0582e-01,\n",
      "        -2.4152e-01, -3.4572e-02, -8.5812e-02, -4.5030e-01, -5.7337e-03,\n",
      "        -1.2365e-01,  1.1523e-01, -1.1173e-01, -9.3096e-02,  5.5326e-02,\n",
      "        -1.2129e-01,  9.3391e-02,  2.3531e-01, -7.3549e-02,  1.2530e-01,\n",
      "        -2.3160e-01, -6.7216e-02,  8.0127e-02, -4.1363e-02, -2.3438e-01,\n",
      "        -1.2301e-01, -1.8900e-01,  4.7962e-01,  1.4841e-01, -3.4174e-01,\n",
      "        -1.2938e-01, -8.7351e-02,  1.8938e-02,  7.0518e-01, -2.4659e-01,\n",
      "         1.6518e-01,  1.5746e-02, -2.0054e-01, -3.1351e-01,  1.7473e-02,\n",
      "        -1.6994e-01,  8.2027e-02, -1.4012e-01,  4.7812e-03, -2.6862e-02,\n",
      "         5.8278e-02, -1.2452e-01, -2.1399e-02, -6.2470e-02,  1.8837e-01,\n",
      "        -9.8858e-02,  8.7702e-02,  1.2921e-01,  1.9473e-01,  5.2714e-01,\n",
      "         2.1113e-01], device='cuda:0', requires_grad=True)\n",
      "-------------------------------\n",
      "dec.weight_ih_l1_reverse\n",
      "Parameter containing:\n",
      "tensor([[ 0.2996,  0.3563, -0.4081,  ..., -0.3466,  0.1941, -0.3545],\n",
      "        [ 0.4882,  0.2329,  0.3685,  ...,  0.3885,  0.0740, -0.1350],\n",
      "        [-0.2838,  0.1316, -0.4940,  ..., -0.0681,  0.1732,  0.2789],\n",
      "        ...,\n",
      "        [ 0.3702,  0.1077, -0.1508,  ...,  0.1112,  0.0432, -0.6977],\n",
      "        [ 0.0627,  0.2011, -0.3245,  ..., -0.2577,  0.5829,  0.0098],\n",
      "        [ 0.0698, -0.0225,  0.0703,  ..., -0.2265, -0.1532, -0.2444]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "-------------------------------\n",
      "dec.weight_hh_l1_reverse\n",
      "Parameter containing:\n",
      "tensor([[-0.3397, -0.1969, -0.2003,  ...,  0.0557,  0.0740, -0.9937],\n",
      "        [ 0.2349,  0.0037, -0.3938,  ..., -0.3832,  0.3853,  0.6199],\n",
      "        [ 0.4671,  0.3635,  0.3252,  ..., -0.0698,  0.1404, -0.3258],\n",
      "        ...,\n",
      "        [-0.2795, -0.4033, -0.0965,  ...,  0.3671, -0.7177, -0.4323],\n",
      "        [ 0.3237,  0.2171, -0.3287,  ..., -0.4994,  0.0866,  0.2736],\n",
      "        [ 0.3718, -0.1611, -0.4239,  ...,  0.3330, -0.0612, -0.4586]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "-------------------------------\n",
      "dec.bias_ih_l1_reverse\n",
      "Parameter containing:\n",
      "tensor([-1.0567e-01, -3.1263e-01,  2.4742e-01, -2.5174e-01,  1.7018e-01,\n",
      "         1.2144e-01, -1.2125e-01,  3.1827e-01,  2.1093e-01,  1.6939e-01,\n",
      "        -4.4154e-01,  1.0590e-02, -2.3926e-01, -1.0274e-01, -5.4252e-02,\n",
      "         3.8606e-02, -8.9852e-02, -1.7825e-02,  9.4528e-02,  2.4176e-01,\n",
      "        -1.6954e-01, -2.3409e-01,  3.1690e-02,  3.5142e-01,  7.2669e-02,\n",
      "        -4.9696e-01, -5.1503e-01,  3.2745e-01, -3.0768e-02,  3.2173e-01,\n",
      "         9.2251e-02, -8.9428e-02, -1.5685e-01,  1.9725e-01, -4.6323e-01,\n",
      "        -3.5478e-01,  1.0912e-01, -2.1764e-01, -4.8643e-01, -3.1697e-04,\n",
      "        -2.3581e-03, -4.0080e-01,  1.2562e-01,  1.3350e-01, -1.9834e-01,\n",
      "        -2.3693e-01, -2.4059e-01,  5.4121e-01, -1.1157e-01,  1.8180e-01,\n",
      "        -6.1603e-01,  2.0992e-01, -2.3995e-01,  1.5793e-01, -3.7553e-02,\n",
      "        -3.0956e-01, -2.5949e-01,  2.4378e-02, -3.7827e-02, -2.0918e-01,\n",
      "        -2.7232e-01, -2.0123e-01, -4.3176e-01,  1.6531e-01,  5.9924e-01,\n",
      "        -1.6884e-01, -5.7414e-02, -1.4739e-01, -4.1774e-01, -3.1069e-02,\n",
      "        -5.2162e-01, -1.2654e-01, -5.6926e-01,  1.1820e-02,  1.0913e-01,\n",
      "         4.3798e-01, -7.3584e-01,  4.4669e-02,  2.3231e-01, -1.2391e-01,\n",
      "         5.6673e-01, -2.7865e-01,  1.2419e-01, -5.3495e-01, -1.5593e-01,\n",
      "        -3.8805e-01, -2.5299e-01, -3.7811e-01, -1.1957e-01, -1.8146e-01,\n",
      "        -4.7058e-01, -3.5076e-01,  7.3857e-02, -4.3904e-01,  9.9447e-02,\n",
      "        -1.6077e-01, -7.0167e-02, -3.3266e-02,  1.4312e-01, -9.7774e-02,\n",
      "         2.9814e-01,  2.8518e-01,  5.7766e-01, -4.2838e-01,  2.3026e-01,\n",
      "         2.9676e-01,  2.5836e-01, -7.4838e-02,  2.5944e-01,  2.5476e-01,\n",
      "         5.6409e-01,  2.2762e-01, -1.4605e-01, -6.5420e-01,  3.6383e-01,\n",
      "        -7.2964e-02, -6.9866e-03, -3.7601e-01,  1.2455e-02,  3.3239e-01,\n",
      "        -5.7577e-01,  5.6224e-02,  6.8770e-02,  1.1465e-01,  6.5860e-01,\n",
      "         2.0664e-01, -1.0618e-01, -4.4226e-01, -3.8010e-01, -7.4983e-02,\n",
      "         2.7615e-01,  1.9632e-01,  7.2501e-02, -1.1161e-01, -2.4839e-03,\n",
      "        -1.2498e-01, -2.0110e-01,  4.5885e-01,  3.7377e-02,  1.7027e-02,\n",
      "        -3.6488e-01,  8.6180e-02,  1.8814e-01, -5.7352e-02, -1.3079e-01,\n",
      "        -4.2248e-02,  5.8475e-02,  2.4381e-01,  1.5677e-01,  8.2474e-02,\n",
      "        -3.3246e-01, -2.3132e-01,  5.6657e-02,  3.8502e-01,  2.2992e-01,\n",
      "        -4.0050e-01,  3.3041e-02,  4.1867e-01,  3.0398e-01,  4.9862e-01,\n",
      "         2.4008e-01,  3.3182e-01, -1.1102e-01,  3.6557e-01, -2.2774e-01,\n",
      "         2.4800e-01, -3.2147e-01,  1.1625e-01,  2.9134e-01,  1.1411e-01,\n",
      "        -1.8614e-01,  1.1845e-01,  5.0315e-02,  4.9090e-02, -2.3563e-01,\n",
      "         3.7056e-01, -9.6905e-02, -9.2329e-02,  1.5438e-01, -2.5559e-01,\n",
      "         2.0868e-01,  2.0707e-02,  3.8694e-01,  1.2066e-01, -4.0594e-01,\n",
      "         4.3720e-01,  3.4050e-01, -1.7020e-01, -2.2328e-01, -3.2178e-01,\n",
      "         1.6148e-01,  3.5618e-02,  1.1701e-01, -3.1156e-01, -3.1759e-02,\n",
      "        -3.2785e-01,  1.5177e-01, -1.0042e-02, -9.3494e-02, -1.0685e-01,\n",
      "         4.4696e-01, -7.7794e-02, -2.5878e-01,  1.9801e-01,  5.8119e-01,\n",
      "        -2.4392e-02, -3.5484e-01,  5.6879e-02, -3.2573e-01, -3.3932e-01,\n",
      "        -2.3715e-01, -7.9505e-02,  3.5749e-01,  6.3356e-02, -1.2982e-01,\n",
      "         1.4850e-02, -8.0993e-02, -4.8075e-01,  4.8759e-02, -4.0752e-01,\n",
      "         4.8160e-02, -2.5173e-01, -1.1094e-01, -1.3027e-01, -2.3752e-01,\n",
      "        -3.1684e-01,  4.0348e-01,  6.1431e-02, -8.5032e-02,  3.5454e-01,\n",
      "         2.7069e-01,  1.2634e-01, -3.4930e-01, -2.7074e-02, -3.5387e-01,\n",
      "         5.0712e-02, -1.6653e-01, -4.8377e-02,  2.6981e-01, -7.5213e-02,\n",
      "         2.1131e-01,  1.8534e-01, -1.5952e-01, -3.8425e-01, -2.7560e-01,\n",
      "        -4.2810e-01, -8.3138e-02, -3.7516e-02, -1.9861e-01, -1.7086e-01,\n",
      "         8.3527e-02, -1.2669e-01,  1.5409e-01, -1.5311e-01,  8.4159e-04,\n",
      "         1.1634e-01], device='cuda:0', requires_grad=True)\n",
      "-------------------------------\n",
      "dec.bias_hh_l1_reverse\n",
      "Parameter containing:\n",
      "tensor([-0.2043, -0.3718,  0.1233, -0.1554,  0.1666,  0.1370, -0.2481,  0.1952,\n",
      "         0.2147,  0.2432, -0.4280,  0.0152, -0.3426, -0.2126, -0.0530, -0.0431,\n",
      "        -0.0741, -0.1853,  0.0089,  0.2764, -0.1081, -0.0838, -0.0702,  0.2729,\n",
      "         0.2381, -0.4053, -0.4973,  0.3726, -0.0891,  0.3140,  0.1425,  0.0568,\n",
      "        -0.2281,  0.1444, -0.3096, -0.3240, -0.0783, -0.3681, -0.3360, -0.0014,\n",
      "        -0.0425, -0.4368,  0.1793, -0.0350, -0.1496, -0.2426, -0.3129,  0.6373,\n",
      "        -0.0496,  0.0935, -0.4668,  0.3530, -0.3167, -0.0043,  0.1454, -0.2305,\n",
      "        -0.2769,  0.0880,  0.0022, -0.1048, -0.0904, -0.0151, -0.4442,  0.3030,\n",
      "         0.4119, -0.1430, -0.0291, -0.1381, -0.4570,  0.0587, -0.5228, -0.1291,\n",
      "        -0.7190, -0.0716,  0.1294,  0.5635, -0.7284,  0.1870,  0.3630, -0.2416,\n",
      "         0.5532, -0.2682, -0.0439, -0.5134, -0.0911, -0.4473, -0.1529, -0.3244,\n",
      "        -0.2956, -0.1391, -0.4649, -0.4491,  0.0238, -0.3033,  0.0551, -0.2781,\n",
      "        -0.1173, -0.0893,  0.3254, -0.0549,  0.3271,  0.0514,  0.7121, -0.2354,\n",
      "         0.2821,  0.3345,  0.3461, -0.0365,  0.3478,  0.2332,  0.5854,  0.3962,\n",
      "        -0.2886, -0.6723,  0.4146, -0.0496,  0.0129, -0.4323, -0.1750,  0.2370,\n",
      "        -0.4077,  0.0963,  0.1081,  0.2065,  0.6518,  0.1576,  0.0402, -0.5289,\n",
      "        -0.4142,  0.0480,  0.2335,  0.2687,  0.2825, -0.2254, -0.0179, -0.1610,\n",
      "        -0.2310,  0.3787, -0.0521,  0.1444, -0.3864,  0.1170,  0.2892, -0.2025,\n",
      "        -0.0519,  0.0224,  0.0030,  0.0316,  0.1302, -0.0523, -0.2758, -0.2461,\n",
      "         0.0756,  0.3605,  0.1823, -0.4558,  0.0769,  0.4936,  0.0839,  0.3710,\n",
      "         0.3057,  0.2600,  0.0540,  0.3662, -0.0982,  0.1639, -0.1565,  0.1387,\n",
      "         0.3394,  0.2306, -0.1907,  0.0010,  0.0501, -0.0566, -0.0474,  0.4020,\n",
      "        -0.3105,  0.0747,  0.1259, -0.4122,  0.1383,  0.0381,  0.4454,  0.1656,\n",
      "        -0.2501,  0.4580,  0.2295, -0.1771, -0.0819, -0.2321,  0.2391,  0.1392,\n",
      "         0.2811, -0.2805, -0.0732, -0.2579,  0.0632, -0.1067, -0.1952, -0.0925,\n",
      "         0.3251, -0.0689, -0.2827,  0.1873,  0.3800, -0.1408, -0.2753,  0.1770,\n",
      "        -0.3481, -0.3171, -0.3622, -0.1454,  0.3970, -0.0428, -0.3074, -0.1250,\n",
      "        -0.1087, -0.4677, -0.0910, -0.3245, -0.1070, -0.3212, -0.0670, -0.0198,\n",
      "        -0.1586, -0.4469,  0.4323, -0.0574,  0.0140,  0.3427,  0.3858,  0.1860,\n",
      "        -0.2453,  0.0726, -0.2926, -0.0152, -0.0865, -0.0365,  0.2388,  0.0231,\n",
      "         0.2283,  0.3084, -0.1369, -0.2373, -0.2136, -0.3894, -0.0911, -0.1624,\n",
      "        -0.0995, -0.1199,  0.0125, -0.2185,  0.1078, -0.1231, -0.0380,  0.0361],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "-------------------------------\n",
      "emb.weight\n",
      "Parameter containing:\n",
      "tensor([[ 1.3883, -0.2476,  0.2552,  ...,  0.0677,  1.3257,  0.8114],\n",
      "        [ 0.9807,  0.1526, -1.8136,  ...,  0.6633, -0.0154, -0.6805],\n",
      "        [ 0.3834,  0.5871,  0.6329,  ..., -0.4487, -0.6847, -0.9418],\n",
      "        ...,\n",
      "        [ 0.1919,  0.3474,  0.2540,  ..., -0.6307, -0.4799, -0.8840],\n",
      "        [ 2.1452,  2.5686, -1.2354,  ..., -0.9120,  0.0647, -0.4639],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "-------------------------------\n",
      "gnn1.conv_layers.0.bias\n",
      "Parameter containing:\n",
      "tensor([ 0.5441, -0.1274, -0.1475, -0.4997, -0.4888, -0.0689, -0.3399,  0.3190,\n",
      "         0.5074, -0.2753,  0.3389,  0.0077,  0.0586,  0.2971, -0.1631,  0.0267,\n",
      "         0.1173,  0.4981, -0.1609, -0.1802, -0.1079, -0.1175, -0.2100, -0.3297,\n",
      "        -0.1085, -0.1109, -0.2616, -0.1254, -0.0560, -0.1336, -0.2538, -0.2216],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "-------------------------------\n",
      "gnn1.conv_layers.0.lin.weight\n",
      "Parameter containing:\n",
      "tensor([[-0.4466,  0.4065,  0.0035,  ...,  0.5093, -0.4217,  0.0915],\n",
      "        [-0.0064, -0.1379, -0.0519,  ...,  0.0722,  0.0545, -0.0437],\n",
      "        [ 0.0424, -0.1487,  0.1261,  ...,  0.1432, -0.1890, -0.0656],\n",
      "        ...,\n",
      "        [-0.0705, -0.1115, -0.0318,  ..., -0.2117,  0.1170,  0.0540],\n",
      "        [-0.0931, -0.2549, -0.0538,  ..., -0.2058, -0.0356, -0.0648],\n",
      "        [-0.0227, -0.2483,  0.0834,  ..., -0.0328, -0.0831,  0.0098]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "-------------------------------\n",
      "gnn1.conv_layers.1.bias\n",
      "Parameter containing:\n",
      "tensor([ 0.1233, -0.0169,  0.1635, -0.1489,  0.5826,  0.3853,  0.1361,  0.3700,\n",
      "        -0.2920,  0.5914, -0.2081, -0.1823,  0.6995, -0.0983, -0.5176,  0.4321],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "-------------------------------\n",
      "gnn1.conv_layers.1.lin.weight\n",
      "Parameter containing:\n",
      "tensor([[ 7.3921e-01,  8.0401e-02,  9.6164e-02,  1.1693e-01,  1.3898e-01,\n",
      "          6.3826e-03, -6.9148e-01,  1.1934e-01, -5.0701e-01, -2.8391e-01,\n",
      "         -2.2284e-01,  7.6438e-01,  2.2994e-01, -3.7407e-02,  1.1986e-02,\n",
      "         -1.0656e+00,  1.2273e-01,  5.4770e-01,  3.7333e-02, -6.9717e-01,\n",
      "          4.1120e-01, -1.3894e-01, -5.9927e-02, -2.4676e-01, -2.2908e-02,\n",
      "          5.6574e-02,  4.8334e-03, -3.3861e-01,  1.4285e-02,  2.7301e-01,\n",
      "         -1.4235e-01,  1.6461e-01],\n",
      "        [-3.1438e-01, -1.2534e-03, -1.7082e-01,  2.1349e-01,  3.8756e-01,\n",
      "          1.8046e-01,  5.2254e-01, -9.0496e-01,  6.9896e-02, -4.0174e-01,\n",
      "         -7.5096e-01, -5.2385e-01, -7.5786e-01, -2.8049e-01, -3.9442e-02,\n",
      "         -1.7875e-01,  1.8550e-01, -5.3546e-01,  4.2984e-02,  3.8160e-02,\n",
      "          2.9358e-01,  2.2427e-02,  1.1793e-01, -9.1235e-02, -5.4997e-02,\n",
      "         -8.9063e-03,  2.8496e-02, -5.4827e-01, -3.0733e-01,  2.1823e-02,\n",
      "         -1.0311e-01, -3.5284e-01],\n",
      "        [ 5.3410e-01,  1.0988e-01, -7.8121e-02, -9.5150e-02, -3.2056e-01,\n",
      "          4.6414e-01, -6.9486e-01, -4.6801e-01, -1.8812e-01, -5.8711e-01,\n",
      "          5.1962e-02, -4.8314e-02,  4.6894e-01,  2.1914e-01,  1.4755e-01,\n",
      "         -7.6775e-01,  2.8849e-01,  1.6976e-01,  1.0807e-03, -1.3989e-01,\n",
      "         -5.0066e-01,  3.1179e-01, -1.7903e-01,  2.1936e-01,  1.7926e-01,\n",
      "         -5.7948e-02, -8.8341e-01,  1.2146e-01, -1.7712e-01, -3.3401e-01,\n",
      "         -3.0706e-01,  1.2551e-01],\n",
      "        [-1.2444e-01,  1.2966e-02, -6.3857e-03, -1.5710e-01, -5.8005e-02,\n",
      "          5.2317e-01,  1.2413e+00,  3.0412e-01,  4.6664e-02, -7.1508e-01,\n",
      "         -1.2153e+00,  1.2942e-01,  1.0146e-01,  7.4320e-01, -1.1575e-02,\n",
      "          7.0565e-01, -1.9180e-01, -1.8311e-01, -1.9737e-01,  4.3902e-03,\n",
      "          4.2647e-01, -1.9779e-01,  3.4778e-01, -3.0305e-01,  2.1429e-01,\n",
      "         -2.6387e-01,  1.4194e-01,  5.4740e-02,  2.4337e-01, -3.8748e-01,\n",
      "         -3.5865e-01, -8.3631e-02],\n",
      "        [-9.2405e-01,  2.5304e-01, -7.8717e-01, -1.9408e-01, -2.7146e-01,\n",
      "          7.2615e-01, -1.7634e-02,  4.5332e-01,  7.5086e-01, -4.9932e-02,\n",
      "          5.6883e-01,  6.7197e-02,  1.1808e-01,  1.3903e+00,  1.0486e-01,\n",
      "          6.7873e-01, -1.5941e-01,  2.2898e-01,  9.2052e-02,  3.9204e-02,\n",
      "         -4.9808e-01, -7.9412e-01, -8.3409e-02,  3.0720e-01, -4.1524e-01,\n",
      "         -4.8868e-01,  1.3480e-01,  5.1590e-01,  1.2041e-01,  7.8341e-02,\n",
      "         -1.2316e+00,  6.1848e-01],\n",
      "        [-2.3583e-01,  2.1048e-02, -3.3259e-01, -3.6816e-01, -6.0172e-01,\n",
      "         -7.8807e-02, -2.2836e-01, -5.4527e-01, -3.3877e-01,  4.4693e-01,\n",
      "          2.5042e-01,  3.9363e-01, -4.1039e-01,  3.7507e-01,  3.5463e-01,\n",
      "          2.0908e-02, -6.4072e-02, -7.3465e-01,  2.1023e-01, -1.7326e-01,\n",
      "          4.5816e-01, -1.0050e-02, -3.1551e-01,  9.9883e-02, -3.8217e-01,\n",
      "          1.4265e-01, -3.1443e-01,  2.6369e-01, -2.1878e-01,  2.5075e-02,\n",
      "         -5.6756e-01, -3.1671e-02],\n",
      "        [ 1.7057e-01,  2.7290e-01, -2.3076e-02, -3.9421e-01, -1.6960e-01,\n",
      "         -7.3303e-01, -1.2720e-01,  5.8756e-01, -3.7053e-01, -9.7661e-02,\n",
      "          3.9390e-01,  1.1233e-01,  6.7292e-01, -5.9117e-01,  4.6522e-02,\n",
      "          2.8442e-01, -3.0212e-01,  9.2882e-01,  9.4795e-02, -7.0662e-03,\n",
      "          1.0163e-01,  1.1804e-02,  8.5922e-02,  1.9429e-01,  4.6548e-01,\n",
      "          3.0269e-01, -1.9104e-02,  3.8762e-02,  4.7291e-01, -1.4614e-01,\n",
      "         -8.0415e-01, -2.9605e-01],\n",
      "        [ 6.1876e-02, -1.6840e-01, -2.2839e-01, -1.3887e-01, -4.5198e-01,\n",
      "         -1.6684e-01, -8.4442e-01,  3.4723e-01,  1.0119e+00, -1.6111e-01,\n",
      "          4.8938e-01,  5.9156e-01, -4.1512e-01,  3.7937e-01,  1.0729e-01,\n",
      "         -3.9997e-03,  1.8248e-01, -2.0140e-01,  1.2980e-01,  1.5706e-01,\n",
      "          3.7435e-01,  2.2827e-01,  2.8964e-02, -4.5516e-01,  6.9291e-02,\n",
      "          5.8693e-02, -3.4499e-01,  1.2686e-01, -1.7155e-01, -2.9165e-01,\n",
      "         -3.6574e-01, -1.4634e-01],\n",
      "        [-4.0153e-01,  3.2781e-02,  1.8573e-01,  2.0838e-01,  2.0269e-01,\n",
      "         -2.6713e-01,  2.9838e-01,  2.6424e-01, -1.9162e-01,  2.5566e-01,\n",
      "         -2.0159e-02, -8.5471e-02, -5.5143e-01, -9.4743e-02,  2.6616e-02,\n",
      "         -5.8740e-02,  1.7138e-01, -2.8301e-01,  3.8936e-01,  3.2664e-01,\n",
      "         -5.9603e-01, -3.6817e-01,  6.2874e-01, -1.2849e-01,  3.3062e-01,\n",
      "          2.7393e-02, -3.0209e-03, -5.3183e-01,  2.2083e-01, -3.2471e-02,\n",
      "          4.0492e-01,  4.3657e-02],\n",
      "        [ 8.2157e-01, -2.7043e-01,  2.6510e-01, -4.6901e-01, -9.8083e-02,\n",
      "         -7.3689e-01,  4.7363e-01, -2.3882e-01, -4.1060e-01, -8.7061e-01,\n",
      "          4.1374e-01,  8.7309e-02,  1.6094e+00,  3.6719e-01,  3.2503e-01,\n",
      "          4.3061e-01,  6.4321e-02,  5.6568e-01, -3.8736e-02, -1.6703e-01,\n",
      "          4.2640e-01, -6.9404e-02,  3.7649e-02, -7.7603e-01,  1.3478e-01,\n",
      "          4.1300e-01, -1.9609e-02, -4.9909e-01, -2.6725e-01, -6.3644e-01,\n",
      "          2.4992e-01,  2.0277e-01],\n",
      "        [-8.4024e-01,  5.3046e-01,  3.9287e-01,  4.3172e-01,  7.3997e-01,\n",
      "         -5.2995e-02, -3.3013e-01, -5.5084e-01, -4.0505e-01,  3.2961e-01,\n",
      "         -1.6189e-02,  1.1099e-02, -1.1275e-02, -2.1415e-01, -2.8096e-01,\n",
      "         -3.8652e-01, -4.3742e-01, -4.6430e-01,  3.9010e-01, -2.2658e-01,\n",
      "          4.1866e-01,  4.0546e-01,  2.7533e-02,  5.0999e-03,  6.0381e-02,\n",
      "         -4.5789e-02,  4.1080e-01,  2.9327e-01,  9.4750e-02,  4.1408e-01,\n",
      "         -5.2894e-02, -6.4483e-02],\n",
      "        [-7.3119e-01,  6.1150e-01, -1.4466e-01, -1.5383e-01,  1.3399e-01,\n",
      "          1.3235e-01, -2.7404e-01, -1.0855e-01, -1.0212e-02,  8.9526e-02,\n",
      "         -1.1046e-01, -1.0031e-01, -3.8588e-01, -1.6469e-01,  3.6727e-01,\n",
      "          3.6447e-01, -5.5739e-01, -2.4321e-01,  4.7274e-01,  3.2179e-01,\n",
      "         -1.7262e-02,  3.1529e-01, -7.0030e-02, -1.2462e-01,  8.9234e-02,\n",
      "         -4.7253e-01, -1.1153e-01,  1.7551e-01, -3.9048e-02,  2.5306e-01,\n",
      "          5.6928e-01, -2.4578e-01],\n",
      "        [ 8.0437e-01, -9.2954e-02,  4.1268e-01, -4.6578e-01, -6.1967e-01,\n",
      "          4.0767e-01, -7.6498e-01,  1.4203e-01, -8.2897e-01, -5.1009e-02,\n",
      "          7.2960e-01,  5.8776e-01, -1.7380e-01,  1.1502e-01,  6.7406e-01,\n",
      "          2.3651e-01, -6.1886e-01,  4.5150e-01, -1.5652e-01, -3.6491e-01,\n",
      "          9.0476e-02, -1.0695e-01,  4.7374e-02, -8.4202e-01, -1.8955e-01,\n",
      "          2.0913e-01, -1.5924e-01,  3.4488e-01, -5.6288e-01,  4.2617e-01,\n",
      "         -5.1843e-01, -4.7687e-01],\n",
      "        [-6.8575e-01, -3.3798e-01,  3.5201e-01,  2.5897e-01,  7.0069e-01,\n",
      "         -2.4845e-01, -4.6252e-01,  1.5202e-02,  1.0093e-01, -3.0437e-01,\n",
      "         -3.0089e-01,  2.2790e-01,  4.0066e-01, -7.0134e-01,  3.5317e-01,\n",
      "         -3.1751e-01, -4.2075e-01, -2.6534e-01, -2.5954e-01,  1.1831e-01,\n",
      "          1.3478e-01,  8.7379e-02,  2.1257e-01, -3.9364e-02, -9.6544e-02,\n",
      "          2.0458e-01, -2.7787e-01,  3.9646e-01,  2.2073e-02,  4.1133e-01,\n",
      "          3.1252e-01, -1.0575e-01],\n",
      "        [-5.8308e-01,  3.5799e-01, -1.8666e-01,  5.6790e-01,  5.9405e-01,\n",
      "          7.4410e-02,  3.2290e-01,  3.0347e-02, -2.1525e-01,  1.2404e-01,\n",
      "         -1.6584e-01, -1.8785e-01,  7.9124e-02, -2.2644e-02, -9.4682e-02,\n",
      "         -1.5852e-01, -5.3903e-01, -1.3294e-02, -4.6049e-01, -5.7145e-02,\n",
      "          1.4095e-01,  3.6689e-01, -9.8300e-02,  5.1437e-01, -1.2000e-01,\n",
      "          3.3197e-01,  4.3341e-01, -1.7449e-01,  7.0858e-02,  3.9673e-01,\n",
      "         -1.0381e-01,  2.0726e-01],\n",
      "        [ 3.3162e-01, -3.0670e-02,  4.7298e-01, -3.2833e-01, -4.2941e-01,\n",
      "         -5.2687e-02,  1.2486e-01,  3.0143e-01,  6.0602e-01, -9.2164e-02,\n",
      "         -1.0470e-01, -4.1246e-02,  1.8795e-01,  3.3252e-01, -1.5968e-01,\n",
      "          4.4555e-01,  4.1408e-01,  4.3781e-01, -2.0452e-01, -5.3779e-01,\n",
      "          2.9637e-01,  8.0916e-02, -2.2573e-01,  1.4666e-01,  2.2277e-01,\n",
      "          2.5888e-01,  3.2880e-01,  4.2204e-01, -2.1908e-01,  1.8281e-01,\n",
      "         -3.3814e-01, -6.2048e-02]], device='cuda:0', requires_grad=True)\n",
      "-------------------------------\n",
      "gnn1.fc.weight\n",
      "Parameter containing:\n",
      "tensor([[-0.1064,  0.2962, -0.3272,  ..., -0.3956, -0.3170, -0.1508],\n",
      "        [ 0.9978, -0.4023,  0.4464,  ...,  0.8097,  0.2290,  0.7378],\n",
      "        [ 0.3153,  0.4825,  0.2214,  ..., -0.6816, -0.1818, -0.3998],\n",
      "        ...,\n",
      "        [ 0.0703, -0.4657,  0.3266,  ...,  0.5410,  0.2019,  0.1017],\n",
      "        [ 0.4771, -0.0420,  0.0462,  ...,  0.5799,  0.3916,  0.8553],\n",
      "        [-0.9560,  0.2579, -0.8024,  ..., -0.4818, -0.1714, -0.1051]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "-------------------------------\n",
      "gnn1.fc.bias\n",
      "Parameter containing:\n",
      "tensor([-0.7023,  1.1815, -0.1078, -0.8061, -0.9809,  0.7810, -0.8642,  0.5309,\n",
      "        -0.6369, -0.7501, -1.1043,  0.8739,  1.0900, -0.4616, -0.5669,  0.3186,\n",
      "        -0.7688, -0.7973,  0.4743, -0.9323,  0.5012,  0.7883,  0.8277,  1.2310,\n",
      "        -0.2681, -0.9026, -0.9564, -1.1321,  0.6872, -0.5526,  0.8992,  0.3645,\n",
      "         1.1683,  0.0391,  0.4344,  0.7071,  1.0174, -0.2470, -0.2350,  1.2544,\n",
      "         1.0752, -0.5351, -0.8249,  0.1025, -1.0000,  0.7567, -0.0823,  0.9115,\n",
      "        -0.8844, -1.1307, -0.2747,  1.0337, -0.3057, -0.2038, -0.8634,  0.0143,\n",
      "        -0.1332,  0.1362, -1.2955,  0.0729,  0.7164,  0.1887,  1.0691, -1.0793,\n",
      "        -0.9462,  0.4907, -1.0461, -0.0207, -0.0240, -1.1488, -0.2316, -0.3733,\n",
      "         1.1496, -0.3541,  1.3116,  0.9499,  0.3051,  1.1903,  1.0704,  0.3213,\n",
      "         1.0663,  1.2076, -0.1685, -0.3426, -0.5818,  0.9503,  0.0073,  1.1203,\n",
      "        -0.2388, -1.1148,  0.6065,  1.2007, -1.0847,  0.8537, -0.8612,  0.5284,\n",
      "        -1.1078, -0.3410, -0.6514, -0.0244, -0.2146,  0.1123,  1.1676, -0.3575,\n",
      "         0.2509, -0.2274,  1.2607,  0.7228, -0.5290,  0.2984, -0.6631,  1.0738,\n",
      "        -0.9819, -0.3958, -1.0216,  1.0779,  1.0361, -0.6915, -1.2223,  0.2516,\n",
      "        -0.3212, -0.0713, -1.1425,  1.0181, -0.9296,  1.0690,  0.8284,  0.4948,\n",
      "         0.3514,  1.1076, -0.3578, -1.2282,  0.1246, -0.5595, -0.8207,  0.8973,\n",
      "        -1.1182, -0.5864,  0.8748, -1.0259, -1.0594,  1.4473, -0.7118,  1.2396,\n",
      "         0.7008, -1.1005, -1.1558,  0.3217, -1.0287, -0.5701, -0.9272,  0.8116,\n",
      "        -0.8085, -1.0745, -0.6993,  0.3177,  0.7717,  1.1465,  0.4921, -1.0654,\n",
      "         0.5786,  1.0215, -0.3902, -0.3084,  0.4012,  0.8240,  0.7950,  0.0429,\n",
      "         0.9325, -0.3478, -0.6936, -1.1162,  0.2040, -0.7625, -0.6748, -0.9757,\n",
      "         0.9549, -0.6335, -0.4210,  0.3681, -1.2235, -0.0813,  0.9789,  0.4709,\n",
      "         0.3142,  0.9618, -1.1668, -0.3990, -0.6927, -0.2475, -0.5967, -0.0323,\n",
      "        -1.3840, -0.4390,  0.9897, -0.4532,  0.0347,  1.0354,  0.3468, -0.5152,\n",
      "         0.1966, -0.9089,  0.4954, -0.2926,  0.2632,  0.5749,  1.2561,  0.2433,\n",
      "        -1.0133, -0.2028, -0.7793,  0.9249,  0.6451,  0.7144, -1.2462,  0.8937,\n",
      "        -0.4239, -0.5879,  0.6967, -0.9288,  0.1840,  0.7685,  1.0562, -0.9185,\n",
      "         0.8358,  0.5376, -0.5155, -0.7643, -0.1695,  0.9768,  0.6628, -0.9565,\n",
      "        -0.6946, -0.0896, -0.6892, -0.5825, -0.7528, -0.2073, -0.8556,  1.0792,\n",
      "        -0.3676,  0.5349, -1.3648, -0.9261, -0.2224, -0.9374,  1.1752,  0.8268,\n",
      "        -0.1246,  1.2488, -1.0189, -0.7420, -1.0354,  0.6445,  1.1519, -1.1535],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "-------------------------------\n",
      "gnn2.conv_layers.0.bias\n",
      "Parameter containing:\n",
      "tensor([-0.0102, -0.3104, -0.5485,  0.2883,  0.3019, -0.1584,  0.2408, -0.0989,\n",
      "        -0.3101, -0.1753,  0.0107, -0.0576, -0.3922,  0.2328, -0.1584, -0.3833,\n",
      "        -0.0864,  0.1109,  0.0148,  0.0598, -0.0970, -0.0696, -0.2963,  0.5353,\n",
      "         0.2232, -0.0517,  0.3256, -0.4224,  0.6543,  0.0842, -0.0437,  0.5710],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "-------------------------------\n",
      "gnn2.conv_layers.0.lin.weight\n",
      "Parameter containing:\n",
      "tensor([[-0.1119,  0.0838, -0.0553,  ..., -0.1337,  0.1118,  0.0619],\n",
      "        [ 0.0711, -0.0511,  0.0706,  ..., -0.3241,  0.0039, -0.0214],\n",
      "        [ 0.0759, -0.3520,  0.0436,  ..., -0.4673, -0.1424, -0.0383],\n",
      "        ...,\n",
      "        [-0.0172,  0.1116,  0.2687,  ..., -0.1738, -0.3364,  0.1284],\n",
      "        [-0.0090, -0.1130, -0.0050,  ..., -0.1676, -0.0659,  0.0365],\n",
      "        [-0.0339,  0.4728, -0.1446,  ...,  0.1696,  0.1208, -0.2909]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "-------------------------------\n",
      "gnn2.conv_layers.1.bias\n",
      "Parameter containing:\n",
      "tensor([ 0.5463,  0.5400,  0.5544,  0.2902,  0.1476,  0.4939,  0.1654,  0.3490,\n",
      "        -0.0466, -0.8971,  0.1531,  0.6859,  0.0596, -0.0267,  0.1256,  0.4700],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "-------------------------------\n",
      "gnn2.conv_layers.1.lin.weight\n",
      "Parameter containing:\n",
      "tensor([[-0.2235, -0.6867, -0.1929,  0.0767, -0.0764,  0.3934,  0.0916,  0.1956,\n",
      "         -0.0283, -0.4496,  0.1442, -0.0199, -0.4729,  0.6508,  0.1557, -0.0843,\n",
      "         -0.2487,  0.4308,  0.0757,  0.2187,  0.0667,  0.2623, -0.0109,  0.6746,\n",
      "          0.3793, -0.2479, -0.3359, -0.3107,  0.6695,  0.1538, -0.1364,  0.9170],\n",
      "        [-0.6231, -0.3667, -0.7027,  0.6584,  0.4733, -0.1660,  0.3865,  0.2890,\n",
      "          0.2214, -0.5281,  0.4626,  0.0017,  0.0270,  0.4602,  0.1847, -0.0292,\n",
      "          0.1465,  0.6901, -0.2819,  0.0666, -0.1126, -0.2672, -0.3673,  0.5875,\n",
      "          0.3291,  0.4715, -0.2594, -0.5730,  0.9647,  0.6235, -0.1517,  0.2309],\n",
      "        [ 0.1225, -0.6120, -0.2029, -0.3044,  0.6083, -0.5015,  0.5416, -0.0607,\n",
      "         -0.3337, -0.0249, -0.2140,  0.0481, -0.6107, -0.2858,  0.3610, -0.7882,\n",
      "          0.1526, -0.1865,  0.1011,  0.3991,  0.0245,  0.0569,  0.3813,  0.8047,\n",
      "          0.3374,  0.1274,  0.3006,  0.2851,  0.1353,  0.5050,  0.1872,  0.3250],\n",
      "        [-0.0089, -0.0941, -0.6629, -0.0861, -0.0971, -0.2617,  0.2623,  0.0619,\n",
      "         -0.5009, -0.1647, -0.1535, -0.3790, -0.5948,  0.8536,  0.2087, -0.2673,\n",
      "          0.2304,  0.0558, -0.0079,  0.1903,  0.1556, -0.1829, -0.2155,  0.2643,\n",
      "          0.0479, -0.4908,  0.1057,  0.2144,  0.2174, -0.1950, -0.0293,  0.3371],\n",
      "        [ 0.0027,  1.1596, -0.4855, -0.1180,  0.1789,  0.3018,  0.1931, -0.0414,\n",
      "         -0.1532, -0.2116, -0.1093,  0.0858, -0.2035, -0.4662,  0.0366,  0.0318,\n",
      "          0.1873, -0.1955,  0.5462,  0.3261, -0.3696,  0.3223,  0.9804, -0.0914,\n",
      "          0.0578,  0.3459, -0.1140, -0.2424, -0.0118, -0.1439, -0.2736, -0.0670],\n",
      "        [-0.4688, -0.4913, -0.4928, -0.3532,  0.5094, -0.2200,  0.1303,  0.3163,\n",
      "         -0.4019, -0.1632,  0.5627, -0.1751,  0.0752, -0.5150,  0.0666,  0.1598,\n",
      "         -0.0515,  0.1953,  0.2379,  0.5696, -0.1376,  0.1404, -0.2303,  0.8909,\n",
      "          0.1834,  0.2641,  0.0748, -0.4712,  0.0104,  0.4082,  0.2129, -0.1765],\n",
      "        [ 0.2689,  0.5670, -0.2247, -0.8134,  0.0790,  0.1348,  0.3594, -0.0479,\n",
      "          0.0780, -0.1445, -0.0386,  0.0446,  0.3932,  0.3037,  0.3028,  0.2052,\n",
      "          0.1518,  0.2603,  0.4496, -0.0331, -0.1249,  0.3753,  0.8547,  0.0190,\n",
      "          0.5305,  0.0622, -0.2628,  0.2177,  0.6714, -0.2774,  0.0042,  0.4436],\n",
      "        [ 0.1545, -0.0907, -0.2247,  0.6788, -0.1693, -0.4179, -0.0947,  0.0439,\n",
      "         -0.0405, -0.2305,  0.4907, -0.2081,  0.0685, -0.1567,  0.1528,  0.1032,\n",
      "         -0.0374, -0.1646,  0.3466,  0.3093,  0.0052, -0.5203, -0.9581,  0.5152,\n",
      "          0.4134,  0.3861, -0.0645, -0.5052,  0.6806,  0.2870,  0.0895,  0.5474],\n",
      "        [ 0.0554, -0.1809,  0.2441,  0.3881, -0.3747, -0.1387, -0.5361,  0.5468,\n",
      "          0.4496,  0.3705, -0.1790, -0.3553,  0.2834, -0.6659,  0.3552,  0.9214,\n",
      "         -0.3634, -0.2639,  0.0677, -0.4106,  0.2269,  0.0928, -0.0362, -0.5435,\n",
      "         -0.0737, -0.2914, -0.1705,  0.4275, -0.2847,  0.1498, -0.0673, -0.2049],\n",
      "        [ 0.1889, -0.3995,  0.7274, -0.5491, -0.8916,  0.0621, -0.4937,  0.0454,\n",
      "          0.5062,  0.5137, -0.6742,  0.4222,  0.5791, -0.1859, -0.1490,  0.3980,\n",
      "          0.1159, -0.8124,  0.1342, -0.4144, -0.1957,  0.4102,  0.2363, -0.2819,\n",
      "         -0.7002, -0.5877, -0.9785,  0.1257, -0.8988, -0.2274,  0.1322, -0.9812],\n",
      "        [-0.2481,  0.5666, -0.4655,  0.3611,  0.5921, -0.1823, -0.0103,  0.0097,\n",
      "          0.0654, -0.3198,  0.5059,  0.2258, -0.4006,  0.2318, -0.3425, -0.1049,\n",
      "         -0.0813,  0.0995,  0.2562,  0.1850,  0.3046, -0.1079,  0.0370,  0.1975,\n",
      "         -0.1983,  0.5319,  0.3066, -0.4497,  0.7398,  0.7553,  0.0532,  0.4999],\n",
      "        [ 0.0726,  0.7510, -0.0933,  0.8084,  0.2991,  0.0363, -0.2196,  0.0172,\n",
      "         -0.4434, -0.0523,  0.7666,  0.0748, -0.3009,  0.7618, -0.3667,  0.3167,\n",
      "         -0.1837,  0.5855, -0.2107, -0.2402,  0.0531, -0.6733,  0.3704, -0.1461,\n",
      "          0.1364,  0.0081,  0.7596,  0.1141,  0.0372,  0.3886, -0.0410,  0.0630],\n",
      "        [ 0.0482, -0.3885, -0.3766, -0.1060,  0.0252,  0.1004,  0.1220, -0.3770,\n",
      "         -0.1971,  0.1313, -0.0941,  0.0987, -0.0788,  0.3919, -0.2745,  0.0404,\n",
      "          0.0077, -0.1493, -0.1070,  0.2752,  0.1739, -0.0381, -0.2168,  0.4356,\n",
      "         -0.0411,  0.2082,  0.1630, -0.0444, -0.1252,  0.1560,  0.3133, -0.5056],\n",
      "        [ 0.1271,  0.8257, -0.2687,  1.0485, -0.5115, -0.0501,  0.1657, -0.3224,\n",
      "         -0.1465, -0.3315,  0.6679,  0.1018,  0.4397,  0.6217,  0.0331,  0.3825,\n",
      "          0.2766,  0.6672, -0.2471,  0.1793,  0.2888, -0.2465,  0.3755,  0.1595,\n",
      "          0.1034,  0.6843,  0.4921,  0.1939,  0.3118,  0.2058, -0.0428,  0.1315],\n",
      "        [ 0.0262,  0.6921, -0.1897,  0.4652, -0.0588,  0.3750,  0.2586,  0.3346,\n",
      "          0.1408, -0.2942,  0.3591, -0.0656, -0.2354,  0.0525, -0.0411,  0.0562,\n",
      "          0.0069,  0.1715,  0.0834,  0.0015,  0.2997, -0.1435, -0.9134, -0.5693,\n",
      "          0.1289,  0.2284,  0.6581, -0.3155,  0.0291, -0.0026,  0.0297,  0.1823],\n",
      "        [-0.3215,  0.2827, -0.5146,  0.3008,  0.5579, -0.3981,  0.2943, -0.2774,\n",
      "         -0.7577, -0.3647,  0.1689, -0.0705, -0.0220,  0.2707,  0.1463, -0.2412,\n",
      "          0.1300, -0.1850,  0.0993, -0.0301, -0.2373, -0.0654,  0.1928,  0.3566,\n",
      "          0.5878,  0.1296,  0.0462,  0.7118,  0.3582,  0.1392, -0.0185,  0.6559]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "-------------------------------\n",
      "gnn2.fc.weight\n",
      "Parameter containing:\n",
      "tensor([[ 0.1463,  0.4287,  0.2541,  ...,  0.2745,  0.5243,  0.3838],\n",
      "        [-0.2409,  0.4722, -0.2256,  ...,  0.0698, -0.1756, -0.1870],\n",
      "        [ 0.3017,  0.5774,  0.4062,  ...,  0.3612, -0.1063,  0.7724],\n",
      "        ...,\n",
      "        [-0.1013,  0.5692,  0.1426,  ..., -0.0602,  0.3718,  0.3449],\n",
      "        [-0.2374,  0.1008, -0.1240,  ...,  0.6580,  0.0740, -0.2790],\n",
      "        [ 1.3020, -0.1483,  0.2375,  ..., -0.1191,  0.1316,  0.2747]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "-------------------------------\n",
      "gnn2.fc.bias\n",
      "Parameter containing:\n",
      "tensor([ 0.7882, -0.5010,  0.7903, -0.9203,  0.6709, -0.4509,  0.3515, -0.5696,\n",
      "        -0.0698, -0.7095, -0.6467, -0.0503,  0.0945,  0.3374,  0.5029, -0.5748,\n",
      "         0.4472,  0.2304, -0.1627, -0.3186,  0.0789, -0.4571, -0.3773, -0.5781,\n",
      "         0.3302,  0.7970, -0.8291,  0.5960, -0.2905, -0.9114, -0.2340, -0.4417,\n",
      "         0.2723,  0.1792, -0.6635,  0.5172, -0.1899, -0.3979, -0.8748, -0.2451,\n",
      "        -0.7158, -0.2374,  1.1261,  0.6840,  0.2881, -1.0622, -0.8555, -0.7131,\n",
      "         0.5469,  0.2954,  0.4535, -0.8714, -0.5062, -0.2041,  0.0074,  0.0644,\n",
      "        -0.7144,  0.7008,  0.0674,  0.6932, -0.1033,  0.4651,  0.1696, -0.6199,\n",
      "         0.0666, -0.9705, -0.0610,  0.0751,  0.0155, -0.0780, -0.1213,  0.8255,\n",
      "         0.4003, -0.3076,  0.1982, -0.3000,  0.6925,  0.4545, -1.2923, -0.1445,\n",
      "        -0.1369, -0.2045,  0.3756,  0.2778, -0.5555,  0.1145,  0.1808,  0.0787,\n",
      "        -0.1328,  0.3823,  0.0104, -0.2688, -0.0730, -0.8822, -0.9866, -0.4080,\n",
      "         0.4337,  0.8011,  0.3413, -0.6517,  0.7027,  0.0775,  0.1532,  0.9083,\n",
      "        -0.0357,  0.0506,  0.0565, -1.0595,  0.7072, -0.6130, -0.0427, -0.0788,\n",
      "         0.4260, -0.2049, -0.4570,  0.3553, -0.8535,  0.5084,  0.7215, -0.9409,\n",
      "        -0.1032, -0.0127,  0.3155, -0.3391, -0.2342,  0.2422,  0.0806,  0.5726,\n",
      "         1.1783, -0.7011, -0.4750, -0.0980,  0.2849,  0.7419, -0.6136,  0.5467,\n",
      "        -0.9184,  0.1571, -0.2247,  0.2987, -0.6629, -0.2866,  0.5681,  0.7717,\n",
      "        -0.7728,  0.3835, -0.5309,  0.6086, -0.8343,  1.0280, -0.2782, -0.4467,\n",
      "        -0.7134,  0.5926,  0.7573, -0.9834,  0.0116,  0.8468,  0.0309, -0.6695,\n",
      "        -0.4306, -0.5217,  0.3820, -0.2085, -0.4588, -0.7366, -1.0942,  0.5045,\n",
      "         0.2449, -0.2326,  0.1080,  0.0882, -0.4261, -1.0122, -0.8513,  0.7432,\n",
      "        -0.0239, -0.1760, -0.4007, -0.7551, -0.0533, -0.9701,  0.7239,  0.6732,\n",
      "        -0.6721, -0.8826, -0.7767, -0.4541, -0.8488,  1.0828, -0.5917,  0.5810,\n",
      "        -0.1705, -0.3379, -0.9868,  0.3830, -0.3016, -0.8597,  0.1488,  0.8109,\n",
      "         0.2762,  0.0997,  0.3144,  0.8267, -0.6648,  0.0891,  0.1148, -0.1116,\n",
      "         0.3255, -0.1345, -0.2147,  0.6278,  0.0660, -0.2416,  0.8588,  0.1933,\n",
      "        -0.8647, -0.6891,  0.4494, -0.9824, -0.6773, -0.2861,  0.5387, -0.2941,\n",
      "        -0.6240, -0.2897, -0.9136, -0.6600,  0.3815, -0.3442, -0.1473,  0.0904,\n",
      "         0.7170,  0.4727, -0.0598, -0.9010,  0.2840, -1.1188, -0.7967, -0.3165,\n",
      "        -1.1147, -0.9466,  0.6604, -0.1414, -0.1254,  0.5244, -0.3148, -0.1995,\n",
      "         0.9489, -0.9266,  0.1185,  0.3734,  0.5310,  0.7773, -0.2408,  0.4115],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "-------------------------------\n",
      "proj1.weight\n",
      "Parameter containing:\n",
      "tensor([[ 4.5760e-02,  4.8801e-01,  3.1782e-01,  ...,  8.0846e-02,\n",
      "          6.6251e-01, -4.7957e-01],\n",
      "        [-3.4596e-02,  1.4466e-01, -1.8671e-01,  ...,  1.1147e-01,\n",
      "          6.2014e-04, -9.8989e-02],\n",
      "        [-2.7205e-01,  1.8229e-01, -4.5828e-01,  ...,  3.9012e-01,\n",
      "          2.4586e-01, -2.7259e-01],\n",
      "        ...,\n",
      "        [ 1.6469e-01, -2.1368e-01,  1.9211e-02,  ..., -1.4138e-01,\n",
      "         -3.6903e-01,  4.0359e-01],\n",
      "        [-1.4727e-01,  9.0504e-02,  2.1084e-01,  ..., -1.0173e-01,\n",
      "          6.3406e-02, -8.3213e-02],\n",
      "        [ 1.7318e-01, -5.3789e-01,  5.2336e-02,  ..., -2.8605e-01,\n",
      "         -5.1493e-01,  3.4842e-01]], device='cuda:0', requires_grad=True)\n",
      "-------------------------------\n",
      "proj1.bias\n",
      "Parameter containing:\n",
      "tensor([-0.0789,  0.0889, -0.1082,  0.2069, -0.5000,  0.3899, -0.1283,  0.0698,\n",
      "         0.1194, -0.0023,  0.1444, -0.0649,  0.2412,  0.1280, -0.2157, -0.2025,\n",
      "        -0.1302, -0.0395, -0.1928, -0.0524, -0.2362,  0.1913, -0.0063,  0.0082,\n",
      "         0.2039, -0.1182,  0.2523, -0.0773, -0.0634,  0.0824, -0.0998,  0.2354,\n",
      "        -0.0906, -0.5385, -0.0650,  0.4495, -0.0438,  0.0341, -0.0055, -0.0316,\n",
      "        -0.0628,  0.4567, -0.1927,  0.0079, -0.5325,  0.0654,  0.1512, -0.5025,\n",
      "        -0.3303,  0.3064, -0.0063, -0.1617, -0.2007,  0.1490,  0.6615,  0.0705,\n",
      "         0.0671,  0.5099, -0.0169,  0.0369,  0.3357,  0.1490, -0.3808, -0.2668,\n",
      "        -0.5718,  0.3305,  0.0984,  0.5039, -0.0631,  0.2193, -0.2788,  0.0600,\n",
      "         0.0788,  0.1685, -0.5232,  0.4273, -0.1328, -0.4416,  0.3246,  0.4846,\n",
      "         0.1573,  0.0511,  0.0717,  0.1505,  0.2790,  0.0115, -0.0915,  0.1695,\n",
      "        -0.0152,  0.0253, -0.3489,  0.2593, -0.1958,  0.5785, -0.1897, -0.3454,\n",
      "         0.4615,  0.2618, -0.0011, -0.0885, -0.2240, -0.2613, -0.1300,  0.0249,\n",
      "         0.3028, -0.4549, -0.1527,  0.1287,  0.1462,  0.1627,  0.0809,  0.0219,\n",
      "        -0.1548, -0.4771,  0.0968, -0.1150,  0.2620,  0.4633, -0.3386,  0.2218,\n",
      "         0.1212,  0.1081,  0.0322, -0.2934,  0.3293,  0.1133,  0.2405, -0.2545],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "-------------------------------\n",
      "proj2.weight\n",
      "Parameter containing:\n",
      "tensor([[-0.0547,  0.2844, -0.1060,  ...,  0.4392, -0.3766, -0.3543],\n",
      "        [-0.3732,  0.4399, -0.2347,  ..., -0.2817,  0.4706,  0.2185],\n",
      "        [-0.1250,  0.3518,  0.1051,  ...,  0.2819,  0.3706,  0.1217],\n",
      "        ...,\n",
      "        [ 0.2112, -0.1865,  0.3260,  ..., -0.1132, -0.4230,  0.6240],\n",
      "        [ 0.1064, -0.0530,  0.4326,  ...,  0.0922,  0.1676, -0.0169],\n",
      "        [ 0.2073, -0.0050,  0.0122,  ...,  0.0203, -0.1315, -0.0179]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "-------------------------------\n",
      "proj2.bias\n",
      "Parameter containing:\n",
      "tensor([ 0.1683,  0.3906,  0.0989,  0.1243, -0.1731, -0.1579, -0.2089, -0.3262,\n",
      "        -0.0661,  0.0844,  0.2367, -0.1594,  0.5942, -0.3155,  0.3276,  0.0221,\n",
      "         0.2790, -0.0321,  0.0522, -0.0699,  0.3179,  0.0517, -0.2821, -0.2514,\n",
      "         0.3218, -0.3589, -0.4419,  0.1597, -0.5316, -0.2839, -0.4184, -0.0605,\n",
      "         0.8819, -0.0547, -0.0009,  0.2749,  0.3576,  0.1108,  0.1713,  0.0343,\n",
      "        -0.1748,  0.0752, -0.0723,  0.0528, -0.0366, -0.0654,  0.0748, -0.6833,\n",
      "        -0.0393,  0.0310,  0.0655,  0.0436,  0.6670, -0.7775,  0.0205, -0.1395,\n",
      "         0.0676, -0.0129,  0.0236,  0.1262, -0.1399, -0.0557,  0.5976,  0.3907,\n",
      "         0.3907,  0.6798,  0.0190,  0.4396, -0.2231,  0.3420, -0.0161,  0.3665,\n",
      "        -0.2217,  0.5018, -0.1292, -0.0268, -0.4221,  0.0520,  0.1223, -0.0200,\n",
      "         0.1126, -0.1226,  0.4391, -0.2058,  0.0009, -0.2181, -0.1360,  0.2733,\n",
      "        -0.2293, -0.0222,  0.0285,  0.0152,  0.5124,  0.0305,  0.6407, -0.1371,\n",
      "         0.4825, -0.0347, -0.1756,  0.1156, -0.2410,  0.0597,  0.1692, -0.0969,\n",
      "         0.1877, -0.0265, -0.1295,  0.0855,  0.1255, -0.0691, -0.1634,  0.4014,\n",
      "        -0.5000, -0.3459, -0.1511,  0.0457,  0.4392,  0.4446, -0.0183,  0.0011,\n",
      "        -0.6429,  0.8151,  0.0485, -0.2178, -0.0626, -0.1963,  0.2615,  0.0460],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "-------------------------------\n",
      "proj1_shortcut.weight\n",
      "Parameter containing:\n",
      "tensor([[-0.0569, -0.0005, -0.0118,  ...,  0.0571, -0.0561,  0.0337],\n",
      "        [-0.0464,  0.0616,  0.0624,  ...,  0.0064,  0.0471,  0.0274],\n",
      "        [ 0.0420, -0.0153,  0.0594,  ..., -0.0328,  0.0407,  0.0434],\n",
      "        ...,\n",
      "        [ 0.0044,  0.0270, -0.0335,  ..., -0.0386,  0.0110,  0.0527],\n",
      "        [ 0.0619,  0.0300, -0.0326,  ...,  0.0266, -0.0340, -0.0525],\n",
      "        [-0.0008,  0.0548, -0.0625,  ..., -0.0241, -0.0433, -0.0107]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "-------------------------------\n",
      "proj1_shortcut.bias\n",
      "Parameter containing:\n",
      "tensor([ 0.0527, -0.0141, -0.0217, -0.0156, -0.0589,  0.0040, -0.0147, -0.0145,\n",
      "        -0.0519,  0.0030,  0.0106, -0.0544,  0.0237, -0.0455,  0.0513,  0.0329,\n",
      "        -0.0470, -0.0153,  0.0268,  0.0069, -0.0247, -0.0221, -0.0258,  0.0253,\n",
      "         0.0247, -0.0371, -0.0054,  0.0044, -0.0370,  0.0553, -0.0369, -0.0301,\n",
      "        -0.0413,  0.0518,  0.0157,  0.0337,  0.0122, -0.0157, -0.0535,  0.0260,\n",
      "        -0.0448, -0.0408,  0.0292, -0.0444,  0.0503, -0.0508, -0.0596, -0.0079,\n",
      "        -0.0110, -0.0174, -0.0120,  0.0471,  0.0044,  0.0228, -0.0516, -0.0183,\n",
      "        -0.0309,  0.0224,  0.0491,  0.0584,  0.0614,  0.0275, -0.0424, -0.0480,\n",
      "         0.0249, -0.0200, -0.0250,  0.0415, -0.0248,  0.0406,  0.0025,  0.0278,\n",
      "        -0.0303, -0.0499,  0.0062, -0.0602, -0.0353,  0.0568, -0.0364,  0.0361,\n",
      "         0.0369, -0.0205,  0.0094,  0.0589,  0.0432,  0.0584,  0.0045,  0.0436,\n",
      "         0.0477, -0.0394, -0.0160,  0.0172,  0.0398,  0.0509,  0.0600, -0.0572,\n",
      "        -0.0594,  0.0301,  0.0374, -0.0404,  0.0094,  0.0460,  0.0323,  0.0286,\n",
      "        -0.0360,  0.0034,  0.0098, -0.0299,  0.0107, -0.0040, -0.0421, -0.0585,\n",
      "        -0.0595,  0.0219, -0.0034, -0.0616,  0.0352, -0.0169,  0.0170,  0.0133,\n",
      "         0.0316,  0.0146, -0.0008, -0.0398, -0.0439, -0.0486,  0.0444,  0.0546],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "-------------------------------\n",
      "proj2_shortcut.weight\n",
      "Parameter containing:\n",
      "tensor([[-0.0136,  0.0553,  0.0440,  ...,  0.0075, -0.0462,  0.0616],\n",
      "        [ 0.0077, -0.0269, -0.0361,  ..., -0.0100,  0.0345, -0.0492],\n",
      "        [ 0.0195,  0.0082,  0.0353,  ...,  0.0401, -0.0392,  0.0174],\n",
      "        ...,\n",
      "        [-0.0316,  0.0430, -0.0526,  ...,  0.0559, -0.0424, -0.0571],\n",
      "        [-0.0304,  0.0382, -0.0308,  ..., -0.0534, -0.0321,  0.0493],\n",
      "        [-0.0539, -0.0553, -0.0065,  ..., -0.0596, -0.0554, -0.0286]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "-------------------------------\n",
      "proj2_shortcut.bias\n",
      "Parameter containing:\n",
      "tensor([-0.0326,  0.0328,  0.0456,  0.0149, -0.0152, -0.0156,  0.0203, -0.0439,\n",
      "        -0.0400, -0.0609,  0.0149,  0.0126, -0.0386,  0.0379, -0.0245, -0.0222,\n",
      "         0.0433,  0.0098, -0.0582, -0.0096,  0.0043,  0.0444,  0.0107, -0.0120,\n",
      "         0.0549, -0.0335,  0.0496, -0.0048,  0.0307,  0.0082,  0.0098,  0.0240,\n",
      "         0.0473, -0.0106,  0.0184, -0.0566, -0.0590,  0.0489, -0.0135, -0.0289,\n",
      "        -0.0529, -0.0297, -0.0547, -0.0042, -0.0451,  0.0584, -0.0371,  0.0082,\n",
      "         0.0440,  0.0607, -0.0111, -0.0040, -0.0576, -0.0144, -0.0037, -0.0346,\n",
      "        -0.0097,  0.0548, -0.0387, -0.0420, -0.0358,  0.0018,  0.0419,  0.0193,\n",
      "         0.0069, -0.0167,  0.0476,  0.0056, -0.0520, -0.0040, -0.0031, -0.0185,\n",
      "        -0.0156, -0.0599,  0.0131, -0.0510,  0.0074, -0.0298, -0.0449, -0.0423,\n",
      "         0.0349, -0.0161,  0.0248,  0.0183,  0.0035,  0.0492, -0.0575, -0.0603,\n",
      "         0.0365,  0.0176,  0.0453, -0.0507, -0.0063,  0.0342, -0.0063,  0.0614,\n",
      "        -0.0346,  0.0408, -0.0063, -0.0083,  0.0287,  0.0232,  0.0277, -0.0215,\n",
      "        -0.0432,  0.0595, -0.0502, -0.0227, -0.0191,  0.0231, -0.0102, -0.0396,\n",
      "        -0.0100,  0.0572, -0.0321,  0.0020, -0.0087,  0.0184,  0.0464, -0.0022,\n",
      "        -0.0576, -0.0604, -0.0010,  0.0131,  0.0573,  0.0084, -0.0325,  0.0247],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "-------------------------------\n",
      "concat.weight\n",
      "Parameter containing:\n",
      "tensor([[ 0.0419,  0.0380, -0.0475,  ...,  0.0594,  0.0442,  0.0131],\n",
      "        [ 0.0103,  0.0271, -0.0452,  ...,  0.0488, -0.0607, -0.0353],\n",
      "        [ 0.0202,  0.0174,  0.0184,  ..., -0.0576,  0.0398, -0.0037],\n",
      "        ...,\n",
      "        [ 0.0052, -0.0537, -0.0275,  ..., -0.0115,  0.0346,  0.0005],\n",
      "        [ 0.0141, -0.0298, -0.0565,  ...,  0.0005, -0.0092, -0.0268],\n",
      "        [-0.0325,  0.0017, -0.0374,  ..., -0.0228,  0.0617,  0.0053]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "-------------------------------\n",
      "concat.bias\n",
      "Parameter containing:\n",
      "tensor([-4.9169e-02, -4.2452e-03,  9.7646e-03, -1.9694e-02, -5.8456e-02,\n",
      "         1.9276e-02,  3.0938e-02,  2.2177e-02, -5.4731e-02, -5.4382e-03,\n",
      "        -6.6650e-03,  2.9778e-02,  1.6521e-03, -4.1789e-02,  2.1486e-02,\n",
      "        -5.6665e-02, -2.6502e-02,  1.1111e-02, -4.6391e-02,  2.0711e-02,\n",
      "         3.6156e-02,  2.5461e-02,  4.3246e-02, -5.7498e-03,  1.3347e-02,\n",
      "        -4.6954e-05,  2.8780e-02,  3.5993e-02, -2.4429e-02, -4.8415e-02,\n",
      "         6.2162e-02, -3.9669e-02, -3.7904e-02, -2.9326e-02, -1.8841e-02,\n",
      "         1.1967e-02,  6.0165e-02, -4.4659e-03,  3.4700e-02,  1.0295e-02,\n",
      "        -2.3530e-02, -7.9934e-03, -5.9537e-02,  1.3232e-02, -3.9808e-02,\n",
      "        -5.4236e-02, -5.0464e-02, -1.3898e-02, -1.3899e-02, -2.3321e-02,\n",
      "         1.3889e-02,  8.4254e-03,  2.5038e-02,  4.9236e-02, -4.1035e-02,\n",
      "         2.3205e-02,  4.1040e-03, -3.8870e-02, -5.0770e-02,  3.1875e-02,\n",
      "         5.5614e-02, -2.1535e-02, -5.3273e-02, -2.3655e-02,  4.9761e-02,\n",
      "         6.6122e-03,  5.2426e-02,  4.3736e-02, -4.3659e-02, -2.0690e-02,\n",
      "        -1.1078e-02, -2.3070e-02,  3.1689e-02, -2.4254e-03, -5.7824e-02,\n",
      "        -4.8503e-02,  1.7027e-02,  4.8375e-02,  2.2080e-02, -1.6304e-02,\n",
      "        -5.8262e-02, -3.9452e-02, -5.0467e-02,  4.9075e-02, -5.1020e-03,\n",
      "        -7.4010e-03,  4.2678e-02,  6.1945e-02,  4.3017e-02, -3.2567e-02,\n",
      "         4.5366e-02,  1.0751e-02,  5.5586e-02, -7.9613e-03, -5.4879e-02,\n",
      "        -1.1334e-02,  2.6827e-02, -6.2858e-03,  1.8905e-02, -6.1046e-03,\n",
      "         1.5377e-02,  5.8768e-02, -3.1753e-02,  3.5535e-02, -3.2581e-04,\n",
      "        -9.6678e-03,  4.1764e-02,  2.5730e-02,  1.6936e-02, -1.5835e-02,\n",
      "        -2.6874e-02,  3.1326e-03, -4.9820e-02,  1.8478e-02, -5.7448e-02,\n",
      "         8.9839e-03, -4.6341e-02, -5.2525e-02, -2.3174e-02,  4.9412e-02,\n",
      "         4.5939e-02, -6.0558e-02,  2.6535e-02, -3.7783e-02,  5.8186e-02,\n",
      "        -3.9835e-03,  1.2522e-02, -6.0788e-02], device='cuda:0',\n",
      "       requires_grad=True)\n",
      "-------------------------------\n",
      "pred.weight\n",
      "Parameter containing:\n",
      "tensor([[ 0.3408,  0.1915, -0.1720,  ...,  0.5348, -0.6069, -0.1173],\n",
      "        [-0.1021,  0.4360,  0.2814,  ..., -0.1842, -0.1057, -0.4428],\n",
      "        [ 0.5111, -0.2813, -0.0297,  ...,  0.0102, -0.0848, -0.2370],\n",
      "        ...,\n",
      "        [-0.1484,  0.2022,  0.3304,  ...,  0.9967,  0.2807,  0.1741],\n",
      "        [-0.1501,  0.1515,  0.2241,  ...,  0.0372,  0.8412,  0.1886],\n",
      "        [ 0.3417,  0.2367, -0.1091,  ...,  0.5930, -0.6188, -0.0999]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "-------------------------------\n",
      "pred.bias\n",
      "Parameter containing:\n",
      "tensor([-0.2812, -0.3209,  0.1718,  0.0515,  0.0260, -0.3485, -0.3183,  0.0174,\n",
      "         0.4632,  0.0688, -0.3547, -0.1003, -0.3406, -0.4605, -0.3291, -0.1761,\n",
      "        -0.2177, -0.3046, -0.2191, -0.2413, -0.2724, -0.3436, -0.1674,  0.0626,\n",
      "        -0.0048,  0.4367, -0.0495, -0.6126,  0.0400, -0.1024,  0.0132, -0.2702,\n",
      "        -0.0072, -0.3125, -0.0562, -0.2489,  0.1296, -0.1819, -0.1833, -0.1314,\n",
      "        -0.2819], device='cuda:0', requires_grad=True)\n",
      "-------------------------------\n"
     ]
    }
   ],
   "source": [
    "for name, param in ae.named_parameters():\n",
    "    print(name)\n",
    "    print(param)\n",
    "    print(\"-------------------------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performance Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 4 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, axs = plt.subplots(2, 2, figsize=(10,6)) \n",
    "x = [i*5 for i in range(len(accu_test))]\n",
    "axs[0,0].plot(loss_train)\n",
    "axs[0,0].set_ylabel(\"loss\")\n",
    "axs[0,0].set_xlabel(\"epochs\")\n",
    "axs[0,0].set_title(\"train\")\n",
    "axs[1,0].plot(accu_train)\n",
    "axs[1,0].set_ylabel(\"Accuracy\")\n",
    "axs[1,0].set_xlabel(\"epochs\")\n",
    "axs[1,0].set_title(\"train\")\n",
    "axs[0,1].plot(x, loss_test)\n",
    "axs[0,1].set_ylabel(\"loss\")\n",
    "axs[0,1].set_xlabel(\"epochs\")\n",
    "axs[0,1].set_title(\"test\")\n",
    "axs[1,1].plot(x, accu_test)\n",
    "axs[1,1].set_ylabel(\"Accuracy\")\n",
    "axs[1,1].set_xlabel(\"epochs\")\n",
    "axs[1,1].set_title(\"test\")\n",
    "plt.tight_layout()\n",
    "plt.savefig('AE_result.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a 1\n",
      "b 2\n"
     ]
    }
   ],
   "source": [
    "d = {'a': 1, 'b':2}\n",
    "for key, val in d.items():\n",
    "    print(key, val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pred:\t8\t28\t8\t25\t8\t8\t8\t8\t8\t8\t8\t28\t8\t25\t25\t8\t8\t8\t28\t28\t8\t8\t8\t8\t28\t8\t25\t25\t8\t8\t8\t28\t8\t25\t25\t8\t8\t28\t8\t8\t8\t8\t28\t8\t8\t8\t8\t25\t25\t8\t8\t25\t25\t8\t8\t8\t28\t8\t8\t8\t8\t8\t8\t28\t8\t28\t8\t25\t8\t25\t25\t8\t8\t8\t8\t8\t8\t8\t8\t25\t25\t8\t8\t8\t28\t8\t8\t25\t25\t25\t25\t8\t8\t8\t8\t8\t8\t8\t8\t25\t25\t8\t8\t8\t28\t8\t8\t25\t25\t25\t25\t25\t8\t25\t25\t25\t8\t25\t8\t8\t8\t8\t8\t8\t8\t8\t25\t25\t25\t25\t8\t8\t8\t28\t8\t8\t8\t8\t8\t8\t28\t8\t25\t25\t25\t8\t8\t8\t28\t8\t8\t8\t8\t8\t8\t28\t8\t25\t25\t8\t25\t25\t25\t25\t8\t8\t8\t28\t8\t8\t25\t8\t8\t8\t8\t8\t28\t8\t25\t8\t8\t8\t28\t8\t25\t8\t8\t8\t28\t8\t25\t25\t8\t8\t8\t28\t8\t8\t25\t25\t25\t25\t25\t8\t25\t25\t25\t25\t25\t8\t8\t8\t8\t8\t8\t8\t8\t25\t25\t25\t25\t8\t8\t8\t28\t8\t8\t8\t8\t8\t8\t28\t8\t25\t25\t25\t8\t8\t8\t28\t8\t8\t8\t8\t8\t8\t28\t8\t25\t25\t8\t8\t8\t28\t8\t8\t25\t25\t25\t25\t8\t8\t8\t8\t8\t8\t8\t8\t25\t25\t25\t25\t8\t8\t8\t28\t8\t8\t8\t8\t8\t8\t28\t8\t25\t25\t25\t8\t8\t8\t28\t8\t8\t8\t8\t8\t8\t28\t8\t25\t8\t8\t8\t28\t8\t25\t25\t8\t8\t8\t28\t8\t8\t8\t8\t8\t28\t8\t8\t8\t8\t8\t8\t8\t25\t25\t8\t8\t8\t28\t8\t8\t28\t8\t8\t8\t8\t8\t8\t28\t8\t8\t8\t8\t8\t8\t8\t8\t28\t8\t8\t8\t8\t28\t8\t8\t8\t8\t8\t8\t8\t8\t28\t8\t25\t25\t25\t8\t8\t8\t28\t8\t8\t8\t8\t8\t8\t28\t8\t8\t8\t8\t8\t8\t8\t8\t25\t25\t25\t25\t8\t8\t8\t28\t8\t8\t8\t8\t8\t8\t28\t8\t25\t8\t8\t8\t28\t8\t25\t8\t8\t8\t28\t8\t8\t8\t8\t8\t8\t8\t8\t8\t8\t8\t8\t8\t8\t8\t25\t25\t25\t25\t8\t8\t8\t28\t8\t8\t8\t8\t8\t8\t28\t8\t25\t25\t25\t8\t8\t8\t28\t8\t8\t8\t8\t8\t8\t28\t8\t25\t8\t8\t8\t28\t8\t8\t28\t8\t8\t8\t8\t8\t8\t28\t8\t8\t8\t8\t8\t8\t8\t25\t25\t8\t8\t8\t8\t28\t28\t8\t8\t8\t8\t8\t28\t8\t8\t8\t8\t8\t28\t8\t8\t8\t8\t8\t8\t8\t25\t25\t8\t8\t8\t8\t28\t8\t8\t8\t8\t25\t8\t8\t8\t8\t8\t8\t8\t8\t8\t8\t8\t8\t8\t8\t8\t8\t8\t8\t8\t8\t8\t8\t8\t8\t8\t8\t8\t8\t8\t8\t8\t8\t8\t8\t25\t25\t25\t8\t8\t28\t8\t8\t8\t8\t28\t8\t25\t25\t8\t8\t8\t25\t25\t25\t25\t8\t8\t25\t25\t25\t25\t8\t8\t8\t25\t25\t25\t25\t8\t8\t25\t25\t25\t8\t25\t8\t8\t8\t8\t8\t28\t8\t8\t25\t25\t25\t8\t8\t8\t8\t28\t8\t8\t8\t25\t8\t25\t8\t25\t25\t8\t8\t8\t28\t8\t8\t28\t8\t8\t8\t25\t25\t25\t25\t8\t8\t8\t28\t8\n",
      "actu:\t8\t28\t25\t23\t8\t8\t8\t8\t8\t8\t8\t28\t25\t25\t8\t8\t8\t8\t8\t8\t8\t8\t8\t8\t28\t25\t25\t8\t8\t8\t8\t28\t25\t25\t8\t8\t8\t37\t8\t8\t8\t8\t8\t8\t8\t8\t28\t25\t23\t8\t28\t25\t23\t8\t8\t8\t8\t8\t8\t8\t8\t8\t8\t8\t8\t36\t25\t23\t7\t25\t8\t32\t9\t11\t14\t15\t16\t8\t28\t25\t23\t8\t8\t8\t8\t36\t25\t25\t7\t25\t8\t32\t9\t11\t14\t15\t16\t8\t28\t25\t23\t8\t8\t8\t8\t8\t36\t25\t25\t2\t25\t8\t36\t25\t25\t4\t25\t8\t32\t9\t11\t14\t15\t16\t8\t36\t25\t25\t3\t23\t8\t8\t8\t37\t8\t8\t8\t8\t8\t8\t36\t25\t25\t3\t23\t8\t8\t8\t37\t8\t8\t8\t8\t8\t8\t28\t25\t25\t8\t36\t25\t25\t3\t23\t8\t8\t8\t37\t8\t37\t8\t8\t8\t8\t8\t8\t28\t25\t23\t8\t8\t8\t28\t25\t23\t8\t8\t8\t8\t28\t25\t23\t8\t8\t8\t8\t8\t36\t25\t25\t2\t25\t8\t36\t25\t25\t3\t25\t8\t32\t9\t11\t14\t15\t16\t8\t36\t25\t25\t3\t23\t8\t8\t8\t37\t8\t8\t8\t8\t8\t8\t36\t25\t25\t3\t23\t8\t8\t8\t37\t8\t8\t8\t8\t8\t8\t8\t28\t25\t23\t8\t8\t8\t8\t36\t25\t25\t2\t25\t8\t32\t9\t11\t14\t15\t16\t8\t36\t25\t25\t3\t23\t8\t8\t8\t37\t8\t8\t8\t8\t8\t8\t36\t25\t25\t3\t23\t8\t8\t8\t37\t8\t8\t8\t8\t8\t8\t28\t25\t23\t8\t8\t8\t8\t28\t25\t23\t8\t8\t8\t8\t8\t8\t8\t8\t8\t32\t9\t11\t14\t15\t16\t8\t28\t25\t23\t8\t8\t8\t8\t8\t8\t37\t8\t8\t8\t8\t8\t8\t32\t9\t11\t14\t15\t16\t8\t8\t8\t8\t8\t8\t8\t8\t32\t9\t11\t14\t15\t16\t8\t8\t8\t36\t25\t25\t3\t23\t8\t8\t8\t37\t8\t8\t8\t8\t8\t8\t8\t32\t9\t11\t14\t15\t16\t8\t36\t25\t25\t3\t23\t8\t8\t8\t37\t8\t8\t8\t8\t8\t8\t28\t25\t23\t8\t8\t8\t28\t25\t23\t8\t8\t8\t8\t32\t9\t11\t14\t15\t16\t8\t32\t9\t11\t14\t15\t16\t8\t36\t25\t25\t3\t23\t8\t8\t8\t37\t8\t8\t8\t8\t8\t8\t36\t25\t25\t3\t23\t8\t8\t8\t37\t8\t8\t8\t8\t8\t8\t28\t25\t23\t8\t8\t8\t8\t8\t8\t8\t8\t8\t8\t8\t8\t8\t32\t33\t11\t14\t15\t16\t8\t28\t25\t23\t8\t8\t8\t8\t8\t8\t8\t8\t8\t8\t8\t8\t8\t8\t8\t8\t8\t32\t9\t11\t14\t15\t16\t8\t28\t25\t23\t8\t8\t8\t8\t8\t8\t8\t8\t28\t9\t23\t8\t32\t9\t11\t14\t8\t32\t9\t11\t14\t15\t16\t17\t8\t8\t8\t32\t9\t11\t8\t32\t9\t11\t8\t32\t9\t11\t8\t32\t9\t11\t8\t28\t25\t25\t8\t8\t8\t37\t8\t8\t8\t8\t8\t28\t25\t24\t8\t8\t36\t25\t25\t7\t23\t8\t36\t25\t25\t2\t23\t8\t8\t36\t25\t25\t2\t23\t8\t36\t25\t25\t4\t25\t8\t8\t8\t8\t8\t8\t8\t36\t25\t25\t3\t23\t8\t8\t8\t8\t37\t8\t8\t28\t24\t25\t8\t28\t25\t24\t8\t8\t8\t8\t8\t8\t8\t8\t8\t36\t25\t25\t7\t23\t8\t8\t8\t8\t8\n",
      "----------------------------------------------------------------------------------------\n",
      "pred:\t8\t28\t8\t25\t8\t8\t8\t8\t8\t8\t8\t28\t8\t25\t25\t8\t8\t8\t28\t28\t8\t8\t8\t8\t28\t8\t25\t25\t8\t8\t8\t28\t8\t25\t25\t8\t8\t28\t8\t8\t8\t8\t28\t8\t8\t8\t8\t25\t25\t8\t8\t25\t25\t8\t8\t8\t28\t8\t8\t8\t8\t8\t8\t28\t8\t28\t8\t25\t8\t25\t25\t8\t8\t8\t8\t8\t8\t8\t8\t25\t25\t8\t8\t8\t28\t8\t8\t25\t25\t25\t25\t8\t8\t8\t8\t8\t8\t8\t8\t25\t25\t8\t8\t8\t28\t8\t8\t25\t25\t25\t25\t25\t8\t25\t25\t25\t8\t25\t8\t8\t8\t8\t8\t8\t8\t8\t25\t25\t25\t25\t8\t8\t8\t28\t8\t8\t8\t8\t8\t8\t28\t8\t25\t25\t25\t8\t8\t8\t28\t8\t8\t8\t8\t8\t8\t28\t8\t25\t25\t8\t25\t25\t25\t25\t8\t8\t8\t28\t8\t8\t25\t8\t8\t8\t8\t8\t28\t8\t25\t8\t8\t8\t28\t8\t25\t8\t8\t8\t28\t8\t25\t25\t8\t8\t8\t28\t8\t8\t25\t25\t25\t25\t25\t8\t25\t25\t25\t25\t25\t8\t8\t8\t8\t8\t8\t8\t8\t25\t25\t25\t25\t8\t8\t8\t28\t8\t8\t8\t8\t8\t8\t28\t8\t25\t25\t25\t8\t8\t8\t28\t8\t8\t8\t8\t8\t8\t28\t8\t25\t25\t8\t8\t8\t28\t8\t8\t25\t25\t25\t25\t8\t8\t8\t8\t8\t8\t8\t8\t25\t25\t25\t25\t8\t8\t8\t28\t8\t8\t8\t8\t8\t8\t28\t8\t25\t25\t25\t8\t8\t8\t28\t8\t8\t8\t8\t8\t8\t28\t8\t25\t8\t8\t8\t28\t8\t25\t25\t8\t8\t8\t28\t8\t8\t8\t8\t8\t28\t8\t8\t8\t8\t8\t8\t8\t25\t25\t8\t8\t8\t28\t8\t8\t28\t8\t8\t8\t8\t8\t8\t28\t8\t8\t8\t8\t8\t8\t8\t8\t28\t8\t8\t8\t8\t28\t8\t8\t8\t8\t8\t8\t8\t8\t28\t8\t25\t25\t25\t8\t8\t8\t28\t8\t8\t8\t8\t8\t8\t28\t8\t8\t8\t8\t8\t8\t8\t8\t25\t25\t25\t25\t8\t8\t8\t28\t8\t8\t8\t8\t8\t8\t28\t8\t25\t8\t8\t8\t28\t8\t25\t8\t8\t8\t28\t8\t8\t8\t8\t8\t8\t8\t8\t8\t8\t8\t8\t8\t8\t8\t25\t25\t25\t25\t8\t8\t8\t28\t8\t8\t8\t8\t8\t8\t28\t8\t25\t25\t25\t8\t8\t8\t28\t8\t8\t8\t8\t8\t8\t28\t8\t25\t8\t8\t8\t28\t8\t8\t28\t8\t8\t8\t8\t8\t8\t28\t8\t8\t8\t8\t8\t8\t8\t25\t25\t8\t8\t8\t8\t28\t28\t8\t8\t8\t8\t8\t28\t8\t8\t8\t8\t8\t28\t8\t8\t8\t8\t8\t8\t8\t25\t25\t8\t8\t8\t8\t28\t8\t8\t8\t8\t25\t8\t8\t8\t8\t8\t8\t8\t8\t8\t8\t8\t8\t8\t8\t8\t8\t8\t8\t8\t8\t8\t8\t8\t8\t8\t8\t8\t8\t8\t8\t8\t8\t8\t8\t25\t25\t25\t8\t8\t28\t8\t8\t8\t8\t28\t8\t25\t25\t8\t8\t8\t25\t25\t25\t25\t8\t8\t25\t25\t25\t25\t8\t8\t8\t25\t25\t25\t25\t8\t8\t25\t25\t25\t8\t25\t8\t8\t8\t8\t8\t28\t8\t8\t25\t25\t25\t8\t8\t8\t8\t28\t8\t8\t8\t25\t8\t25\t8\t25\t25\t8\t8\t8\t28\t8\t8\t28\t8\t8\t8\t25\t25\t25\t25\t8\t8\t8\t28\t8\n",
      "actu:\t8\t28\t25\t23\t8\t8\t8\t8\t8\t8\t8\t28\t25\t25\t8\t8\t8\t8\t8\t8\t8\t8\t8\t8\t28\t25\t25\t8\t8\t8\t8\t28\t25\t25\t8\t8\t8\t37\t8\t8\t8\t8\t8\t8\t8\t8\t28\t25\t23\t8\t28\t25\t23\t8\t8\t8\t8\t8\t8\t8\t8\t8\t8\t8\t8\t36\t25\t23\t7\t25\t8\t32\t9\t11\t14\t15\t16\t8\t28\t25\t23\t8\t8\t8\t8\t36\t25\t25\t7\t25\t8\t32\t9\t11\t14\t15\t16\t8\t28\t25\t23\t8\t8\t8\t8\t8\t36\t25\t25\t2\t25\t8\t36\t25\t25\t4\t25\t8\t32\t9\t11\t14\t15\t16\t8\t36\t25\t25\t3\t23\t8\t8\t8\t37\t8\t8\t8\t8\t8\t8\t36\t25\t25\t3\t23\t8\t8\t8\t37\t8\t8\t8\t8\t8\t8\t28\t25\t25\t8\t36\t25\t25\t3\t23\t8\t8\t8\t37\t8\t37\t8\t8\t8\t8\t8\t8\t28\t25\t23\t8\t8\t8\t28\t25\t23\t8\t8\t8\t8\t28\t25\t23\t8\t8\t8\t8\t8\t36\t25\t25\t2\t25\t8\t36\t25\t25\t3\t25\t8\t32\t9\t11\t14\t15\t16\t8\t36\t25\t25\t3\t23\t8\t8\t8\t37\t8\t8\t8\t8\t8\t8\t36\t25\t25\t3\t23\t8\t8\t8\t37\t8\t8\t8\t8\t8\t8\t8\t28\t25\t23\t8\t8\t8\t8\t36\t25\t25\t2\t25\t8\t32\t9\t11\t14\t15\t16\t8\t36\t25\t25\t3\t23\t8\t8\t8\t37\t8\t8\t8\t8\t8\t8\t36\t25\t25\t3\t23\t8\t8\t8\t37\t8\t8\t8\t8\t8\t8\t28\t25\t23\t8\t8\t8\t8\t28\t25\t23\t8\t8\t8\t8\t8\t8\t8\t8\t8\t32\t9\t11\t14\t15\t16\t8\t28\t25\t23\t8\t8\t8\t8\t8\t8\t37\t8\t8\t8\t8\t8\t8\t32\t9\t11\t14\t15\t16\t8\t8\t8\t8\t8\t8\t8\t8\t32\t9\t11\t14\t15\t16\t8\t8\t8\t36\t25\t25\t3\t23\t8\t8\t8\t37\t8\t8\t8\t8\t8\t8\t8\t32\t9\t11\t14\t15\t16\t8\t36\t25\t25\t3\t23\t8\t8\t8\t37\t8\t8\t8\t8\t8\t8\t28\t25\t23\t8\t8\t8\t28\t25\t23\t8\t8\t8\t8\t32\t9\t11\t14\t15\t16\t8\t32\t9\t11\t14\t15\t16\t8\t36\t25\t25\t3\t23\t8\t8\t8\t37\t8\t8\t8\t8\t8\t8\t36\t25\t25\t3\t23\t8\t8\t8\t37\t8\t8\t8\t8\t8\t8\t28\t25\t23\t8\t8\t8\t8\t8\t8\t8\t8\t8\t8\t8\t8\t8\t32\t33\t11\t14\t15\t16\t8\t28\t25\t23\t8\t8\t8\t8\t8\t8\t8\t8\t8\t8\t8\t8\t8\t8\t8\t8\t8\t32\t9\t11\t14\t15\t16\t8\t28\t25\t23\t8\t8\t8\t8\t8\t8\t8\t8\t28\t9\t23\t8\t32\t9\t11\t14\t8\t32\t9\t11\t14\t15\t16\t17\t8\t8\t8\t32\t9\t11\t8\t32\t9\t11\t8\t32\t9\t11\t8\t32\t9\t11\t8\t28\t25\t25\t8\t8\t8\t37\t8\t8\t8\t8\t8\t28\t25\t24\t8\t8\t36\t25\t25\t7\t23\t8\t36\t25\t25\t2\t23\t8\t8\t36\t25\t25\t2\t23\t8\t36\t25\t25\t4\t25\t8\t8\t8\t8\t8\t8\t8\t36\t25\t25\t3\t23\t8\t8\t8\t8\t37\t8\t8\t28\t24\t25\t8\t28\t25\t24\t8\t8\t8\t8\t8\t8\t8\t8\t8\t36\t25\t25\t7\t23\t8\t8\t8\t8\t8\n",
      "----------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "for (padded_seq, padded_seq_dec, lengths, edge_index) in test_gpu:\n",
    "    j_test += np.sum(lengths)\n",
    "    cntBatch_test += 1\n",
    "    out = ae(padded_seq, padded_seq_dec, lengths, edge_index, mode=\"mix\", ratio=1, ratio_mix=1)\n",
    "    pred = out.flatten(0).reshape(-1,N_max).argmax(dim=1).to(\"cpu\").tolist()\n",
    "    actu = padded_seq.flatten().to(\"cpu\").tolist()\n",
    "    pred_f = []\n",
    "    actu_f = []\n",
    "    for i in range(len(actu)):\n",
    "        if (actu[i]!=40):\n",
    "            pred_f.append(pred[i])\n",
    "            actu_f.append(actu[i])\n",
    "    print(\"pred:\", *pred_f, sep='\\t')\n",
    "    print(\"actu:\", *actu_f, sep='\\t')\n",
    "    print(\"----------------------------------------------------------------------------------------\")\n",
    "    break\n",
    "for (padded_seq, padded_seq_dec, lengths, edge_index) in test_gpu:\n",
    "    j_test += np.sum(lengths)\n",
    "    cntBatch_test += 1\n",
    "    out = ae(padded_seq, padded_seq_dec, lengths, edge_index, mode=\"teaching\", ratio=1, ratio_mix=1)\n",
    "    pred = out.flatten(0).reshape(-1,N_max).argmax(dim=1).to(\"cpu\").tolist()\n",
    "    actu = padded_seq.flatten().to(\"cpu\").tolist()\n",
    "    pred_f = []\n",
    "    actu_f = []\n",
    "    for i in range(len(actu)):\n",
    "        if (actu[i]!=40):\n",
    "            pred_f.append(pred[i])\n",
    "            actu_f.append(actu[i])\n",
    "    print(\"pred:\", *pred_f, sep='\\t')\n",
    "    print(\"actu:\", *actu_f, sep='\\t')\n",
    "    print(\"----------------------------------------------------------------------------------------\")\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.2.2+cu118'"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for (padded_seq, padded_seq_dec, lengths, edge_index) in train_gpu:\n",
    "    j_test += np.sum(lengths)\n",
    "    cntBatch_test += 1\n",
    "    out = ae(padded_seq, padded_seq_dec, lengths, edge_index, mode=\"recursive\")\n",
    "    print(\"pred:\", out.flatten(0).reshape(-1,N_max).argmax(dim=1).to(\"cpu\").tolist())\n",
    "    print(\"actu:\",padded_seq.flatten().to(\"cpu\").tolist())\n",
    "    print(\"----------------------------------------------------------------------------------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LSTM Only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "bidir          = True\n",
    "dir            = 2 if bidir else 1 \n",
    "batch_size     = 64\n",
    "num_layers_enc = 4\n",
    "hidden_dim_enc = 128\n",
    "num_layers_dec = 4\n",
    "hidden_dim_dec = 128\n",
    "emb_dim        = 128\n",
    "N_max          = len(word_to_idx)+1\n",
    "\n",
    "dataset = split_pp_into_sublists(data_emb, batch_size)\n",
    "(train, test) = split_train_test(dataset)\n",
    "\n",
    "ae = AutoEncoder_rnn(batch_size     = batch_size,\n",
    "            bidir          = True,\n",
    "            num_layers_enc = num_layers_enc,\n",
    "            hidden_dim_enc = hidden_dim_enc,\n",
    "            num_layers_dec = num_layers_dec,\n",
    "            hidden_dim_dec = hidden_dim_dec,\n",
    "            emb_dim        = emb_dim,\n",
    "            N_max          = N_max)\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")  # Or \"cuda:0\" for the first GPU\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "\n",
    "#device = torch.device(\"cpu\")\n",
    "ae.to(device)\n",
    "\n",
    "\n",
    "train_gpu = batch_gnn_for_gpu(train, device, len(word_to_idx))\n",
    "test_gpu = batch_gnn_for_gpu(test, device, len(word_to_idx))\n",
    "weight = count_occurrences(train, word_to_idx, device)\n",
    "\n",
    "\n",
    "criterion = nn.CrossEntropyLoss(ignore_index=len(word_to_idx), weight=weight)\n",
    "#data_emb_device = [(edge_index.to(device), [bb.to(device) for bb in node_embs ]) for (edge_index, node_embs) in data_emb] \n",
    "optimizer = optim.Adam(ae.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For 56009 Tokens List in Train set: Epoch 1/100, Average Loss: 2.79574, Acuuracy: 6.10699\n",
      "For 11714 Tokens List in Test set: Epoch 1/100, Average Loss: 2.48895, Acuuracy: 8.29973\n",
      "-----------------------------------------------------------------------------------\n",
      "For 56009 Tokens List in Train set: Epoch 6/100, Average Loss: 0.93932, Acuuracy: 39.08935\n",
      "For 11714 Tokens List in Test set: Epoch 6/100, Average Loss: 1.77262, Acuuracy: 16.98876\n",
      "-----------------------------------------------------------------------------------\n",
      "For 56009 Tokens List in Train set: Epoch 11/100, Average Loss: 0.76524, Acuuracy: 46.52205\n",
      "For 11714 Tokens List in Test set: Epoch 11/100, Average Loss: 1.55707, Acuuracy: 21.07534\n",
      "-----------------------------------------------------------------------------------\n",
      "For 56009 Tokens List in Train set: Epoch 16/100, Average Loss: 0.62400, Acuuracy: 53.57944\n",
      "For 11714 Tokens List in Test set: Epoch 16/100, Average Loss: 1.64864, Acuuracy: 19.23114\n",
      "-----------------------------------------------------------------------------------\n",
      "For 56009 Tokens List in Train set: Epoch 21/100, Average Loss: 0.57554, Acuuracy: 56.24025\n",
      "For 11714 Tokens List in Test set: Epoch 21/100, Average Loss: 1.45389, Acuuracy: 23.36589\n",
      "-----------------------------------------------------------------------------------\n",
      "For 56009 Tokens List in Train set: Epoch 26/100, Average Loss: 0.50002, Acuuracy: 60.65167\n",
      "For 11714 Tokens List in Test set: Epoch 26/100, Average Loss: 1.42192, Acuuracy: 24.12506\n",
      "-----------------------------------------------------------------------------------\n",
      "For 56009 Tokens List in Train set: Epoch 31/100, Average Loss: 0.51353, Acuuracy: 59.83781\n",
      "For 11714 Tokens List in Test set: Epoch 31/100, Average Loss: 1.42201, Acuuracy: 24.12282\n",
      "-----------------------------------------------------------------------------------\n",
      "For 56009 Tokens List in Train set: Epoch 36/100, Average Loss: 0.47018, Acuuracy: 62.48880\n",
      "For 11714 Tokens List in Test set: Epoch 36/100, Average Loss: 1.50231, Acuuracy: 22.26164\n",
      "-----------------------------------------------------------------------------------\n",
      "For 56009 Tokens List in Train set: Epoch 41/100, Average Loss: 0.43671, Acuuracy: 64.61593\n",
      "For 11714 Tokens List in Test set: Epoch 41/100, Average Loss: 1.38734, Acuuracy: 24.97395\n",
      "-----------------------------------------------------------------------------------\n",
      "For 56009 Tokens List in Train set: Epoch 46/100, Average Loss: 0.48775, Acuuracy: 61.40052\n",
      "For 11714 Tokens List in Test set: Epoch 46/100, Average Loss: 1.46966, Acuuracy: 23.00034\n",
      "-----------------------------------------------------------------------------------\n",
      "For 56009 Tokens List in Train set: Epoch 51/100, Average Loss: 0.47178, Acuuracy: 62.38925\n",
      "For 11714 Tokens List in Test set: Epoch 51/100, Average Loss: 1.62786, Acuuracy: 19.63491\n",
      "-----------------------------------------------------------------------------------\n",
      "For 56009 Tokens List in Train set: Epoch 56/100, Average Loss: 0.40895, Acuuracy: 66.43499\n",
      "For 11714 Tokens List in Test set: Epoch 56/100, Average Loss: 1.25464, Acuuracy: 28.51795\n",
      "-----------------------------------------------------------------------------------\n",
      "For 56009 Tokens List in Train set: Epoch 61/100, Average Loss: 0.38654, Acuuracy: 67.94061\n",
      "For 11714 Tokens List in Test set: Epoch 61/100, Average Loss: 1.46732, Acuuracy: 23.05429\n",
      "-----------------------------------------------------------------------------------\n",
      "For 56009 Tokens List in Train set: Epoch 66/100, Average Loss: 0.34809, Acuuracy: 70.60373\n",
      "For 11714 Tokens List in Test set: Epoch 66/100, Average Loss: 1.20040, Acuuracy: 30.10726\n",
      "-----------------------------------------------------------------------------------\n",
      "For 56009 Tokens List in Train set: Epoch 71/100, Average Loss: 0.35481, Acuuracy: 70.13067\n",
      "For 11714 Tokens List in Test set: Epoch 71/100, Average Loss: 1.30854, Acuuracy: 27.02154\n",
      "-----------------------------------------------------------------------------------\n",
      "For 56009 Tokens List in Train set: Epoch 76/100, Average Loss: 0.30939, Acuuracy: 73.38962\n",
      "For 11714 Tokens List in Test set: Epoch 76/100, Average Loss: 1.47908, Acuuracy: 22.78464\n",
      "-----------------------------------------------------------------------------------\n",
      "For 56009 Tokens List in Train set: Epoch 81/100, Average Loss: 0.31379, Acuuracy: 73.06731\n",
      "For 11714 Tokens List in Test set: Epoch 81/100, Average Loss: 1.44957, Acuuracy: 23.46716\n",
      "-----------------------------------------------------------------------------------\n",
      "For 56009 Tokens List in Train set: Epoch 86/100, Average Loss: 0.33247, Acuuracy: 71.71478\n",
      "For 11714 Tokens List in Test set: Epoch 86/100, Average Loss: 1.41254, Acuuracy: 24.35248\n",
      "-----------------------------------------------------------------------------------\n",
      "For 56009 Tokens List in Train set: Epoch 88/100, Average Loss: 0.34673, Acuuracy: 70.69947\r"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [77], line 23\u001b[0m\n\u001b[1;32m     21\u001b[0m     j \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39msum(lengths)\n\u001b[1;32m     22\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m---> 23\u001b[0m     \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     24\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m     25\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m epoch\u001b[38;5;241m%\u001b[39m\u001b[38;5;241m5\u001b[39m\u001b[38;5;241m==\u001b[39m\u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m (epoch\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m==\u001b[39mepoch_num:\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/_tensor.py:522\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    512\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    513\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    514\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    515\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    520\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    521\u001b[0m     )\n\u001b[0;32m--> 522\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    523\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    524\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/autograd/__init__.py:266\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    261\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    263\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[1;32m    264\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    265\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 266\u001b[0m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    267\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    268\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    269\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    270\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    271\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    272\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    273\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    274\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "epoch_num = 100\n",
    "loss_train = []\n",
    "accu_train = []\n",
    "loss_test = []\n",
    "accu_test = []\n",
    "for epoch in range(epoch_num):\n",
    "    total_loss = 0\n",
    "    j = 0\n",
    "    cntBatch = 0\n",
    "    for (padded_seq, padded_seq_dec, lengths, edge_index) in train_gpu:\n",
    "        cntBatch += 1\n",
    "        #print(\"seq ->\", padded_seq.shape)\n",
    "        #print(\"lengths -> \", min(lengths), \":\", max(lengths))\n",
    "        out = ae(padded_seq, padded_seq_dec, lengths, edge_index, mode=\"mix\", ratio=0.5, ratio_mix=0.5)\n",
    "        #print(out[:,-1,:])\n",
    "        loss = criterion(out.flatten(0).reshape(-1,N_max), padded_seq.flatten())\n",
    "        #print(out.flatten(0).reshape(-1,N_max).argmax(dim=1).to(\"cpu\").tolist())\n",
    "        #print(padded_seq.flatten().to(\"cpu\").tolist())\n",
    "        #print(\"-------------------------------------------------\")\n",
    "        total_loss  += loss.item()\n",
    "        j += np.sum(lengths)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    if epoch%5==0 or (epoch+1)==epoch_num:\n",
    "        print(f'For {j} Tokens List in Train set: Epoch {epoch+1}/{epoch_num}, Average Loss: {total_loss/cntBatch:.5f}, Acuuracy: {np.exp(-total_loss/cntBatch)*100:.5f}', end='\\n')\n",
    "        cntBatch_test = 0\n",
    "        total_loss_test = 0\n",
    "        j_test = 0\n",
    "        for (padded_seq, padded_seq_dec, lengths, edge_index) in test_gpu:\n",
    "            j_test += np.sum(lengths)\n",
    "            cntBatch_test += 1\n",
    "            out = ae(padded_seq, padded_seq_dec, lengths, edge_index, mode=\"recursive\", ratio=1)\n",
    "            loss = criterion(out.flatten(0).reshape(-1,N_max), padded_seq.flatten())\n",
    "            total_loss_test  += loss.item()\n",
    "        loss_test.append(total_loss_test/cntBatch_test)\n",
    "        accu_test.append(np.exp(-total_loss_test/cntBatch_test)*100)\n",
    "        print(f'For {j_test} Tokens List in Test set: Epoch {epoch+1}/{epoch_num}, Average Loss: {total_loss_test/cntBatch_test:.5f}, Acuuracy: {np.exp(-total_loss_test/cntBatch_test)*100:.5f}', end='\\n')\n",
    "        print(\"-----------------------------------------------------------------------------------\")\n",
    "    else:\n",
    "        print(f'For {j} Tokens List in Train set: Epoch {epoch+1}/{epoch_num}, Average Loss: {total_loss/cntBatch:.5f}, Acuuracy: {np.exp(-total_loss/cntBatch)*100:.5f}', end='\\r')\n",
    "    loss_train.append(total_loss/cntBatch)\n",
    "    accu_train.append(np.exp(-total_loss/cntBatch)*100)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
