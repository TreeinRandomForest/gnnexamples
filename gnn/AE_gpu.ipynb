{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model import AutoEncoder_gnnrnn, AutoEncoder_rnn, AutoEncoder_gnngatrnn\n",
    "from data import prepare_data_vocab, live_feat, batch_gnn_for_gpu, split_pp_into_sublists, split_train_test, count_occurrences, batch_gnngat_for_gpu\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "from torch.optim import lr_scheduler\n",
    "from utils import save_edge_attr_graph, calculate_variable\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data prepration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_to_idx, idx_to_word, data, data_emb = prepare_data_vocab(\"gccData\", func=live_feat, function_num=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Are you sure? yes/no\")\n",
    "if input()=='yes':\n",
    "    print('yes')\n",
    "    with open('data.pickle', 'wb') as f:\n",
    "        pickle.dump([word_to_idx, idx_to_word, data, data_emb], f)\n",
    "else:\n",
    "    print('no')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data.pickle', 'rb') as f:\n",
    "        [word_to_idx, idx_to_word, data, data_emb] = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data_emb = []\n",
    "for g in data_emb:\n",
    "    num_nodes = len(g[1])\n",
    "    max_num_token_local = 0\n",
    "    for gg in g[1]:\n",
    "        if gg.shape[0]>max_num_token_local:\n",
    "            max_num_token_local = gg.shape[0]\n",
    "    if g[0].max() < num_nodes:\n",
    "        if num_nodes<256 and num_nodes>4:\n",
    "            if max_num_token_local<300:\n",
    "                new_data_emb.append(g)\n",
    "data_emb = new_data_emb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hist_plt(data, label):\n",
    "    plt.hist(data, bins=range(min(data), max(data) + 1), edgecolor='black')  # Adjust bin size if needed\n",
    "    plt.xlabel('Values')\n",
    "    plt.ylabel('Frequency')\n",
    "    plt.title('Histogram of '+ label)\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "num_edges = []\n",
    "num_nodes = []\n",
    "max_num_token = []\n",
    "for g in data_emb:\n",
    "    num_edges.append(g[0].shape[1])\n",
    "    num_nodes.append(len(g[1]))\n",
    "    max_num_token_local = 0\n",
    "    for gg in g[1]:\n",
    "        if gg.shape[0]>max_num_token_local:\n",
    "            max_num_token_local = gg.shape[0]\n",
    "    max_num_token.append(max_num_token_local)\n",
    "\n",
    "hist_plt(num_edges, '# edges')\n",
    "hist_plt(num_nodes, '# nodes')\n",
    "hist_plt(max_num_token, 'max # token')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_rate = calculate_variable()\n",
    "drop_rate = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size     = 256\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")  # Or \"cuda:0\" for the first GPU\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "\n",
    "dataset = split_pp_into_sublists(data_emb, batch_size)\n",
    "(train, test) = split_train_test(dataset, drop_rate=drop_rate)\n",
    "train_gpu = batch_gnn_for_gpu(train, device, len(word_to_idx))\n",
    "test_gpu = batch_gnn_for_gpu(test, device, len(word_to_idx))\n",
    "weight = count_occurrences(train, word_to_idx, device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GNN LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#return grad_input.min(), grad_input.min(), grad_input.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def register_hooks(model):\n",
    "    hooks = []\n",
    "    for layer in model.modules():\n",
    "        if isinstance(layer, nn.Linear):\n",
    "            hooks.append(layer.register_full_backward_hook(get_gradient))\n",
    "    return hooks\n",
    "\n",
    "def get_gradient(module, grad_input, grad_output):\n",
    "    #print('Gradient Input:', grad_input)  # Gradients with respect to inputs\n",
    "    #return grad_input\n",
    "    #print('Gradient Output:', grad_output)  # Gradients with respect to outputs\n",
    "    global total_gradients, total_parameters, dict_grad\n",
    "    for name, param in module.named_parameters():\n",
    "        if param.grad is not None:\n",
    "            grad = param.grad\n",
    "            dict_grad[name] = total_gradients\n",
    "            total_gradients += grad.abs().sum().item()\n",
    "            total_parameters += grad.numel()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "bidir          = True\n",
    "dir            = 2 if bidir else 1 \n",
    "\n",
    "num_layers_enc = 2\n",
    "hidden_dim_enc = 64\n",
    "num_layers_dec = 2\n",
    "hidden_dim_dec = 64\n",
    "emb_dim        = 64\n",
    "N_max          = len(word_to_idx)+1\n",
    "layer_dims_gnn = [64]\n",
    "\n",
    "\n",
    "\n",
    "ae = AutoEncoder_gnnrnn(batch_size     = batch_size,\n",
    "            bidir          = bidir,\n",
    "            num_layers_enc = num_layers_enc,\n",
    "            hidden_dim_enc = hidden_dim_enc,\n",
    "            num_layers_dec = num_layers_dec,\n",
    "            hidden_dim_dec = hidden_dim_dec,\n",
    "            layer_dims_gnn = layer_dims_gnn,\n",
    "            emb_dim        = emb_dim,\n",
    "            N_max          = N_max)\n",
    "\n",
    "\n",
    "\n",
    "#device = torch.device(\"cpu\")\n",
    "ae.to(device)\n",
    "\n",
    "criterion      = nn.CrossEntropyLoss(ignore_index=len(word_to_idx), weight=weight)\n",
    "#criterion_real = nn.CrossEntropyLoss(ignore_index=len(word_to_idx))\n",
    "#data_emb_device = [(edge_index.to(device), [bb.to(device) for bb in node_embs ]) for (edge_index, node_embs) in data_emb] \n",
    "optimizer = optim.Adam(ae.parameters(), lr=0.01)\n",
    "optimizer = optim.AdamW(ae.parameters(), lr=0.01, weight_decay=0.01)\n",
    "#optimizer = optim.Adam(ae.parameters(), lr=0.01, weight_decay=0.001)\n",
    "#hooks = register_hooks(ae)\n",
    "# Before the training loop\n",
    "total_gradients = 0.0\n",
    "total_parameters = 0\n",
    "\n",
    "#scheduler = lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.1) \n",
    "\n",
    "#optimizer = optim.SGD(ae.parameters(), lr=0.1, momentum=0.9)\n",
    "#scheduler = lr_scheduler.CyclicLR(optimizer, base_lr=0.01, max_lr=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For 54507 Tokens List in Train set: Epoch 1/100, Average Loss: 2.83269, Acuuracy: 5.88542\n",
      "For 13216 Tokens List in Test set: Epoch 1/100, Average Loss: 2.64929, Acuuracy: 7.07015\n",
      "-----------------------------------------------------------------------------------\n",
      "For 54507 Tokens List in Train set: Epoch 6/100, Average Loss: 2.41458, Acuuracy: 8.94052\n",
      "For 13216 Tokens List in Test set: Epoch 6/100, Average Loss: 2.60501, Acuuracy: 7.39027\n",
      "-----------------------------------------------------------------------------------\n",
      "For 54507 Tokens List in Train set: Epoch 11/100, Average Loss: 2.40969, Acuuracy: 8.98432\n",
      "For 13216 Tokens List in Test set: Epoch 11/100, Average Loss: 2.58792, Acuuracy: 7.51759\n",
      "-----------------------------------------------------------------------------------\n",
      "For 54507 Tokens List in Train set: Epoch 16/100, Average Loss: 2.34280, Acuuracy: 9.605828\n",
      "For 13216 Tokens List in Test set: Epoch 16/100, Average Loss: 2.64430, Acuuracy: 7.10548\n",
      "-----------------------------------------------------------------------------------\n",
      "For 54507 Tokens List in Train set: Epoch 21/100, Average Loss: 2.40829, Acuuracy: 8.996928\n",
      "For 13216 Tokens List in Test set: Epoch 21/100, Average Loss: 2.74602, Acuuracy: 6.41831\n",
      "-----------------------------------------------------------------------------------\n",
      "For 54507 Tokens List in Train set: Epoch 26/100, Average Loss: 2.29255, Acuuracy: 10.10085\n",
      "For 13216 Tokens List in Test set: Epoch 26/100, Average Loss: 2.57589, Acuuracy: 7.60863\n",
      "-----------------------------------------------------------------------------------\n",
      "For 54507 Tokens List in Train set: Epoch 31/100, Average Loss: 2.28961, Acuuracy: 10.13063\n",
      "For 13216 Tokens List in Test set: Epoch 31/100, Average Loss: 2.66414, Acuuracy: 6.96592\n",
      "-----------------------------------------------------------------------------------\n",
      "For 54507 Tokens List in Train set: Epoch 33/100, Average Loss: 2.28420, Acuuracy: 10.18552\r"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [22], line 24\u001b[0m\n\u001b[1;32m     22\u001b[0m     j \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39msum(lengths)\n\u001b[1;32m     23\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m---> 24\u001b[0m     \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     25\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m     26\u001b[0m     \u001b[38;5;66;03m#scheduler.step()\u001b[39;00m\n\u001b[1;32m     27\u001b[0m \u001b[38;5;66;03m#for hook in hooks:\u001b[39;00m\n\u001b[1;32m     28\u001b[0m  \u001b[38;5;66;03m#   hook.remove()  # Remove previous hooks\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[38;5;66;03m# Optionally, you can print the learning rate to monitor its changes\u001b[39;00m\n\u001b[1;32m     33\u001b[0m     \u001b[38;5;66;03m#print(\"Learning Rate:\", optimizer.param_groups[0]['lr'])\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/_tensor.py:522\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    512\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    513\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    514\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    515\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    520\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    521\u001b[0m     )\n\u001b[0;32m--> 522\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    523\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    524\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/autograd/__init__.py:266\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    261\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    263\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[1;32m    264\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    265\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 266\u001b[0m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    267\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    268\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    269\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    270\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    271\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    272\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    273\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    274\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "epoch_num = 100\n",
    "loss_train = []\n",
    "accu_train = []\n",
    "loss_test = []\n",
    "accu_test = []\n",
    "grad_avg = []\n",
    "for epoch in range(epoch_num):\n",
    "    total_loss = 0\n",
    "    j = 0\n",
    "    cntBatch = 0\n",
    "    for (padded_seq, padded_seq_dec, lengths, edge_index) in train_gpu:\n",
    "        cntBatch += 1\n",
    "        #print(\"seq ->\", padded_seq.shape)\n",
    "        #print(\"lengths -> \", min(lengths), \":\", max(lengths))\n",
    "        out = ae(padded_seq, padded_seq_dec, lengths, edge_index, mode=\"teaching\", ratio=0.25, ratio_mix=0.8)\n",
    "        #print(out[:,-1,:])\n",
    "        loss = criterion(out.flatten(0).reshape(-1,N_max), padded_seq.flatten())\n",
    "        #print(out.flatten(0).reshape(-1,N_max).argmax(dim=1).to(\"cpu\").tolist())\n",
    "        #print(padded_seq.flatten().to(\"cpu\").tolist())\n",
    "        #print(\"-------------------------------------------------\")\n",
    "        total_loss  += loss.item()\n",
    "        j += np.sum(lengths)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        #scheduler.step()\n",
    "    #for hook in hooks:\n",
    "     #   hook.remove()  # Remove previous hooks\n",
    "    #hooks = register_hooks(ae)\n",
    "    #grad_avg.append(total_gradients/total_parameters)\n",
    "    #print(hooks[0])\n",
    "    # Optionally, you can print the learning rate to monitor its changes\n",
    "        #print(\"Learning Rate:\", optimizer.param_groups[0]['lr'])\n",
    "    if epoch%5==0 or (epoch+1)==epoch_num:\n",
    "        print(f'For {j} Tokens List in Train set: Epoch {epoch+1}/{epoch_num}, Average Loss: {total_loss/cntBatch:.5f}, Acuuracy: {np.exp(-total_loss/cntBatch)*100:.5f}', end='\\n')\n",
    "        cntBatch_test = 0\n",
    "        total_loss_test = 0\n",
    "        j_test = 0\n",
    "        for (padded_seq, padded_seq_dec, lengths, edge_index) in test_gpu:\n",
    "            j_test += np.sum(lengths)\n",
    "            cntBatch_test += 1\n",
    "            out = ae(padded_seq, padded_seq_dec, lengths, edge_index, mode=\"recursive\", ratio=1)\n",
    "            loss = criterion(out.flatten(0).reshape(-1,N_max), padded_seq.flatten())\n",
    "            total_loss_test  += loss.item()\n",
    "        loss_test.append(total_loss_test/cntBatch_test)\n",
    "        accu_test.append(np.exp(-total_loss_test/cntBatch_test)*100)\n",
    "        print(f'For {j_test} Tokens List in Test set: Epoch {epoch+1}/{epoch_num}, Average Loss: {total_loss_test/cntBatch_test:.5f}, Acuuracy: {np.exp(-total_loss_test/cntBatch_test)*100:.5f}', end='\\n')\n",
    "        print(\"-----------------------------------------------------------------------------------\")\n",
    "    else:\n",
    "        print(f'For {j} Tokens List in Train set: Epoch {epoch+1}/{epoch_num}, Average Loss: {total_loss/cntBatch:.5f}, Acuuracy: {np.exp(-total_loss/cntBatch)*100:.5f}', end='\\r')\n",
    "    loss_train.append(total_loss/cntBatch)\n",
    "    accu_train.append(np.exp(-total_loss/cntBatch)*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "for hook in hooks:\n",
    "    hook.remove()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "enc.weight_ih_l0\n",
      "Parameter containing:\n",
      "tensor([[-0.7218,  0.3673,  0.3925,  ..., -0.1274, -0.1911, -0.0575],\n",
      "        [-0.5486, -0.2140,  0.3919,  ..., -0.0996, -0.2331,  0.3569],\n",
      "        [ 0.2631,  0.4226,  0.2895,  ..., -0.8137,  0.4365, -0.6244],\n",
      "        ...,\n",
      "        [ 0.7515,  0.2327, -0.2643,  ..., -0.1543, -0.0575, -0.4267],\n",
      "        [ 0.1540, -0.1479, -0.2918,  ...,  0.0502, -0.7872,  0.3232],\n",
      "        [ 0.7401,  0.2447, -1.1955,  ...,  0.0285,  0.2472, -1.1198]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "-------------------------------\n",
      "enc.weight_hh_l0\n",
      "Parameter containing:\n",
      "tensor([[-0.1510, -0.7207, -0.2121,  ..., -0.4485, -0.2166,  0.1380],\n",
      "        [ 0.1814,  0.1122, -0.0619,  ...,  0.6065,  0.9286, -0.9765],\n",
      "        [ 0.0046, -0.2300, -0.2010,  ..., -0.1728,  0.0884, -0.3822],\n",
      "        ...,\n",
      "        [-0.5066,  0.6278,  0.0760,  ...,  0.3865,  0.5576,  0.1224],\n",
      "        [ 0.0628,  0.2472,  0.3245,  ..., -0.3430,  0.3996,  0.4059],\n",
      "        [-0.1887,  0.2664,  0.1258,  ..., -0.2920, -0.0320, -0.6751]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "-------------------------------\n",
      "enc.bias_ih_l0\n",
      "Parameter containing:\n",
      "tensor([-4.8389e-01,  8.2881e-02, -3.8207e-01,  4.4332e-01, -3.2483e-01,\n",
      "        -7.8185e-02, -3.0806e-01, -4.6396e-01, -2.1718e-01,  4.1093e-01,\n",
      "         1.3333e-01,  2.4285e-01,  2.8502e-01, -2.2726e-01,  7.2728e-02,\n",
      "        -4.9105e-01,  7.2341e-02, -3.4462e-01, -3.3767e-01,  2.1206e-01,\n",
      "         3.2130e-01,  2.1061e-01, -3.2669e-01,  9.0678e-01,  7.3729e-02,\n",
      "         4.6676e-01,  9.9978e-02,  5.5648e-01, -9.5831e-02, -4.9597e-01,\n",
      "         2.8017e-01,  1.1521e-01, -2.5551e-01,  4.7266e-01, -1.3377e-02,\n",
      "        -3.7578e-01,  2.1428e-01,  2.3068e-01, -2.0636e-01,  1.5082e-01,\n",
      "         1.4460e-01,  4.2657e-01,  5.1029e-01,  5.7829e-02, -8.7195e-02,\n",
      "        -2.4873e-01, -5.9561e-03,  5.8422e-02,  3.5471e-01,  7.4801e-01,\n",
      "        -3.9762e-01,  1.9162e-01, -4.5150e-01, -4.2109e-01,  1.6971e-01,\n",
      "         3.5557e-01, -2.0040e-01, -1.4702e-01, -2.8032e-01, -3.3446e-01,\n",
      "        -1.4945e-01,  2.3025e-01,  2.5059e-01,  3.9980e-01, -3.5897e-01,\n",
      "        -4.6796e-01, -3.7261e-03, -2.8677e-01, -1.5846e-01, -1.6563e-01,\n",
      "         2.0030e-01, -1.0343e-01, -1.4091e-01, -1.5194e-02,  2.8979e-02,\n",
      "         1.5852e-01,  9.4336e-02, -3.9171e-01, -2.5012e-01,  9.5326e-04,\n",
      "        -1.4471e-01,  4.4263e-02, -6.5740e-01,  2.4684e-01,  3.2474e-02,\n",
      "        -3.0107e-02,  6.5244e-01,  7.2835e-01, -1.6442e-01, -1.4596e-01,\n",
      "        -3.7385e-01,  3.6701e-01, -2.9348e-01, -1.5597e-01,  1.3644e-01,\n",
      "         9.8253e-01,  9.3718e-01,  8.2383e-01,  4.8072e-01,  3.5727e-02,\n",
      "        -2.7325e-01,  9.6628e-01, -2.8828e-01,  2.6735e-01, -2.7662e-01,\n",
      "        -2.8214e-02, -4.2594e-02, -2.0874e-01,  3.7875e-01, -1.8358e-01,\n",
      "         2.5115e-01,  1.1283e+00,  4.2771e-01,  5.3281e-03,  6.1675e-02,\n",
      "        -1.2410e-01,  3.1333e-01, -4.2607e-01, -1.4248e-02,  4.2064e-01,\n",
      "        -6.3183e-02,  6.4006e-01, -2.8191e-01, -1.7717e-01,  2.2225e-01,\n",
      "         2.9688e-01,  1.1485e+00,  4.5597e-01, -9.8475e-02,  4.1020e-01,\n",
      "         5.2616e-02, -3.7696e-02, -9.5235e-02, -1.6612e-01,  1.5378e-01,\n",
      "        -1.5273e-01, -1.6774e-01, -9.7627e-02,  5.1073e-01, -1.2690e-01,\n",
      "         8.2958e-02,  1.8709e-01, -1.8997e-01,  5.1317e-02,  1.5406e-01,\n",
      "        -1.6057e-01, -9.8162e-02,  4.6003e-01, -5.3467e-02,  5.4592e-01,\n",
      "        -4.4459e-01, -8.5868e-02,  2.7993e-01,  1.7772e-01, -1.7690e-01,\n",
      "        -3.6931e-01,  2.4912e-04,  4.2981e-02, -7.9061e-03,  3.6878e-01,\n",
      "        -3.2700e-01, -4.7736e-01, -3.6664e-01, -7.3004e-02, -3.3916e-01,\n",
      "        -2.3897e-02,  5.2029e-02, -2.6987e-01, -1.5510e-02, -7.4365e-02,\n",
      "         4.0611e-01, -2.6338e-01, -3.7567e-01,  1.6286e-02,  4.2988e-02,\n",
      "        -5.4443e-01,  2.2851e-01, -2.4328e-02, -3.2397e-02, -9.5638e-02,\n",
      "        -3.7676e-01,  1.1522e-01, -7.5797e-02,  3.5133e-01, -1.3450e-01,\n",
      "         9.7633e-02, -1.7760e-01,  5.8909e-02,  2.6302e-01,  9.5501e-02,\n",
      "         1.5423e-01, -1.2758e-01,  4.1119e-02, -1.8289e-02,  8.3405e-02,\n",
      "        -3.8759e-01, -3.8623e-01, -4.8196e-01, -2.5113e-01, -3.5282e-01,\n",
      "        -1.9604e-01, -2.8947e-02,  4.7903e-01,  1.4094e-01, -3.3746e-01,\n",
      "        -1.1885e-01,  1.4919e-01, -2.0547e-01,  3.3034e-01, -2.6169e-01,\n",
      "         2.4764e-01,  8.1492e-03, -1.1170e-01,  3.8946e-01, -1.0129e-01,\n",
      "        -4.9132e-02, -2.9026e-01, -4.5054e-01,  8.2290e-02,  1.7325e-01,\n",
      "         7.3676e-02,  2.2151e-01,  1.1270e-01, -2.3134e-01,  6.9990e-01,\n",
      "         3.5635e-01, -1.0059e-01, -2.8188e-01,  1.6655e-01, -3.0925e-01,\n",
      "         3.0757e-01,  1.0454e+00, -1.5048e-01,  3.5342e-01,  4.5527e-01,\n",
      "         4.7768e-01,  1.2429e-01,  1.9292e-01,  4.5212e-01,  3.2898e-01,\n",
      "        -1.7951e-01,  3.9927e-01,  2.2286e-01,  2.7036e-01, -2.5575e-01,\n",
      "        -1.9413e-01,  1.5772e-01,  3.8251e-01,  1.1231e-01,  1.7260e-01,\n",
      "         6.2736e-03,  1.9722e-01,  3.5260e-01,  7.5168e-01,  2.6116e-01,\n",
      "         4.4442e-01], device='cuda:0', requires_grad=True)\n",
      "-------------------------------\n",
      "enc.bias_hh_l0\n",
      "Parameter containing:\n",
      "tensor([-4.8662e-01,  2.0459e-01, -2.5097e-01,  3.2731e-01, -2.5736e-01,\n",
      "         6.6678e-02, -4.0301e-01, -2.9516e-01, -1.1191e-01,  4.1244e-01,\n",
      "         2.8762e-01,  2.0517e-01,  3.8445e-01, -4.5355e-01,  4.7294e-02,\n",
      "        -5.2102e-01,  5.3049e-02, -2.2364e-01, -3.2852e-01,  1.3385e-01,\n",
      "         3.1532e-01,  2.8749e-01, -3.4096e-01,  8.1011e-01,  4.9028e-02,\n",
      "         4.4047e-01,  2.9997e-01,  4.5347e-01, -6.1297e-02, -5.4571e-01,\n",
      "         2.8632e-01,  6.4386e-02, -4.0102e-01,  6.0494e-01,  1.2916e-01,\n",
      "        -3.5905e-01,  2.3348e-01,  3.5049e-01, -1.1058e-01,  1.7277e-01,\n",
      "         1.4726e-01,  4.3194e-01,  6.5240e-01,  3.3265e-02,  9.3383e-03,\n",
      "        -3.2331e-01,  1.2666e-01, -1.5338e-01,  4.6113e-01,  6.4082e-01,\n",
      "        -5.1219e-01,  1.1281e-01, -6.6504e-01, -3.2370e-01,  9.0184e-02,\n",
      "         2.4670e-01, -3.4231e-03, -6.6455e-02, -1.6968e-01, -5.4684e-01,\n",
      "        -1.2757e-01,  2.2817e-01,  2.7844e-01,  4.4895e-01, -2.1825e-01,\n",
      "        -3.5332e-01,  9.2474e-02, -3.4038e-01, -3.7052e-02, -3.6473e-01,\n",
      "         3.0050e-01, -1.3753e-01, -2.6564e-01,  1.8846e-01, -9.6562e-02,\n",
      "         2.5794e-01,  4.2722e-02, -3.3873e-01, -4.7352e-02,  5.7421e-02,\n",
      "         3.3477e-02, -1.3832e-01, -6.4176e-01,  2.7403e-01,  2.3809e-01,\n",
      "        -4.2562e-02,  6.7592e-01,  6.7120e-01, -5.1817e-03, -3.9242e-02,\n",
      "        -2.7914e-01,  2.7211e-01, -2.9670e-01,  4.2452e-02,  7.0573e-02,\n",
      "         1.1082e+00,  9.3975e-01,  9.7231e-01,  5.9728e-01,  1.7891e-01,\n",
      "        -8.8182e-02,  8.0547e-01, -1.0819e-01,  2.8013e-01, -3.8173e-01,\n",
      "        -3.0889e-02, -4.7959e-02, -3.9898e-01,  3.7593e-01, -1.2160e-01,\n",
      "         4.5565e-01,  1.0357e+00,  3.4882e-01,  1.4811e-01,  2.6077e-01,\n",
      "        -2.7666e-01,  2.6835e-01, -6.0059e-01,  9.1212e-02,  2.7834e-01,\n",
      "        -5.5073e-02,  7.7214e-01, -2.2136e-01, -6.4629e-02,  2.6879e-01,\n",
      "         2.6395e-01,  1.0138e+00,  5.7248e-01,  9.6058e-02,  4.2078e-01,\n",
      "        -7.0947e-02, -1.3208e-01, -1.3922e-01, -3.1506e-01,  6.4626e-02,\n",
      "         4.2373e-02, -2.8102e-01,  9.3240e-02,  4.7599e-01, -3.2742e-01,\n",
      "         1.6177e-02,  2.3824e-01, -3.7347e-02, -1.9548e-02,  1.5293e-01,\n",
      "        -2.2597e-01, -1.2993e-01,  3.7136e-01, -1.6061e-01,  7.0894e-01,\n",
      "        -3.6901e-01, -4.8040e-02,  1.8505e-01,  3.0882e-01, -1.2110e-01,\n",
      "        -3.5571e-01, -7.6374e-04, -1.2364e-01,  2.7037e-02,  2.5890e-01,\n",
      "        -5.2708e-01, -3.3500e-01, -2.5915e-01, -6.8721e-02, -3.1553e-01,\n",
      "        -1.2929e-01, -1.4205e-02, -1.5709e-01,  1.2493e-01, -1.0976e-01,\n",
      "         3.6743e-01, -1.1351e-01, -3.1263e-01,  2.3748e-01, -1.0333e-02,\n",
      "        -4.8246e-01,  3.3747e-01,  6.5066e-02, -4.4440e-03, -2.1658e-01,\n",
      "        -4.6968e-01,  2.6185e-02, -2.7576e-01,  3.1143e-01, -1.9727e-01,\n",
      "         1.0847e-01, -2.1117e-01, -5.0268e-02,  4.6855e-01, -1.9302e-02,\n",
      "         4.9556e-02, -8.0582e-02,  5.6540e-02, -3.1057e-02,  1.2980e-01,\n",
      "        -3.9673e-01, -2.0452e-01, -4.5854e-01, -2.4135e-01, -4.0057e-01,\n",
      "        -1.6760e-01,  1.7769e-02,  3.7670e-01,  2.1060e-01, -4.4364e-01,\n",
      "        -1.7641e-01,  1.7623e-01, -2.6960e-01,  3.2410e-01, -3.7553e-01,\n",
      "         4.0064e-01, -9.8893e-03,  4.7117e-02,  4.0115e-01,  6.1178e-02,\n",
      "         4.0816e-02, -4.5527e-01, -3.6363e-01, -1.2893e-01,  1.4147e-01,\n",
      "         1.9640e-01,  1.7269e-01,  3.2674e-02, -2.1208e-01,  6.2094e-01,\n",
      "         2.6212e-01, -2.5325e-01, -3.2530e-01,  5.8912e-02, -3.6657e-01,\n",
      "         2.5308e-01,  8.5596e-01, -1.0066e-01,  3.2240e-01,  5.2845e-01,\n",
      "         4.0047e-01,  7.1074e-02,  2.7200e-01,  4.8960e-01,  4.8925e-01,\n",
      "        -6.5871e-02,  2.9822e-01,  1.7707e-01,  1.7002e-01, -2.7816e-01,\n",
      "        -1.4127e-01,  2.6975e-01,  3.7191e-01,  1.0020e-01,  2.4705e-01,\n",
      "        -2.0246e-02,  3.1328e-01,  3.2252e-01,  9.6365e-01,  2.2181e-01,\n",
      "         3.7186e-01], device='cuda:0', requires_grad=True)\n",
      "-------------------------------\n",
      "enc.weight_ih_l0_reverse\n",
      "Parameter containing:\n",
      "tensor([[ 1.1068,  0.1766, -0.1076,  ..., -0.6331, -0.2345, -0.7149],\n",
      "        [ 0.1212, -0.4137, -0.1050,  ...,  0.1651, -0.4451,  0.2012],\n",
      "        [ 0.3408,  0.4866, -0.1299,  ..., -0.5818,  0.0336, -0.4585],\n",
      "        ...,\n",
      "        [ 0.4521,  0.4930,  0.2402,  ..., -0.1881, -0.0895, -0.4134],\n",
      "        [ 0.8622,  1.0386, -0.3759,  ...,  0.3634,  0.5337, -0.0194],\n",
      "        [ 0.7303, -0.3328,  0.0810,  ...,  0.2822,  0.3209,  0.5134]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "-------------------------------\n",
      "enc.weight_hh_l0_reverse\n",
      "Parameter containing:\n",
      "tensor([[ 0.7510, -0.9309, -0.7007,  ...,  0.5327,  0.0280, -0.1641],\n",
      "        [-0.3208,  0.4064,  0.2406,  ...,  0.8423,  0.1088, -0.5685],\n",
      "        [-0.6550, -0.1253, -0.2821,  ...,  0.2845, -0.0340, -0.0500],\n",
      "        ...,\n",
      "        [-0.0094, -0.4058,  0.3821,  ...,  0.0860,  0.3251,  0.1126],\n",
      "        [-0.2793, -0.2957,  0.4148,  ...,  0.1091, -0.3475, -0.0724],\n",
      "        [-0.7223,  0.4595,  0.6268,  ..., -0.1721,  0.6415, -0.2123]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "-------------------------------\n",
      "enc.bias_ih_l0_reverse\n",
      "Parameter containing:\n",
      "tensor([ 5.5849e-01,  7.0605e-01, -1.5425e-01,  2.2385e-01,  7.3351e-04,\n",
      "         3.9095e-01,  7.5587e-01,  3.6574e-01,  1.6737e-01,  1.1513e-01,\n",
      "         1.4496e-01,  5.3686e-01,  1.1202e-01,  3.5934e-01, -1.2450e-01,\n",
      "         2.6200e-01,  4.5783e-01, -2.3512e-01, -4.1535e-01,  2.9772e-01,\n",
      "        -1.9530e-01,  5.0131e-01,  6.4693e-01,  3.0118e-01,  9.0276e-01,\n",
      "         1.9523e-01, -6.1548e-02,  3.6175e-01,  2.8301e-01, -2.9246e-01,\n",
      "        -4.5672e-02,  1.9062e-01,  4.4095e-01,  4.6001e-01, -1.9553e-01,\n",
      "         5.9999e-01,  6.2549e-01,  1.3591e-01, -2.4235e-02,  1.2567e-01,\n",
      "        -3.2706e-01,  1.5715e-01,  4.3034e-01,  6.6464e-02,  4.0290e-01,\n",
      "        -3.6872e-01,  2.2364e-01,  4.5248e-01,  5.7970e-01,  4.4921e-01,\n",
      "         4.5585e-01, -1.6705e-01,  3.3646e-01,  3.5713e-01,  9.0438e-01,\n",
      "         5.1417e-02,  8.0618e-02, -1.9298e-01,  2.8683e-01,  4.7236e-01,\n",
      "         1.8532e-01, -4.0140e-01, -3.9121e-01,  8.5642e-01,  8.2294e-02,\n",
      "        -1.2558e-01,  1.3652e-01,  6.0551e-01, -1.3309e-01,  3.3287e-01,\n",
      "         4.7663e-01, -1.2338e-01,  6.9560e-01,  7.2484e-01,  1.9682e-01,\n",
      "         9.4523e-02,  1.7633e-01,  3.8358e-01,  2.0715e-02,  2.5763e-01,\n",
      "         3.4558e-01, -2.4704e-01, -2.3799e-01,  3.4802e-01,  4.6406e-01,\n",
      "         1.4773e-01,  6.0307e-01,  6.9092e-01,  4.9228e-01, -2.8109e-01,\n",
      "        -2.7829e-01, -8.8304e-02,  2.7030e-01, -9.1636e-02,  7.8610e-02,\n",
      "        -4.0285e-02,  4.3192e-02,  2.7393e-01,  8.0403e-01, -1.3621e-01,\n",
      "        -1.7580e-01,  8.1562e-01,  4.3578e-01, -4.2074e-02, -2.6319e-01,\n",
      "        -2.3546e-02,  5.1199e-01,  2.9724e-01,  3.7737e-01,  4.7537e-02,\n",
      "        -1.0631e-01,  2.2563e-01,  1.5869e-01, -2.0125e-01,  8.0684e-02,\n",
      "         1.4096e-01, -4.0034e-02, -4.4021e-01, -1.3114e-01,  4.4194e-01,\n",
      "        -5.5628e-01,  5.0091e-01,  3.6038e-01,  2.1152e-01,  5.8566e-02,\n",
      "        -2.3994e-01,  1.0689e-01,  5.2345e-01,  5.2123e-01, -5.1956e-01,\n",
      "        -5.0334e-01,  9.8245e-03,  2.7334e-01,  2.1125e-01,  6.5165e-02,\n",
      "        -1.1655e-01,  7.8797e-02, -4.2543e-01, -5.8664e-01, -1.8785e-01,\n",
      "         1.5987e-01,  8.9930e-02,  1.6020e-01, -9.6463e-02,  5.7174e-02,\n",
      "        -9.9705e-02,  5.0236e-02,  4.2702e-02, -2.0278e-01,  1.0285e-01,\n",
      "        -7.1459e-02,  2.1268e-01, -4.1295e-02, -1.1338e-01,  3.0051e-01,\n",
      "         8.4603e-02,  7.4294e-02, -4.6779e-01, -2.7201e-01, -1.1412e-01,\n",
      "        -4.2062e-01,  4.8268e-02, -6.2315e-01,  2.2258e-01, -2.0742e-01,\n",
      "         2.9244e-01, -7.5739e-02,  4.1355e-02, -4.1110e-01,  2.7543e-01,\n",
      "         1.6514e-01, -2.7142e-01, -1.9488e-01, -1.0898e-01, -2.7223e-01,\n",
      "         5.1418e-03, -2.5102e-01, -1.1541e-01, -2.3867e-01, -2.6596e-01,\n",
      "        -2.5309e-01,  6.0726e-02,  8.9820e-02, -6.3785e-02,  5.6697e-01,\n",
      "         3.0573e-02, -6.9470e-02, -2.5402e-01,  5.7213e-01,  1.4770e-01,\n",
      "         2.5231e-01, -5.6113e-01,  3.5464e-01,  9.8610e-02, -6.7559e-02,\n",
      "        -8.4097e-02,  4.1712e-01, -2.9881e-01,  3.9012e-01, -2.8435e-01,\n",
      "         8.8699e-02, -8.4075e-02,  1.6253e-01,  8.2054e-01,  8.8999e-02,\n",
      "        -3.8187e-01, -9.6419e-01,  9.6108e-02,  5.7641e-01,  2.0112e-01,\n",
      "        -5.8012e-02,  2.7432e-01,  3.9255e-01, -1.4881e-01, -7.6776e-02,\n",
      "         6.2931e-01, -1.8210e-01,  3.2196e-01,  1.2330e-01, -2.5100e-01,\n",
      "         3.7777e-01, -3.4192e-01, -3.0736e-01, -6.1304e-02,  3.3996e-01,\n",
      "         5.0032e-01,  2.0830e-01,  1.2998e-01,  7.8657e-01, -3.4538e-02,\n",
      "        -3.8607e-01,  6.9502e-02, -8.5422e-02, -1.7993e-01, -1.2323e-01,\n",
      "         4.8825e-01,  4.3087e-01, -2.2568e-01, -1.8771e-01, -1.2143e-01,\n",
      "         2.1968e-01, -2.7769e-02,  6.5450e-01, -2.8179e-01, -7.1070e-02,\n",
      "        -3.4165e-01,  1.6568e-01,  4.6748e-01, -1.4864e-01,  2.8350e-02,\n",
      "        -4.7381e-02, -1.7590e-01,  3.2355e-01, -1.8141e-01,  3.2487e-01,\n",
      "         2.0150e-01], device='cuda:0', requires_grad=True)\n",
      "-------------------------------\n",
      "enc.bias_hh_l0_reverse\n",
      "Parameter containing:\n",
      "tensor([ 6.9200e-01,  5.6002e-01, -9.2024e-02,  2.5244e-01,  1.2192e-01,\n",
      "         1.6211e-01,  5.9231e-01,  3.9266e-01,  1.6631e-01,  1.2665e-01,\n",
      "         1.5396e-01,  6.4749e-01,  1.1268e-01,  3.3726e-01,  5.6777e-03,\n",
      "         2.3658e-01,  4.7910e-01, -1.3557e-01, -5.8073e-01,  2.3247e-01,\n",
      "        -3.1969e-01,  6.1642e-01,  6.2218e-01,  2.6296e-01,  9.4691e-01,\n",
      "         3.1452e-01,  9.3645e-02,  2.9739e-01,  2.9006e-01, -1.9322e-01,\n",
      "         5.2255e-03,  1.8346e-01,  5.9876e-01,  5.2779e-01, -2.7725e-01,\n",
      "         4.8574e-01,  6.2893e-01,  2.6414e-01,  1.4331e-02,  1.5733e-02,\n",
      "        -2.6852e-01,  2.3515e-01,  6.3697e-01,  5.1662e-05,  3.5157e-01,\n",
      "        -2.1436e-01,  2.2808e-01,  3.2727e-01,  6.8703e-01,  2.7311e-01,\n",
      "         5.3076e-01, -3.3042e-01,  3.2636e-01,  3.3130e-01,  8.0160e-01,\n",
      "        -1.2088e-01, -1.5923e-02, -2.1595e-01,  2.7669e-01,  5.0390e-01,\n",
      "        -4.0216e-02, -3.5072e-01, -1.8507e-01,  9.1200e-01,  1.1987e-01,\n",
      "        -2.2904e-02,  1.6348e-01,  6.9015e-01, -1.2237e-01,  4.2805e-01,\n",
      "         5.1096e-01,  6.5198e-02,  5.1569e-01,  6.7353e-01,  1.6326e-01,\n",
      "         6.7396e-02,  5.8131e-02,  3.4792e-01,  1.1717e-01,  1.6923e-01,\n",
      "         2.2913e-01, -6.6839e-02, -2.1617e-01,  1.3693e-01,  3.5076e-01,\n",
      "         2.0329e-01,  6.2005e-01,  5.4672e-01,  6.6817e-01, -4.8211e-01,\n",
      "        -2.7039e-01, -2.6273e-01,  2.2633e-01, -1.9933e-01,  3.2191e-01,\n",
      "        -1.0969e-01,  1.6123e-01,  2.2337e-01,  7.8112e-01, -1.2956e-01,\n",
      "        -2.1505e-01,  6.8957e-01,  3.9083e-01, -1.7850e-01, -3.2274e-01,\n",
      "         8.1076e-02,  5.3043e-01,  2.8534e-01,  4.2164e-01, -1.5624e-01,\n",
      "        -2.0244e-01,  4.1193e-01,  2.1525e-01, -2.0820e-01, -6.7085e-03,\n",
      "         3.0581e-01,  8.1408e-02, -5.1037e-01, -1.7440e-01,  4.5148e-01,\n",
      "        -5.3181e-01,  3.5158e-01,  4.5697e-01,  1.7196e-01,  5.4318e-02,\n",
      "        -3.2318e-02,  1.3909e-01,  5.4064e-01,  3.9810e-01, -3.5160e-01,\n",
      "        -7.2990e-01, -2.0023e-01,  3.3815e-01,  3.1439e-01, -6.8052e-02,\n",
      "        -1.3607e-01,  5.6762e-02, -5.4166e-01, -4.7873e-01, -1.7725e-01,\n",
      "         1.6705e-03, -3.4946e-02, -2.7027e-02, -1.5605e-01,  1.4322e-01,\n",
      "         2.6476e-02,  1.8077e-02,  4.7808e-02, -7.7649e-02,  1.3659e-01,\n",
      "         8.6095e-03,  2.6361e-01, -2.3021e-01, -2.6370e-02,  2.5108e-01,\n",
      "         4.9343e-02,  1.9568e-01, -4.2410e-01, -3.1610e-01,  1.0615e-01,\n",
      "        -3.8436e-01,  5.0206e-02, -5.4677e-01,  1.9845e-01, -2.4937e-01,\n",
      "         1.9596e-01,  1.9516e-02,  1.1967e-01, -4.2112e-01,  3.0106e-01,\n",
      "         6.5144e-02, -1.1961e-01, -3.0425e-01, -1.7353e-01, -1.2312e-01,\n",
      "         1.3013e-01, -3.4483e-01, -2.8389e-02, -1.3368e-01, -4.4101e-02,\n",
      "        -3.5034e-01,  1.0555e-01,  3.1864e-02,  9.4677e-02,  4.5965e-01,\n",
      "         9.3446e-02, -6.8281e-02, -4.7660e-01,  4.7662e-01,  1.5531e-01,\n",
      "         2.8568e-01, -3.9125e-01,  3.5617e-01, -3.2361e-02,  3.1135e-02,\n",
      "        -8.0209e-02,  5.7974e-01, -3.7820e-01,  3.1696e-01, -1.7726e-01,\n",
      "         7.0186e-02, -5.1789e-02,  3.5279e-01,  7.9480e-01,  4.3402e-03,\n",
      "        -3.9232e-01, -9.7633e-01,  4.8859e-02,  5.7760e-01,  1.0728e-01,\n",
      "        -2.1359e-02,  1.9317e-01,  4.7589e-01, -1.1308e-01, -2.1206e-01,\n",
      "         7.6104e-01, -2.2210e-01,  3.5744e-01,  2.1341e-01, -5.9547e-02,\n",
      "         3.6843e-01, -3.5690e-01, -1.5974e-01,  1.1845e-01,  2.1711e-01,\n",
      "         4.2487e-01,  9.6384e-02,  1.0424e-01,  7.7237e-01, -9.7093e-02,\n",
      "        -4.4344e-01,  1.8398e-01,  3.5982e-02, -1.1293e-01,  1.3060e-02,\n",
      "         5.2989e-01,  6.4247e-01, -3.3082e-01, -9.3413e-02, -1.0781e-01,\n",
      "         4.1099e-01, -2.5298e-01,  8.4117e-01, -2.1414e-01,  8.2380e-02,\n",
      "        -2.3672e-01,  2.2162e-01,  5.8302e-01, -2.6472e-02, -5.8427e-03,\n",
      "         1.9753e-02, -1.9757e-01,  3.1471e-01, -1.5087e-01,  1.2929e-01,\n",
      "         7.8937e-02], device='cuda:0', requires_grad=True)\n",
      "-------------------------------\n",
      "enc.weight_ih_l1\n",
      "Parameter containing:\n",
      "tensor([[-0.4111, -0.4241,  0.1220,  ..., -0.4045, -0.3345,  0.3567],\n",
      "        [-0.2155, -0.1945,  0.0522,  ...,  0.3207, -0.4646,  0.2503],\n",
      "        [-0.4769, -0.3568,  0.1538,  ..., -0.5640, -0.2447,  0.5761],\n",
      "        ...,\n",
      "        [ 0.1105,  0.1233,  0.5152,  ...,  0.6185, -0.0517,  0.0279],\n",
      "        [-0.4690, -0.4248, -0.4284,  ..., -0.0926, -0.0018,  0.1567],\n",
      "        [-0.4832, -0.6455, -0.1287,  ..., -0.4578, -0.6232,  0.2624]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "-------------------------------\n",
      "enc.weight_hh_l1\n",
      "Parameter containing:\n",
      "tensor([[ 0.1927, -0.1183,  0.1111,  ...,  0.3173, -0.0574,  0.0937],\n",
      "        [ 0.0303, -0.0876,  0.0791,  ...,  0.0399, -0.1953,  0.1513],\n",
      "        [ 0.6148, -0.2671, -0.4880,  ...,  0.8347, -0.0265, -0.0336],\n",
      "        ...,\n",
      "        [-0.1791, -0.2108,  0.4280,  ..., -0.1874, -0.0754, -0.3806],\n",
      "        [-0.0018, -0.3811,  0.1361,  ...,  0.2277, -0.3824,  0.2653],\n",
      "        [-0.9184, -0.3105, -0.0846,  ...,  0.2108, -0.2229, -0.2759]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "-------------------------------\n",
      "enc.bias_ih_l1\n",
      "Parameter containing:\n",
      "tensor([-0.2093, -0.2134, -0.1264, -0.3952, -0.4506, -0.4611, -0.2122, -0.9813,\n",
      "        -0.2748, -0.7843, -0.2734, -0.6319, -0.1239, -0.3419, -0.2696, -0.4084,\n",
      "        -0.4204, -0.1223, -0.3413, -0.1740, -1.0820, -0.1612, -0.1105, -0.4274,\n",
      "        -0.2338,  0.0718, -0.2389, -0.2061, -0.5496, -0.4556, -0.2384,  0.2128,\n",
      "         0.2585,  0.1548, -0.3971, -0.1758,  0.1358, -0.2862, -0.4801, -0.2069,\n",
      "        -0.4028,  0.0470, -0.5041, -0.7722, -0.3001, -0.1858, -0.2574, -0.7625,\n",
      "         0.0630, -0.2375, -0.3767, -0.2168, -0.4899, -0.4932, -1.1354, -0.4704,\n",
      "        -0.5146, -0.1880, -0.3698, -0.3052, -0.8131, -0.0206, -0.4755, -0.3857,\n",
      "        -0.4088, -0.0634, -0.1599,  0.1872, -0.0552, -0.4457, -0.5995, -0.5826,\n",
      "        -0.0958,  0.0862, -0.1944,  0.0403, -0.3311, -0.3351, -0.5953, -0.3006,\n",
      "        -0.1675,  0.3095, -0.1870, -0.4134, -0.5112, -0.1733, -0.2976,  0.0048,\n",
      "        -0.2752, -0.0371, -0.3501, -0.5821, -0.1879, -0.0520, -0.3953, -0.2651,\n",
      "        -0.3612, -0.2898, -0.8318, -0.3709, -0.2643, -0.3248, -0.4093, -0.4470,\n",
      "        -0.2734, -0.4489, -0.3509,  0.3438, -0.6843, -0.5810, -0.4918, -0.4161,\n",
      "        -0.1887, -0.1194,  0.1343, -0.3219, -0.8412, -0.3275,  0.0600,  0.0257,\n",
      "        -0.1520, -0.4278, -0.4340, -0.0628, -0.5287, -0.3764, -0.0256, -0.2398,\n",
      "         0.3007, -0.2687,  0.2460,  0.1931, -0.1290, -0.3217,  0.0169,  0.2159,\n",
      "        -0.5778,  0.2406, -0.0518, -0.0315, -0.1326, -0.1466,  0.1110, -0.1225,\n",
      "         0.2883, -0.0433,  0.2321, -0.2244,  0.0656,  0.2228,  0.0986, -0.5187,\n",
      "         0.0366, -0.0495,  0.3990,  0.2322,  0.1260, -0.0224, -0.0966, -0.0557,\n",
      "         0.1866,  0.2065,  0.1111,  0.2358, -0.0308, -0.1872, -0.2325,  0.2913,\n",
      "         0.1650, -0.2610, -0.2066,  0.0469, -0.1946, -0.2886, -0.1372,  0.3718,\n",
      "         0.2280, -0.1467,  0.0987, -0.1735,  0.2479, -0.0181, -0.0655,  0.0404,\n",
      "         0.0673, -0.2737, -0.0524, -0.0986,  0.0652, -0.2723, -0.0570,  0.2518,\n",
      "        -0.7102, -0.1748, -0.1784, -0.2051,  0.2550, -0.0624, -0.4379,  0.2310,\n",
      "        -0.4122, -0.3322, -0.5593,  0.2206, -0.6691, -0.2793, -0.1511, -0.2435,\n",
      "         0.0727,  0.0425, -0.6019, -0.2021, -0.5540, -0.3553,  0.4376, -0.0942,\n",
      "        -0.0747,  0.8320, -0.2997, -0.2556, -0.2514,  0.1634, -0.1295, -0.0522,\n",
      "        -0.4898,  0.1485, -0.3110, -0.0804, -0.2650,  0.3684, -0.4771,  0.8086,\n",
      "        -0.1238,  0.1696, -0.5032, -0.0329, -0.1926,  0.0968, -0.5081,  0.0742,\n",
      "        -0.0909,  0.6003, -0.1793, -0.3000, -0.4204, -0.0422, -0.5175,  0.2489,\n",
      "        -0.4372,  0.1315, -0.4551, -0.2461, -0.5033,  0.7183, -0.5618, -0.6142],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "-------------------------------\n",
      "enc.bias_hh_l1\n",
      "Parameter containing:\n",
      "tensor([-0.2299, -0.1733, -0.3151, -0.2389, -0.2925, -0.3984, -0.1920, -0.7564,\n",
      "        -0.2828, -0.7743, -0.2017, -0.7106, -0.1052, -0.3276, -0.3272, -0.3369,\n",
      "        -0.3623, -0.1383, -0.3455, -0.3003, -0.9432, -0.3182, -0.0226, -0.4340,\n",
      "        -0.4043,  0.0656, -0.2747, -0.1743, -0.3297, -0.6048, -0.0710,  0.3169,\n",
      "         0.1789,  0.0568, -0.3973, -0.3471,  0.1327, -0.1843, -0.3965, -0.1302,\n",
      "        -0.5006,  0.0853, -0.4691, -0.8106, -0.2218, -0.2235, -0.3517, -0.8594,\n",
      "         0.0391, -0.3999, -0.2119, -0.2294, -0.6417, -0.4280, -1.0139, -0.3145,\n",
      "        -0.6090, -0.2774, -0.4222, -0.2792, -0.6637, -0.0579, -0.6927, -0.5459,\n",
      "        -0.5991, -0.2968, -0.0187,  0.2334, -0.0261, -0.4963, -0.4213, -0.5726,\n",
      "         0.0591,  0.0498, -0.3176,  0.1242, -0.2516, -0.3331, -0.5882, -0.2432,\n",
      "        -0.2467,  0.1621, -0.2075, -0.2951, -0.4433, -0.2574, -0.3126, -0.0228,\n",
      "        -0.2456, -0.0555, -0.3732, -0.6094, -0.1030,  0.0508, -0.3151, -0.1890,\n",
      "        -0.3359, -0.5027, -0.6643, -0.2795, -0.3953, -0.3318, -0.3255, -0.6044,\n",
      "        -0.3407, -0.3373, -0.4203,  0.4377, -0.5392, -0.5393, -0.3976, -0.2856,\n",
      "        -0.1424, -0.3192,  0.0304, -0.0809, -0.9749, -0.2182,  0.1275, -0.1772,\n",
      "        -0.1585, -0.4505, -0.4796, -0.1394, -0.4706, -0.3965, -0.0209, -0.1944,\n",
      "         0.0856, -0.2255,  0.2774,  0.1625, -0.0135, -0.2500, -0.0682,  0.3035,\n",
      "        -0.4909,  0.3436, -0.0891, -0.0917,  0.0224, -0.2231, -0.0235, -0.2895,\n",
      "         0.3496,  0.1305,  0.1263, -0.3266, -0.0494,  0.1701, -0.0470, -0.5270,\n",
      "         0.1537, -0.0339,  0.4107,  0.1589,  0.1545, -0.1314, -0.2073, -0.1142,\n",
      "         0.2911,  0.2029, -0.1083,  0.2935, -0.1415, -0.2797, -0.0495,  0.0968,\n",
      "         0.1889, -0.2675, -0.2213,  0.0012, -0.1673, -0.1234, -0.1853,  0.2592,\n",
      "         0.2803, -0.1178,  0.0043, -0.1482,  0.4127, -0.0684, -0.1606, -0.1013,\n",
      "        -0.0335, -0.3844, -0.0130, -0.0895, -0.1294, -0.1662,  0.1486,  0.2101,\n",
      "        -0.6914, -0.0152, -0.1266, -0.1984,  0.3927, -0.2504, -0.2883,  0.2648,\n",
      "        -0.4123, -0.2556, -0.6009,  0.1164, -0.8143, -0.2713, -0.2358, -0.2298,\n",
      "         0.1291,  0.0237, -0.5063, -0.2531, -0.6839, -0.3789,  0.2660, -0.0462,\n",
      "        -0.0502,  0.8079, -0.3195, -0.3362, -0.1134,  0.0784, -0.0156, -0.0813,\n",
      "        -0.3593,  0.2636, -0.1812, -0.1238, -0.1692,  0.3571, -0.3721,  0.8192,\n",
      "        -0.2509, -0.0265, -0.6296,  0.1491, -0.1094,  0.2262, -0.5181, -0.1193,\n",
      "        -0.2694,  0.3987, -0.2727, -0.3410, -0.4288,  0.1568, -0.3601,  0.1466,\n",
      "        -0.3922,  0.1029, -0.3036, -0.0593, -0.4652,  0.6403, -0.5186, -0.5702],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "-------------------------------\n",
      "enc.weight_ih_l1_reverse\n",
      "Parameter containing:\n",
      "tensor([[ 0.2158, -0.1073,  1.0257,  ...,  0.2868,  0.6239,  0.0053],\n",
      "        [-0.0760, -0.3953,  0.0429,  ...,  0.3693, -0.2725,  0.0753],\n",
      "        [-0.2614,  0.1626, -0.2603,  ...,  0.0567,  0.3007, -0.2752],\n",
      "        ...,\n",
      "        [-0.4251,  0.0731, -0.1030,  ..., -0.5993,  0.2100, -0.0259],\n",
      "        [-0.2315, -0.1939, -0.2808,  ..., -0.1761, -0.1491,  0.4545],\n",
      "        [-0.1148, -0.0941, -0.1962,  ...,  0.0627, -0.2793, -0.1129]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "-------------------------------\n",
      "enc.weight_hh_l1_reverse\n",
      "Parameter containing:\n",
      "tensor([[-0.7801,  0.7691,  0.4236,  ...,  0.5246, -0.4502, -1.5744],\n",
      "        [ 0.2174,  0.0321,  0.2153,  ..., -0.3631, -0.1185,  0.5839],\n",
      "        [-0.3679,  0.5856,  0.5138,  ...,  0.4185, -0.3571, -1.3711],\n",
      "        ...,\n",
      "        [ 0.0654,  0.7209,  0.6748,  ..., -0.4467, -0.2606, -0.5343],\n",
      "        [-0.6546,  0.0367,  0.4663,  ..., -0.1681, -0.2629, -0.0729],\n",
      "        [ 0.4989, -0.3455,  0.1980,  ..., -0.0062,  0.0247,  0.9077]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "-------------------------------\n",
      "enc.bias_ih_l1_reverse\n",
      "Parameter containing:\n",
      "tensor([ 0.3223, -0.7315,  0.3209, -0.5137, -0.2539, -0.4660, -0.4595, -0.5810,\n",
      "        -0.1148, -0.0245,  0.4401, -1.0557, -0.1827, -0.3635, -0.6384, -0.2071,\n",
      "        -0.1538, -0.2622, -0.5164, -0.2107, -0.5662, -0.0929, -0.9872, -0.9596,\n",
      "        -0.0419, -0.3882, -0.4150, -0.4200, -0.3426, -0.0960, -0.0687, -0.2197,\n",
      "        -0.2519, -1.0257, -0.8427, -0.4775, -0.2283, -0.3833, -0.4584, -0.2514,\n",
      "        -0.3751, -0.1062, -0.3253, -0.4362,  0.4958, -0.5570, -0.7951, -0.3524,\n",
      "        -0.5074, -0.4938,  0.4186, -0.2489, -0.4533, -0.7737, -0.5410, -0.3583,\n",
      "        -0.4135, -1.0218, -0.2099, -0.3086, -0.0679,  0.0624, -0.3644, -0.0045,\n",
      "         0.0095, -0.3959, -0.0575,  0.0995,  0.1908,  0.7456,  0.9271,  0.0639,\n",
      "         0.1447,  0.2318, -0.3720, -0.3042, -0.3502, -0.3103, -0.5121,  0.3116,\n",
      "        -0.2327, -0.2635, -0.2204, -0.5149, -0.0124,  0.3790, -0.1443, -0.2404,\n",
      "         0.6293, -0.0786,  0.0109, -0.2958,  0.3070,  0.5930,  0.3525,  0.2781,\n",
      "        -0.3519, -0.2412, -0.4911,  0.0428, -0.0066,  0.3625, -0.2881, -0.3510,\n",
      "        -0.3068, -0.4575, -0.1894,  1.0269,  0.1629, -0.0754, -0.3015, -0.4085,\n",
      "        -0.4955, -0.6258, -0.4613,  0.6722, -0.1612, -0.1075,  0.3609, -0.2788,\n",
      "        -0.0057, -0.1990, -0.3992,  0.3142, -0.3676,  0.0114,  0.1389, -0.3140,\n",
      "         0.3387,  0.0177, -0.2666, -0.1912,  0.4088,  0.3158, -0.0371,  0.1876,\n",
      "         0.2094, -0.2348,  0.5602, -0.3319, -0.0475,  0.0528, -0.2750, -0.2434,\n",
      "        -0.2781, -0.3214, -0.2719, -0.0495,  0.0828,  0.2089, -0.3476,  0.0271,\n",
      "        -0.2354, -0.1096, -0.1628, -0.1811, -0.4664,  0.0199,  0.0504,  0.2841,\n",
      "        -0.3726, -0.0347, -0.3060, -0.6180,  0.0063,  0.2268,  0.1698, -0.1331,\n",
      "        -0.5666, -0.0150,  0.2106, -0.5379, -0.1136,  0.1943, -0.3931,  0.0404,\n",
      "        -0.2159,  0.1144,  0.7406, -0.1860, -0.1135, -0.0306, -0.0579,  0.2798,\n",
      "        -0.3744,  0.3296, -0.1534, -0.1581,  0.0540,  0.4134, -0.0787,  0.2378,\n",
      "         0.4858, -0.5436, -0.5428,  0.0389, -0.1554,  0.3643,  0.4241, -0.1698,\n",
      "        -0.3461,  0.0017, -0.2891,  0.4183, -0.4386, -0.2627, -0.0791,  0.3495,\n",
      "        -0.4399,  0.0902, -0.4372, -0.1478,  0.1393,  0.2044, -0.1412, -0.1663,\n",
      "         0.2076,  0.0846,  0.3448,  0.1744,  0.0657, -0.3443, -0.1222,  0.4408,\n",
      "        -0.1658,  0.0838, -0.1156, -0.5472, -0.5253, -0.2298, -0.1764, -0.1025,\n",
      "        -0.2111,  0.3754, -0.0041, -0.2211, -0.2932, -0.3449,  0.1821,  0.3522,\n",
      "        -0.5432, -0.4555,  0.2474, -0.5749,  0.1515, -0.3284, -0.1038, -0.6176,\n",
      "         0.4342, -0.3426, -0.1884,  0.2911,  0.0047,  0.2581, -0.0884,  0.1037],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "-------------------------------\n",
      "enc.bias_hh_l1_reverse\n",
      "Parameter containing:\n",
      "tensor([ 2.3740e-01, -7.5933e-01,  2.9293e-01, -3.7782e-01, -3.5374e-01,\n",
      "        -5.2952e-01, -4.3131e-01, -3.6757e-01, -2.7839e-01,  3.2101e-02,\n",
      "         3.5586e-01, -1.0015e+00, -2.0195e-01, -2.0649e-01, -5.8321e-01,\n",
      "        -1.9931e-01, -5.2144e-02, -1.6089e-01, -5.7856e-01, -2.8148e-01,\n",
      "        -4.6108e-01, -2.1657e-01, -1.0832e+00, -7.3717e-01, -6.5319e-02,\n",
      "        -3.3171e-01, -2.6549e-01, -4.1752e-01, -3.7406e-01, -9.4690e-02,\n",
      "        -1.1945e-01, -2.0506e-01, -4.1846e-01, -1.1104e+00, -8.9557e-01,\n",
      "        -5.9055e-01, -1.8844e-01, -4.4268e-01, -5.2264e-01, -1.9558e-01,\n",
      "        -4.5248e-01, -2.5948e-01, -2.7502e-01, -4.2305e-01,  4.6345e-01,\n",
      "        -6.4899e-01, -5.9411e-01, -2.4604e-01, -5.1527e-01, -5.1690e-01,\n",
      "         3.5257e-01, -1.4835e-01, -5.1069e-01, -9.0316e-01, -5.3144e-01,\n",
      "        -3.3187e-01, -3.9540e-01, -1.0611e+00, -7.5341e-02, -2.5631e-01,\n",
      "        -1.3712e-02,  1.5763e-01, -4.3245e-01, -1.0518e-02,  1.7879e-01,\n",
      "        -3.9362e-01,  5.7298e-02,  3.9283e-03,  2.5978e-01,  9.2377e-01,\n",
      "         7.7147e-01,  1.1795e-03,  1.7722e-01,  1.0348e-01, -3.7002e-01,\n",
      "        -3.8616e-01, -3.6564e-01, -5.2529e-01, -3.2397e-01,  3.4760e-01,\n",
      "        -2.3308e-01, -1.9693e-01, -2.8358e-01, -4.9210e-01,  9.3508e-02,\n",
      "         2.0807e-01, -1.1105e-01, -3.3393e-01,  5.6628e-01, -1.5584e-01,\n",
      "         5.1285e-02, -3.1200e-01,  2.5751e-01,  7.1116e-01,  4.5250e-01,\n",
      "         1.4507e-01, -2.6958e-01, -1.1759e-01, -4.4074e-01,  2.4358e-01,\n",
      "        -1.1999e-02,  3.7661e-01, -3.4054e-01, -2.9925e-01, -3.8686e-01,\n",
      "        -4.9530e-01, -2.8139e-01,  9.5439e-01, -9.8369e-03, -1.1842e-01,\n",
      "        -3.9862e-01, -4.2832e-01, -4.2556e-01, -4.9592e-01, -5.7684e-01,\n",
      "         6.0659e-01, -1.9921e-01,  1.4387e-02,  1.4081e-01, -3.5073e-01,\n",
      "        -8.7041e-02, -2.8312e-01, -4.0066e-01,  3.5411e-01, -3.4953e-01,\n",
      "        -3.9691e-04,  5.5921e-02, -3.4986e-01,  3.3932e-01, -5.2840e-02,\n",
      "        -1.0398e-01, -1.9110e-01,  4.2997e-01,  3.3594e-01,  3.4200e-02,\n",
      "         2.8888e-01,  3.0199e-01, -2.6770e-01,  4.9831e-01, -5.1007e-01,\n",
      "         4.4916e-02,  4.1817e-02, -4.2686e-01, -1.6536e-01, -2.6067e-01,\n",
      "        -5.0479e-01, -1.8243e-01, -3.6030e-03,  6.5977e-02,  3.8565e-01,\n",
      "        -2.1864e-01,  4.8962e-02, -1.7050e-01, -8.2833e-02, -5.8835e-02,\n",
      "        -9.0027e-02, -3.4077e-01,  2.0199e-01,  2.2186e-01,  3.2279e-01,\n",
      "        -4.1872e-01, -7.2921e-02, -3.3595e-01, -6.2571e-01, -8.0735e-02,\n",
      "         3.7413e-02,  1.6954e-01,  1.9668e-02, -4.5375e-01,  1.3020e-01,\n",
      "         2.5627e-01, -6.4337e-01, -2.1037e-02,  1.2189e-01, -4.4318e-01,\n",
      "         1.3029e-01, -2.1592e-01,  1.2487e-01,  6.7458e-01, -2.5613e-01,\n",
      "        -1.0496e-01, -2.3594e-01, -1.4983e-02,  2.9184e-01, -2.9183e-01,\n",
      "         4.5662e-01, -1.0635e-02, -2.5668e-01, -2.9916e-03,  4.3499e-01,\n",
      "         4.6512e-03,  1.9581e-01,  4.4511e-01, -4.2924e-01, -4.6290e-01,\n",
      "        -4.3932e-02, -1.8085e-01,  3.3634e-01,  2.7496e-01, -4.3152e-02,\n",
      "        -3.4271e-01, -1.7846e-01, -2.1797e-01,  3.8907e-01, -2.5730e-01,\n",
      "        -1.5156e-01, -7.8589e-02,  2.7888e-01, -6.0182e-01, -3.7961e-02,\n",
      "        -6.0439e-01, -1.7016e-01,  2.0492e-01,  2.7470e-01, -1.8386e-01,\n",
      "        -1.5330e-01,  1.9966e-01,  1.7736e-01,  3.0300e-01, -3.6047e-02,\n",
      "         4.7231e-02, -1.9768e-01,  3.9695e-02,  2.4866e-01, -1.6019e-01,\n",
      "        -2.3788e-02, -1.0913e-01, -3.1809e-01, -4.9213e-01, -3.9329e-01,\n",
      "        -1.8654e-01, -1.1552e-01, -1.8646e-01,  1.8360e-01, -9.8029e-02,\n",
      "        -5.1269e-02, -3.0308e-01, -3.2415e-01,  1.3097e-01,  3.9406e-01,\n",
      "        -4.1664e-01, -4.6553e-01,  4.7591e-01, -4.4255e-01,  7.7745e-03,\n",
      "        -4.7213e-01, -6.5833e-02, -5.8862e-01,  2.8110e-01, -3.3345e-01,\n",
      "         9.4100e-03,  1.5569e-01,  3.4044e-02,  3.6980e-01, -3.2829e-01,\n",
      "         1.2043e-01], device='cuda:0', requires_grad=True)\n",
      "-------------------------------\n",
      "dec.weight_ih_l0\n",
      "Parameter containing:\n",
      "tensor([[-0.4401,  0.1097,  0.2615,  ..., -0.1229, -0.5957, -0.8849],\n",
      "        [ 0.0860,  0.0479,  0.2113,  ..., -0.3145, -0.0012, -0.3908],\n",
      "        [-0.1900, -0.1709,  0.1172,  ..., -0.0540, -0.0690,  0.0533],\n",
      "        ...,\n",
      "        [-0.0679, -0.1314,  0.2565,  ...,  0.4285, -0.2360,  0.0284],\n",
      "        [-0.2422,  0.6149,  0.1674,  ..., -0.0373,  0.0663, -0.0275],\n",
      "        [-0.0649, -0.1421, -0.0516,  ..., -0.5090, -0.0564, -0.2315]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "-------------------------------\n",
      "dec.weight_hh_l0\n",
      "Parameter containing:\n",
      "tensor([[-0.8147,  0.6254, -0.0446,  ..., -0.1260,  0.3658, -0.7926],\n",
      "        [-0.1522, -0.0892, -0.0796,  ...,  0.1645, -0.3486,  0.1427],\n",
      "        [-0.1782,  0.7134,  0.2132,  ..., -0.1186, -0.2285,  0.0181],\n",
      "        ...,\n",
      "        [-0.0091,  0.2523, -0.0725,  ...,  0.1247, -0.2371,  0.4630],\n",
      "        [ 0.1200,  0.0470,  0.0548,  ..., -0.0426,  0.3042,  0.1417],\n",
      "        [-0.3950, -0.5531, -0.0399,  ...,  0.2887, -0.9991,  0.3832]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "-------------------------------\n",
      "dec.bias_ih_l0\n",
      "Parameter containing:\n",
      "tensor([-0.2424,  0.0337, -0.8814,  0.4771,  0.5280,  0.2118, -0.2384,  0.1282,\n",
      "         0.5155, -0.0313,  0.1566,  0.0436,  0.3827,  0.1013, -0.0198, -0.0157,\n",
      "         0.1456, -0.1888,  0.5492,  0.4462,  0.0998,  0.4907, -0.0699,  0.2662,\n",
      "        -0.4414,  0.5363,  0.1799,  0.1317, -0.2295, -0.0051,  0.3687,  0.1808,\n",
      "         0.1999, -0.6102, -0.2623, -0.3012, -0.0387,  0.2800,  0.0545,  0.2820,\n",
      "        -0.3198,  0.1615,  0.3832,  0.7291,  0.1548,  0.3248,  0.5329, -0.1490,\n",
      "         0.0262,  0.5668,  0.8036,  0.3532, -0.1900, -0.0628,  0.4917,  0.0638,\n",
      "        -0.0366,  0.1013,  0.0079,  0.1825, -0.2945, -0.0660,  0.1401,  0.1036,\n",
      "        -0.1176, -0.7017,  0.1048, -0.7599, -0.3485,  0.2044,  0.4686,  0.0601,\n",
      "        -0.5058, -0.8178, -0.7239, -0.4720, -0.8633, -0.7037,  0.6055, -0.1960,\n",
      "        -0.0554, -0.7786, -0.1806, -0.1987, -0.4621, -0.1547,  0.1491, -0.2612,\n",
      "        -0.0381,  0.0134, -0.1077,  0.0013, -0.4029, -0.4268, -0.1547, -0.0126,\n",
      "        -0.3437,  0.0697,  0.4831,  0.0637, -0.2364,  0.1019, -0.1940, -0.0747,\n",
      "        -0.0057, -0.6216, -0.5279, -0.2336, -0.0518,  0.7753, -0.4101, -0.7029,\n",
      "         0.6186, -0.3778, -0.2782, -0.3331, -0.4043,  0.2466, -0.2373, -0.2169,\n",
      "        -0.1098, -0.7801,  0.4661, -0.4243, -0.0640, -0.5407, -0.2711, -0.4322,\n",
      "        -0.3516,  0.1728,  0.0358, -0.1077,  0.0453, -0.0735,  0.0731, -0.3845,\n",
      "         0.1299, -0.1138,  0.3935, -0.2667,  0.0614,  0.2038, -0.2226, -0.3157,\n",
      "         0.1117,  0.0907,  0.3432, -0.3549, -0.0565,  0.1534, -0.0375, -0.1938,\n",
      "        -0.0667,  0.1684, -0.0961, -0.1666, -0.1420,  0.5011,  0.5093,  0.0274,\n",
      "         0.0685, -0.0687,  0.1058,  0.1546,  0.2536,  0.0182,  0.0911, -0.0950,\n",
      "         0.2455,  0.0166, -0.0713, -0.0125, -0.0230,  0.1554,  0.0385,  0.1845,\n",
      "        -0.0539, -0.3458,  0.1142, -0.0274,  0.0309, -0.1217,  0.3847, -0.1538,\n",
      "         0.3232, -0.0159,  0.1511, -0.1291,  0.2166,  0.3048, -0.2547,  0.4814,\n",
      "        -0.1808, -0.3260, -0.2112,  0.1556,  0.4634,  0.0895,  1.0325, -0.4172,\n",
      "        -0.3879, -0.1638,  0.5175,  0.1198,  0.0634,  0.0012, -0.6681, -0.3316,\n",
      "        -0.4131, -0.2523, -0.4811, -0.0065,  0.0054, -0.6417, -0.3835, -0.1680,\n",
      "        -0.3274, -0.2741, -0.4048, -0.3631, -0.1881, -0.0964, -0.4831, -0.0077,\n",
      "        -0.2368,  0.1782, -0.4342, -0.0912, -0.1929,  0.1069, -0.2836,  0.0346,\n",
      "        -0.2926, -0.2963, -0.5859,  0.3358,  0.1279,  0.0158,  0.4355, -0.2252,\n",
      "         0.1763, -0.1062, -0.5769, -0.7068, -0.0971, -0.0339, -0.2111, -0.3659,\n",
      "        -0.2759, -0.4716, -0.1383, -0.0106, -0.4342, -0.0872, -0.3369, -0.0697],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "-------------------------------\n",
      "dec.bias_hh_l0\n",
      "Parameter containing:\n",
      "tensor([-0.0702,  0.1268, -0.9095,  0.4784,  0.6987,  0.2747, -0.1628,  0.1243,\n",
      "         0.4622,  0.0568, -0.0534, -0.0437,  0.4157,  0.1728,  0.0452, -0.1626,\n",
      "         0.2840, -0.0834,  0.5678,  0.4765,  0.0896,  0.4736, -0.1413,  0.3151,\n",
      "        -0.4534,  0.4911,  0.3065,  0.1834, -0.0992,  0.0408,  0.4232,  0.2820,\n",
      "         0.2013, -0.5663, -0.1590, -0.2907, -0.2867,  0.2210,  0.0075,  0.2798,\n",
      "        -0.3069,  0.0483,  0.4786,  0.7191,  0.3421,  0.3929,  0.4874, -0.1808,\n",
      "        -0.1199,  0.5774,  0.6584,  0.2852, -0.2084, -0.2187,  0.5411,  0.0904,\n",
      "        -0.1860,  0.2565, -0.0637,  0.2017, -0.1994, -0.1984,  0.1411, -0.0204,\n",
      "        -0.1686, -0.5280,  0.1396, -0.6457, -0.2401,  0.3035,  0.3371,  0.1168,\n",
      "        -0.5369, -0.8741, -0.6784, -0.3449, -0.7729, -0.6229,  0.5847, -0.2878,\n",
      "        -0.0898, -0.6554, -0.3690, -0.1684, -0.3448, -0.2112,  0.2966, -0.3149,\n",
      "         0.0779,  0.1253, -0.2188,  0.0428, -0.4867, -0.2674, -0.0337, -0.0205,\n",
      "        -0.4067, -0.0527,  0.4263, -0.1377, -0.2675,  0.0786,  0.0117, -0.1121,\n",
      "         0.0606, -0.6587, -0.4825, -0.3241, -0.0482,  0.7253, -0.6100, -0.5220,\n",
      "         0.6150, -0.2365, -0.1312, -0.3072, -0.5591,  0.0390, -0.2571, -0.1402,\n",
      "        -0.2217, -0.6993,  0.3700, -0.3378, -0.2086, -0.5187, -0.3185, -0.5044,\n",
      "        -0.1910,  0.0127, -0.0912, -0.2723,  0.0800, -0.0759,  0.1168, -0.4021,\n",
      "         0.1773, -0.2821,  0.3701, -0.3167, -0.0042,  0.2046, -0.0940, -0.2813,\n",
      "         0.1444,  0.0627,  0.3386, -0.4051, -0.0526,  0.0149,  0.0335, -0.1023,\n",
      "        -0.0328,  0.0529, -0.1034, -0.2267,  0.0964,  0.5661,  0.4817,  0.1616,\n",
      "         0.0423, -0.1861,  0.0366,  0.2736,  0.2418,  0.0320,  0.1502, -0.1433,\n",
      "         0.3472,  0.0071, -0.1821, -0.0211,  0.1037,  0.1785, -0.0772,  0.0762,\n",
      "        -0.1125, -0.3333,  0.0486, -0.1274, -0.1341, -0.0613,  0.1471, -0.0744,\n",
      "         0.1772, -0.0051,  0.0866, -0.1860,  0.2057,  0.4404, -0.3375,  0.4108,\n",
      "        -0.2654, -0.3920, -0.2090,  0.0851,  0.5400,  0.0424,  1.1441, -0.4214,\n",
      "        -0.4680, -0.2992,  0.5464,  0.0449, -0.1269, -0.0054, -0.7326, -0.2191,\n",
      "        -0.4500, -0.3942, -0.3998, -0.0180,  0.1011, -0.5946, -0.3655, -0.0445,\n",
      "        -0.2920, -0.2507, -0.4036, -0.2341, -0.2920, -0.1356, -0.3419, -0.1158,\n",
      "        -0.2737,  0.2265, -0.3909, -0.2615, -0.2375, -0.0052, -0.2483,  0.0636,\n",
      "        -0.2021, -0.0780, -0.4803,  0.2628,  0.1590,  0.0553,  0.2746, -0.0698,\n",
      "         0.1095,  0.0786, -0.5046, -0.6443, -0.1382, -0.0064, -0.1428, -0.3541,\n",
      "        -0.3502, -0.4140,  0.1009,  0.1137, -0.2585, -0.2139, -0.4146, -0.2185],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "-------------------------------\n",
      "dec.weight_ih_l0_reverse\n",
      "Parameter containing:\n",
      "tensor([[ 0.6608,  0.4130,  0.6704,  ...,  0.0871, -0.4929,  0.5013],\n",
      "        [ 0.0765,  0.3294, -0.0036,  ..., -0.0878, -0.7252, -0.1111],\n",
      "        [ 0.4798,  0.3363,  0.0858,  ..., -0.9169, -0.5502, -0.0900],\n",
      "        ...,\n",
      "        [-0.4903, -0.6699,  0.0583,  ...,  0.3394, -0.4587,  0.1719],\n",
      "        [ 0.0536,  0.3569,  0.1163,  ...,  0.5507, -0.0980,  0.0808],\n",
      "        [ 0.0660, -0.0391, -0.1031,  ...,  0.2015, -0.8226,  0.0269]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "-------------------------------\n",
      "dec.weight_hh_l0_reverse\n",
      "Parameter containing:\n",
      "tensor([[-0.4516,  0.5100, -0.3904,  ...,  0.0222,  0.2785,  0.2447],\n",
      "        [ 0.1652, -0.1449,  0.0428,  ..., -0.1166,  0.0629, -0.2287],\n",
      "        [-0.5152, -0.1492,  0.0237,  ...,  0.5502, -0.1277,  0.3570],\n",
      "        ...,\n",
      "        [ 0.5131, -0.3178,  0.0821,  ..., -0.1228,  0.2788, -0.0337],\n",
      "        [ 0.3275,  0.1462,  0.0558,  ..., -0.2587, -0.2218,  0.0085],\n",
      "        [ 0.1715,  0.4645, -0.1621,  ..., -0.8223, -0.1455, -0.6501]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "-------------------------------\n",
      "dec.bias_ih_l0_reverse\n",
      "Parameter containing:\n",
      "tensor([ 0.2017, -0.1931, -0.1084,  0.4607, -0.2195, -0.6568,  0.6704, -0.0210,\n",
      "        -0.4619,  0.4413,  0.0661, -0.2399,  0.2728,  0.7053,  0.6762,  0.4223,\n",
      "         0.3290, -0.0851,  0.2187,  0.1770, -0.0075, -0.2930,  0.0142,  0.0035,\n",
      "         0.1316,  0.0769, -0.4889,  0.8649,  0.2470,  0.4020,  0.5825, -0.1483,\n",
      "         0.5571,  0.2526,  0.7245,  0.2655,  0.1520,  0.0904,  0.1014,  0.2830,\n",
      "         0.0546,  0.0674,  0.1348,  0.2562,  0.0201, -0.2792,  0.1570,  0.2061,\n",
      "         0.2945, -0.0042, -0.1725, -0.3173, -0.4922,  0.3576, -0.2306,  0.6364,\n",
      "        -0.0244,  0.4138,  0.4366,  0.1876,  0.1564,  0.2533,  0.0421,  0.1268,\n",
      "        -0.2072, -0.4829, -0.4870, -0.4603, -0.3696,  0.2120, -0.3396,  0.1756,\n",
      "        -0.2813, -0.4401,  0.2050, -0.0226, -0.8500, -0.3677, -0.6500,  0.1660,\n",
      "        -0.3472, -0.6294, -0.1958, -0.6055, -0.4027, -0.1155, -0.6470, -0.5104,\n",
      "         0.0686, -0.4126,  0.1392, -0.4819, -0.1707, -0.4996, -0.2477, -0.2534,\n",
      "        -0.2010, -0.6497, -0.1052,  0.3499, -0.1566,  0.1585, -0.0942, -0.7959,\n",
      "        -0.6118, -0.4332, -0.2524, -0.0831, -0.0148, -0.3446, -0.5043,  0.1308,\n",
      "        -0.5428, -0.2862, -0.3367,  0.1388,  0.6636, -0.3045, -0.0059,  0.1138,\n",
      "        -0.1777, -0.1683,  0.0038, -0.0700, -0.2122, -0.4032,  0.3375,  0.2121,\n",
      "         0.1722, -0.2770, -0.0138, -0.1595,  0.0967, -0.0382,  0.4218, -0.2205,\n",
      "         0.4454,  0.0795,  0.2548,  0.0480,  0.2742, -0.3915,  0.0947,  0.2444,\n",
      "        -0.2319,  0.0972, -0.1908, -0.0133, -0.3070,  0.2685, -0.1180,  0.3743,\n",
      "         0.0287, -0.1544,  0.0373, -0.3711, -0.4282,  0.3715,  0.2524,  0.0660,\n",
      "        -0.1739,  0.1368,  0.4169, -0.0036, -0.2591, -0.2276,  0.4537, -0.2052,\n",
      "        -0.2424,  0.1270, -0.2304,  0.0641, -0.3202,  0.0376, -0.2340,  0.0614,\n",
      "        -0.2354,  0.2842, -0.1260, -0.1645,  0.0904, -0.0414,  0.2071, -0.5617,\n",
      "         0.0357, -0.2989,  0.0483, -0.3091,  0.3661,  0.1564,  0.6528,  0.3493,\n",
      "        -0.3727, -0.2184,  0.1198, -0.2944, -0.3525,  0.0964, -0.5314, -0.6020,\n",
      "        -0.4277, -0.3070, -0.6754, -0.2342,  0.4887,  0.2517,  0.5144, -0.1672,\n",
      "        -0.1001, -0.2011,  0.2366,  0.0937, -0.6135, -0.4519, -0.5429, -0.2855,\n",
      "        -0.3607, -0.4714,  0.0836, -0.5098, -0.5812,  0.2404,  0.3382, -0.6230,\n",
      "        -0.2976, -0.3393, -0.2890, -0.0720, -0.3452,  0.1629, -0.4750,  0.0200,\n",
      "        -0.0523,  0.0291,  0.1324, -0.4768, -0.2080, -0.5476, -0.0551, -0.2073,\n",
      "        -0.0610, -0.0022, -0.7252, -0.2499,  0.1486, -0.3154,  0.1590,  0.2355,\n",
      "         0.2043,  0.2486, -0.2675, -0.1344, -0.3997,  0.0327,  0.5864,  0.2481],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "-------------------------------\n",
      "dec.bias_hh_l0_reverse\n",
      "Parameter containing:\n",
      "tensor([ 3.8225e-01, -2.0589e-02, -1.7863e-01,  5.0588e-01, -1.2677e-01,\n",
      "        -5.8440e-01,  6.4223e-01,  1.2425e-01, -3.5735e-01,  2.6544e-01,\n",
      "         2.6706e-01, -2.2215e-01,  3.3396e-01,  8.3517e-01,  6.6595e-01,\n",
      "         4.9313e-01,  3.5411e-01, -8.8803e-02,  6.9551e-02,  2.8129e-01,\n",
      "        -4.3083e-02, -9.6771e-02, -1.1995e-02, -2.0182e-02,  2.8174e-01,\n",
      "        -6.6790e-02, -3.6053e-01,  7.0239e-01,  2.2032e-01,  2.8640e-01,\n",
      "         5.3705e-01, -1.6871e-01,  6.1836e-01,  3.6066e-01,  5.7528e-01,\n",
      "         3.6427e-01,  2.6524e-01,  8.5567e-02,  1.9257e-01,  3.7996e-01,\n",
      "        -3.5418e-04,  8.5131e-02, -6.2142e-03,  2.0001e-01,  4.1523e-03,\n",
      "        -3.3870e-01,  2.0671e-01,  1.9308e-01,  4.1624e-01, -5.4257e-02,\n",
      "        -7.4516e-02, -2.3936e-01, -3.5464e-01,  2.1155e-01, -2.3226e-01,\n",
      "         4.8266e-01,  6.1405e-02,  2.7202e-01,  5.1198e-01,  6.7122e-02,\n",
      "         8.0454e-02,  1.5413e-01,  7.2975e-02,  2.6248e-01, -7.4702e-02,\n",
      "        -3.2123e-01, -6.0349e-01, -5.3186e-01, -3.7526e-01,  1.9087e-01,\n",
      "        -2.2380e-01,  1.5668e-01, -1.3821e-01, -4.8586e-01,  3.9345e-01,\n",
      "        -9.9649e-02, -8.3196e-01, -2.5019e-01, -4.3214e-01,  2.7897e-01,\n",
      "        -3.2500e-01, -5.7797e-01, -4.6816e-02, -5.8235e-01, -3.5307e-01,\n",
      "        -1.3743e-01, -5.5906e-01, -3.8340e-01,  5.1730e-02, -2.9013e-01,\n",
      "         1.5913e-01, -5.5307e-01, -1.3911e-01, -5.1585e-01, -9.3839e-02,\n",
      "        -3.1740e-01, -1.4450e-01, -5.8454e-01, -6.1117e-02,  4.4685e-01,\n",
      "        -1.2624e-01, -6.7221e-02,  1.4450e-01, -6.9198e-01, -7.1379e-01,\n",
      "        -2.7580e-01, -4.0417e-01,  2.0734e-02, -1.6699e-01, -2.8587e-01,\n",
      "        -4.5941e-01,  1.2286e-01, -5.4680e-01, -1.8864e-01, -2.3654e-01,\n",
      "         1.8755e-01,  6.7049e-01, -2.7620e-01, -1.1153e-01,  2.4296e-01,\n",
      "        -1.7660e-01, -9.5134e-02,  1.7479e-01, -9.2708e-02, -2.6638e-01,\n",
      "        -3.5255e-01,  2.6711e-01,  2.1386e-01,  2.0182e-01, -2.3904e-01,\n",
      "        -3.7598e-02, -1.4532e-01,  2.1183e-01,  6.5664e-03,  2.5876e-01,\n",
      "        -3.0886e-01,  4.6329e-01, -6.1045e-02,  1.1153e-01,  1.5003e-01,\n",
      "         1.9532e-01, -4.3896e-01,  9.5532e-02,  2.1283e-01, -2.1817e-01,\n",
      "        -6.8223e-02, -3.5190e-02, -1.1559e-01, -2.9989e-01,  3.5688e-02,\n",
      "        -1.2336e-01,  4.9176e-01,  1.4076e-01, -1.0310e-01,  5.0200e-02,\n",
      "        -2.0139e-01, -4.0765e-01,  1.5977e-01,  1.7351e-01,  1.1099e-02,\n",
      "        -3.1285e-01, -2.0686e-02,  3.3984e-01,  1.2658e-01, -1.2074e-01,\n",
      "        -2.4252e-01,  3.3374e-01, -1.3894e-01, -1.7895e-01,  1.2089e-01,\n",
      "        -1.9441e-01,  3.3936e-02, -3.2886e-01,  2.5172e-01, -9.7039e-02,\n",
      "        -8.3461e-02, -7.7985e-03,  2.5490e-01, -1.7841e-01, -2.1173e-01,\n",
      "         1.8213e-01, -2.1784e-01,  7.5553e-02, -5.7916e-01, -3.2629e-03,\n",
      "        -3.8204e-01, -5.5019e-03, -1.2376e-01,  2.3464e-01,  1.3097e-01,\n",
      "         6.3425e-01,  3.5188e-01, -3.3642e-01, -2.4155e-01,  6.4842e-02,\n",
      "        -2.7670e-01, -3.3507e-01,  2.7636e-02, -4.5225e-01, -6.9041e-01,\n",
      "        -3.5560e-01, -3.5991e-01, -7.1874e-01, -2.6476e-01,  4.3462e-01,\n",
      "         1.9743e-01,  4.9755e-01, -9.5525e-02, -1.8213e-01, -1.4298e-01,\n",
      "         8.2495e-02,  1.5527e-02, -6.7830e-01, -4.6024e-01, -3.8519e-01,\n",
      "        -4.6733e-01, -4.6543e-01, -3.6747e-01, -2.0699e-02, -4.8659e-01,\n",
      "        -4.3926e-01,  1.2398e-01,  1.4666e-01, -5.8768e-01, -2.0873e-01,\n",
      "        -2.3456e-01, -2.9736e-01,  3.2834e-03, -4.9642e-01,  8.0557e-02,\n",
      "        -3.3743e-01,  5.5668e-02, -7.7785e-02,  1.0284e-01,  4.5058e-02,\n",
      "        -6.1356e-01, -1.1440e-01, -5.5216e-01,  6.4424e-02, -1.9543e-01,\n",
      "         5.6018e-02, -4.4901e-02, -6.5175e-01, -2.5368e-01,  1.4213e-01,\n",
      "        -2.5334e-01,  3.4783e-02,  5.0893e-02,  2.2588e-01,  1.9488e-01,\n",
      "        -9.6095e-02, -2.0257e-02, -4.1290e-01,  9.1764e-02,  7.1817e-01,\n",
      "         1.8638e-01], device='cuda:0', requires_grad=True)\n",
      "-------------------------------\n",
      "dec.weight_ih_l1\n",
      "Parameter containing:\n",
      "tensor([[-0.1785,  0.1996, -0.5517,  ..., -0.3745,  0.6613,  0.0235],\n",
      "        [-0.0863,  0.2381,  0.3677,  ...,  0.2771, -0.2556,  0.3643],\n",
      "        [-0.2950,  0.4220, -0.1136,  ..., -0.5106,  0.5182, -0.8104],\n",
      "        ...,\n",
      "        [-0.1640, -0.2386,  0.3003,  ...,  0.5264,  0.1286, -0.0042],\n",
      "        [-0.5170,  0.0794, -0.4772,  ..., -0.2137,  0.1485,  0.3340],\n",
      "        [-0.4643, -0.5377,  0.0999,  ..., -0.1114, -0.9858, -0.5528]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "-------------------------------\n",
      "dec.weight_hh_l1\n",
      "Parameter containing:\n",
      "tensor([[-0.5184, -0.8405,  0.3231,  ...,  1.0514,  0.2274,  0.4733],\n",
      "        [-0.1998, -0.2169,  0.3500,  ...,  0.7800,  0.4200,  0.2491],\n",
      "        [-0.6216,  0.3183,  1.3408,  ...,  0.0234,  0.8262,  0.5007],\n",
      "        ...,\n",
      "        [ 0.2553, -0.1950, -0.5326,  ...,  0.4675,  0.1475, -0.3362],\n",
      "        [-0.1634, -0.5716, -0.3451,  ...,  1.2402, -0.5705,  1.0071],\n",
      "        [-0.7272,  0.0120, -0.1062,  ...,  0.4457, -0.5730, -0.9701]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "-------------------------------\n",
      "dec.bias_ih_l1\n",
      "Parameter containing:\n",
      "tensor([ 0.2874,  0.1765, -0.0533,  0.0913,  0.1914,  0.0566,  0.1845,  0.6088,\n",
      "        -0.1450, -0.5653,  0.0813,  0.2823, -0.1772,  0.2214,  0.2492, -0.2431,\n",
      "         0.2684,  0.2549,  0.0648,  0.1238,  0.1165,  0.4452,  0.3490, -0.1594,\n",
      "         0.5945,  0.3069,  0.0894,  0.2950, -0.3685, -0.4054, -0.2401,  0.4435,\n",
      "        -0.4078,  0.4712, -0.3404,  0.3640,  0.4170, -0.1588,  0.0036, -0.1905,\n",
      "         0.1876,  0.2085,  0.3047, -0.0456,  0.0097,  0.1779,  0.1708,  0.1194,\n",
      "         0.1963, -0.8924, -0.5660,  0.1776,  0.0429,  0.6629,  0.0198, -0.3785,\n",
      "         0.1272,  0.2862,  0.4545, -0.3443,  0.2223, -0.8177,  0.5127, -0.3332,\n",
      "        -0.3445, -0.1135, -0.8021, -0.3779, -0.0055,  0.2364, -0.4764, -0.3744,\n",
      "        -0.0487, -0.2465, -0.0268,  0.4381, -0.0130,  0.1957, -0.3645, -0.3346,\n",
      "         0.3939,  0.4393,  0.1826, -0.3999,  0.3704, -0.5031, -0.3599,  0.2938,\n",
      "        -0.4201, -0.3646,  0.3072, -0.3455,  0.0265, -0.0717, -0.2795, -0.1556,\n",
      "         0.0823, -0.4308,  0.1749, -0.1094, -0.1628,  0.0752, -0.2803,  0.7408,\n",
      "        -0.3569,  0.7766, -0.0054,  0.3995, -0.0227, -0.0763, -0.0075,  0.0896,\n",
      "         0.3531, -0.0686,  0.4627,  0.2566,  0.1450, -0.1168,  0.0674, -0.0632,\n",
      "        -0.1373, -0.3030,  0.2841,  0.1508,  0.7169,  0.5781,  0.8244,  0.2943,\n",
      "        -0.2132, -0.2222,  0.0227, -0.0813,  0.1536,  0.0485, -0.1911,  0.1681,\n",
      "        -0.2798,  0.2358,  0.3925,  0.1214,  0.3053,  0.0735, -0.0491,  0.3709,\n",
      "         0.0308,  0.2679,  0.2141,  0.0553, -0.0037,  0.0611,  0.2336,  0.3094,\n",
      "        -0.0827,  0.0341, -0.3893, -0.1458, -0.3262, -0.1191,  0.3716, -0.1377,\n",
      "        -0.0961,  0.4652, -0.3497,  0.1360, -0.2084,  0.1044,  0.3078, -0.1465,\n",
      "         0.3656,  0.4847, -0.4930, -0.0723, -0.2230, -0.0597,  0.3243,  0.4731,\n",
      "         0.2471, -0.1875, -0.3371, -0.0453, -0.1738, -0.2566, -0.2838, -0.2079,\n",
      "        -0.1676, -0.1039, -0.1723,  0.2516,  0.2411, -0.1839,  0.2670,  0.0358,\n",
      "        -0.0377, -0.1561, -0.1198,  0.0474, -0.0122, -0.0836,  0.4301,  0.0262,\n",
      "         0.0771, -0.1923, -0.1362, -0.1832, -0.3448, -0.1890, -0.0310, -0.1369,\n",
      "        -0.5262, -0.0792, -0.1274,  0.0383, -0.2027, -0.2654,  0.0494, -0.1052,\n",
      "         0.0838,  0.2995, -0.0470,  0.0567, -0.1499, -0.1686,  0.0110, -0.0639,\n",
      "        -0.1943, -0.1198, -0.2179,  0.4974,  0.1015, -0.1054, -0.0919, -0.0246,\n",
      "         0.1622,  0.4653, -0.0846,  0.0888, -0.1465, -0.2210, -0.3480,  0.0114,\n",
      "        -0.2882,  0.1186, -0.0660,  0.1238, -0.0955,  0.0684, -0.2129,  0.0835,\n",
      "         0.1174,  0.1600, -0.2523,  0.1483,  0.1744,  0.2699,  0.5290,  0.0774],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "-------------------------------\n",
      "dec.bias_hh_l1\n",
      "Parameter containing:\n",
      "tensor([ 3.0921e-01,  1.3927e-01,  4.6453e-03,  2.6647e-01,  7.6260e-02,\n",
      "         1.1944e-01,  2.5916e-01,  5.6671e-01, -2.3834e-01, -4.5059e-01,\n",
      "         1.1748e-01,  4.2544e-01, -1.8400e-02,  9.9496e-02,  1.2960e-01,\n",
      "        -1.5345e-01,  5.7056e-02,  7.5545e-02,  1.0807e-01,  2.0170e-01,\n",
      "        -7.9095e-03,  4.2630e-01,  2.0206e-01, -2.7175e-01,  3.5362e-01,\n",
      "         1.3488e-01,  1.3584e-01,  3.0051e-01, -3.1346e-01, -3.8607e-01,\n",
      "        -1.9202e-01,  4.1905e-01, -5.2984e-01,  5.7464e-01, -1.8847e-01,\n",
      "         3.8299e-01,  4.9734e-01, -3.0222e-01, -3.5987e-02, -3.6717e-01,\n",
      "         3.3168e-01,  3.6662e-01,  3.1730e-01,  7.9932e-02, -9.7121e-02,\n",
      "         2.6570e-01,  2.6800e-01,  1.9931e-01,  1.9439e-01, -9.4984e-01,\n",
      "        -5.3682e-01, -3.7598e-02,  6.5660e-02,  4.4636e-01,  6.4867e-02,\n",
      "        -4.5070e-01,  1.8455e-01,  4.2037e-01,  4.0124e-01, -2.6328e-01,\n",
      "         2.3964e-01, -7.7045e-01,  4.8738e-01, -3.2508e-01, -4.0843e-01,\n",
      "        -6.3918e-02, -8.1725e-01, -4.4280e-01, -2.6404e-03,  2.6675e-01,\n",
      "        -5.9716e-01, -4.0522e-01,  1.8780e-01, -5.0205e-02,  6.0387e-02,\n",
      "         4.8887e-01, -4.9476e-02,  1.9407e-01, -3.6512e-01, -2.6535e-01,\n",
      "         3.5229e-01,  3.0103e-01,  2.1396e-01, -2.0805e-01,  3.1749e-01,\n",
      "        -4.5518e-01, -3.7795e-01,  4.3378e-01, -4.7218e-01, -3.9398e-01,\n",
      "         3.5270e-01, -3.5429e-01, -8.3546e-02, -1.2005e-01, -3.9331e-01,\n",
      "        -2.4453e-01, -9.6085e-02, -3.6662e-01,  7.7121e-02, -2.5655e-01,\n",
      "        -2.6836e-01,  5.7091e-04, -3.7208e-01,  8.0182e-01, -4.6960e-01,\n",
      "         6.9809e-01,  3.2598e-03,  3.4118e-01, -1.0411e-01,  4.3152e-02,\n",
      "        -7.9114e-02, -2.8845e-02,  3.6756e-01,  5.6005e-02,  4.7456e-01,\n",
      "         2.6247e-01,  2.3318e-01, -1.1385e-01,  6.8953e-02, -1.5244e-01,\n",
      "        -1.2692e-01, -3.1942e-01,  1.4680e-01,  9.3431e-02,  6.5407e-01,\n",
      "         5.5197e-01,  8.1855e-01,  1.8737e-01, -2.7429e-01, -2.2214e-01,\n",
      "        -1.2602e-01,  2.6506e-02,  1.6434e-01,  2.0675e-01, -7.5977e-02,\n",
      "         3.8759e-01, -2.6760e-01,  2.0722e-01,  3.0846e-01,  8.6469e-02,\n",
      "         1.3895e-01,  1.7341e-01,  1.1862e-01,  3.9386e-01,  1.4768e-02,\n",
      "         1.5126e-01,  1.0334e-01,  2.6033e-01, -1.7344e-01, -4.7475e-02,\n",
      "         2.9014e-01,  2.5626e-01, -1.3305e-02,  2.7388e-02, -2.9825e-01,\n",
      "        -3.1455e-02, -1.8704e-01, -5.1301e-02,  2.3789e-01, -1.1672e-01,\n",
      "        -1.8950e-01,  3.9621e-01, -2.9215e-01,  9.0338e-03, -1.7160e-01,\n",
      "         2.2639e-01,  2.9805e-01,  2.0954e-02,  2.1699e-01,  4.2765e-01,\n",
      "        -4.8922e-01, -8.7300e-02, -7.8869e-03, -2.3562e-01,  3.8267e-01,\n",
      "         4.3600e-01,  2.2090e-01, -2.2732e-01, -2.6371e-01,  9.2933e-03,\n",
      "        -4.1209e-02, -2.1214e-01, -3.1212e-01, -6.1540e-02, -9.4121e-02,\n",
      "        -9.9285e-02, -1.4270e-01,  2.6164e-01,  3.0238e-01, -1.7029e-01,\n",
      "         2.8678e-01, -1.3726e-01,  1.7427e-01, -1.3346e-01, -5.9486e-02,\n",
      "        -2.0077e-02,  3.1541e-02, -2.1071e-01,  3.2680e-01, -6.8839e-02,\n",
      "         4.0759e-02, -2.5879e-02, -3.5057e-02, -2.9618e-01, -3.0582e-01,\n",
      "        -2.4152e-01, -3.4572e-02, -8.5812e-02, -4.5030e-01, -5.7337e-03,\n",
      "        -1.2365e-01,  1.1523e-01, -1.1173e-01, -9.3096e-02,  5.5326e-02,\n",
      "        -1.2129e-01,  9.3391e-02,  2.3531e-01, -7.3549e-02,  1.2530e-01,\n",
      "        -2.3160e-01, -6.7216e-02,  8.0127e-02, -4.1363e-02, -2.3438e-01,\n",
      "        -1.2301e-01, -1.8900e-01,  4.7962e-01,  1.4841e-01, -3.4174e-01,\n",
      "        -1.2938e-01, -8.7351e-02,  1.8938e-02,  7.0518e-01, -2.4659e-01,\n",
      "         1.6518e-01,  1.5746e-02, -2.0054e-01, -3.1351e-01,  1.7473e-02,\n",
      "        -1.6994e-01,  8.2027e-02, -1.4012e-01,  4.7812e-03, -2.6862e-02,\n",
      "         5.8278e-02, -1.2452e-01, -2.1399e-02, -6.2470e-02,  1.8837e-01,\n",
      "        -9.8858e-02,  8.7702e-02,  1.2921e-01,  1.9473e-01,  5.2714e-01,\n",
      "         2.1113e-01], device='cuda:0', requires_grad=True)\n",
      "-------------------------------\n",
      "dec.weight_ih_l1_reverse\n",
      "Parameter containing:\n",
      "tensor([[ 0.2996,  0.3563, -0.4081,  ..., -0.3466,  0.1941, -0.3545],\n",
      "        [ 0.4882,  0.2329,  0.3685,  ...,  0.3885,  0.0740, -0.1350],\n",
      "        [-0.2838,  0.1316, -0.4940,  ..., -0.0681,  0.1732,  0.2789],\n",
      "        ...,\n",
      "        [ 0.3702,  0.1077, -0.1508,  ...,  0.1112,  0.0432, -0.6977],\n",
      "        [ 0.0627,  0.2011, -0.3245,  ..., -0.2577,  0.5829,  0.0098],\n",
      "        [ 0.0698, -0.0225,  0.0703,  ..., -0.2265, -0.1532, -0.2444]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "-------------------------------\n",
      "dec.weight_hh_l1_reverse\n",
      "Parameter containing:\n",
      "tensor([[-0.3397, -0.1969, -0.2003,  ...,  0.0557,  0.0740, -0.9937],\n",
      "        [ 0.2349,  0.0037, -0.3938,  ..., -0.3832,  0.3853,  0.6199],\n",
      "        [ 0.4671,  0.3635,  0.3252,  ..., -0.0698,  0.1404, -0.3258],\n",
      "        ...,\n",
      "        [-0.2795, -0.4033, -0.0965,  ...,  0.3671, -0.7177, -0.4323],\n",
      "        [ 0.3237,  0.2171, -0.3287,  ..., -0.4994,  0.0866,  0.2736],\n",
      "        [ 0.3718, -0.1611, -0.4239,  ...,  0.3330, -0.0612, -0.4586]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "-------------------------------\n",
      "dec.bias_ih_l1_reverse\n",
      "Parameter containing:\n",
      "tensor([-1.0567e-01, -3.1263e-01,  2.4742e-01, -2.5174e-01,  1.7018e-01,\n",
      "         1.2144e-01, -1.2125e-01,  3.1827e-01,  2.1093e-01,  1.6939e-01,\n",
      "        -4.4154e-01,  1.0590e-02, -2.3926e-01, -1.0274e-01, -5.4252e-02,\n",
      "         3.8606e-02, -8.9852e-02, -1.7825e-02,  9.4528e-02,  2.4176e-01,\n",
      "        -1.6954e-01, -2.3409e-01,  3.1690e-02,  3.5142e-01,  7.2669e-02,\n",
      "        -4.9696e-01, -5.1503e-01,  3.2745e-01, -3.0768e-02,  3.2173e-01,\n",
      "         9.2251e-02, -8.9428e-02, -1.5685e-01,  1.9725e-01, -4.6323e-01,\n",
      "        -3.5478e-01,  1.0912e-01, -2.1764e-01, -4.8643e-01, -3.1697e-04,\n",
      "        -2.3581e-03, -4.0080e-01,  1.2562e-01,  1.3350e-01, -1.9834e-01,\n",
      "        -2.3693e-01, -2.4059e-01,  5.4121e-01, -1.1157e-01,  1.8180e-01,\n",
      "        -6.1603e-01,  2.0992e-01, -2.3995e-01,  1.5793e-01, -3.7553e-02,\n",
      "        -3.0956e-01, -2.5949e-01,  2.4378e-02, -3.7827e-02, -2.0918e-01,\n",
      "        -2.7232e-01, -2.0123e-01, -4.3176e-01,  1.6531e-01,  5.9924e-01,\n",
      "        -1.6884e-01, -5.7414e-02, -1.4739e-01, -4.1774e-01, -3.1069e-02,\n",
      "        -5.2162e-01, -1.2654e-01, -5.6926e-01,  1.1820e-02,  1.0913e-01,\n",
      "         4.3798e-01, -7.3584e-01,  4.4669e-02,  2.3231e-01, -1.2391e-01,\n",
      "         5.6673e-01, -2.7865e-01,  1.2419e-01, -5.3495e-01, -1.5593e-01,\n",
      "        -3.8805e-01, -2.5299e-01, -3.7811e-01, -1.1957e-01, -1.8146e-01,\n",
      "        -4.7058e-01, -3.5076e-01,  7.3857e-02, -4.3904e-01,  9.9447e-02,\n",
      "        -1.6077e-01, -7.0167e-02, -3.3266e-02,  1.4312e-01, -9.7774e-02,\n",
      "         2.9814e-01,  2.8518e-01,  5.7766e-01, -4.2838e-01,  2.3026e-01,\n",
      "         2.9676e-01,  2.5836e-01, -7.4838e-02,  2.5944e-01,  2.5476e-01,\n",
      "         5.6409e-01,  2.2762e-01, -1.4605e-01, -6.5420e-01,  3.6383e-01,\n",
      "        -7.2964e-02, -6.9866e-03, -3.7601e-01,  1.2455e-02,  3.3239e-01,\n",
      "        -5.7577e-01,  5.6224e-02,  6.8770e-02,  1.1465e-01,  6.5860e-01,\n",
      "         2.0664e-01, -1.0618e-01, -4.4226e-01, -3.8010e-01, -7.4983e-02,\n",
      "         2.7615e-01,  1.9632e-01,  7.2501e-02, -1.1161e-01, -2.4839e-03,\n",
      "        -1.2498e-01, -2.0110e-01,  4.5885e-01,  3.7377e-02,  1.7027e-02,\n",
      "        -3.6488e-01,  8.6180e-02,  1.8814e-01, -5.7352e-02, -1.3079e-01,\n",
      "        -4.2248e-02,  5.8475e-02,  2.4381e-01,  1.5677e-01,  8.2474e-02,\n",
      "        -3.3246e-01, -2.3132e-01,  5.6657e-02,  3.8502e-01,  2.2992e-01,\n",
      "        -4.0050e-01,  3.3041e-02,  4.1867e-01,  3.0398e-01,  4.9862e-01,\n",
      "         2.4008e-01,  3.3182e-01, -1.1102e-01,  3.6557e-01, -2.2774e-01,\n",
      "         2.4800e-01, -3.2147e-01,  1.1625e-01,  2.9134e-01,  1.1411e-01,\n",
      "        -1.8614e-01,  1.1845e-01,  5.0315e-02,  4.9090e-02, -2.3563e-01,\n",
      "         3.7056e-01, -9.6905e-02, -9.2329e-02,  1.5438e-01, -2.5559e-01,\n",
      "         2.0868e-01,  2.0707e-02,  3.8694e-01,  1.2066e-01, -4.0594e-01,\n",
      "         4.3720e-01,  3.4050e-01, -1.7020e-01, -2.2328e-01, -3.2178e-01,\n",
      "         1.6148e-01,  3.5618e-02,  1.1701e-01, -3.1156e-01, -3.1759e-02,\n",
      "        -3.2785e-01,  1.5177e-01, -1.0042e-02, -9.3494e-02, -1.0685e-01,\n",
      "         4.4696e-01, -7.7794e-02, -2.5878e-01,  1.9801e-01,  5.8119e-01,\n",
      "        -2.4392e-02, -3.5484e-01,  5.6879e-02, -3.2573e-01, -3.3932e-01,\n",
      "        -2.3715e-01, -7.9505e-02,  3.5749e-01,  6.3356e-02, -1.2982e-01,\n",
      "         1.4850e-02, -8.0993e-02, -4.8075e-01,  4.8759e-02, -4.0752e-01,\n",
      "         4.8160e-02, -2.5173e-01, -1.1094e-01, -1.3027e-01, -2.3752e-01,\n",
      "        -3.1684e-01,  4.0348e-01,  6.1431e-02, -8.5032e-02,  3.5454e-01,\n",
      "         2.7069e-01,  1.2634e-01, -3.4930e-01, -2.7074e-02, -3.5387e-01,\n",
      "         5.0712e-02, -1.6653e-01, -4.8377e-02,  2.6981e-01, -7.5213e-02,\n",
      "         2.1131e-01,  1.8534e-01, -1.5952e-01, -3.8425e-01, -2.7560e-01,\n",
      "        -4.2810e-01, -8.3138e-02, -3.7516e-02, -1.9861e-01, -1.7086e-01,\n",
      "         8.3527e-02, -1.2669e-01,  1.5409e-01, -1.5311e-01,  8.4159e-04,\n",
      "         1.1634e-01], device='cuda:0', requires_grad=True)\n",
      "-------------------------------\n",
      "dec.bias_hh_l1_reverse\n",
      "Parameter containing:\n",
      "tensor([-0.2043, -0.3718,  0.1233, -0.1554,  0.1666,  0.1370, -0.2481,  0.1952,\n",
      "         0.2147,  0.2432, -0.4280,  0.0152, -0.3426, -0.2126, -0.0530, -0.0431,\n",
      "        -0.0741, -0.1853,  0.0089,  0.2764, -0.1081, -0.0838, -0.0702,  0.2729,\n",
      "         0.2381, -0.4053, -0.4973,  0.3726, -0.0891,  0.3140,  0.1425,  0.0568,\n",
      "        -0.2281,  0.1444, -0.3096, -0.3240, -0.0783, -0.3681, -0.3360, -0.0014,\n",
      "        -0.0425, -0.4368,  0.1793, -0.0350, -0.1496, -0.2426, -0.3129,  0.6373,\n",
      "        -0.0496,  0.0935, -0.4668,  0.3530, -0.3167, -0.0043,  0.1454, -0.2305,\n",
      "        -0.2769,  0.0880,  0.0022, -0.1048, -0.0904, -0.0151, -0.4442,  0.3030,\n",
      "         0.4119, -0.1430, -0.0291, -0.1381, -0.4570,  0.0587, -0.5228, -0.1291,\n",
      "        -0.7190, -0.0716,  0.1294,  0.5635, -0.7284,  0.1870,  0.3630, -0.2416,\n",
      "         0.5532, -0.2682, -0.0439, -0.5134, -0.0911, -0.4473, -0.1529, -0.3244,\n",
      "        -0.2956, -0.1391, -0.4649, -0.4491,  0.0238, -0.3033,  0.0551, -0.2781,\n",
      "        -0.1173, -0.0893,  0.3254, -0.0549,  0.3271,  0.0514,  0.7121, -0.2354,\n",
      "         0.2821,  0.3345,  0.3461, -0.0365,  0.3478,  0.2332,  0.5854,  0.3962,\n",
      "        -0.2886, -0.6723,  0.4146, -0.0496,  0.0129, -0.4323, -0.1750,  0.2370,\n",
      "        -0.4077,  0.0963,  0.1081,  0.2065,  0.6518,  0.1576,  0.0402, -0.5289,\n",
      "        -0.4142,  0.0480,  0.2335,  0.2687,  0.2825, -0.2254, -0.0179, -0.1610,\n",
      "        -0.2310,  0.3787, -0.0521,  0.1444, -0.3864,  0.1170,  0.2892, -0.2025,\n",
      "        -0.0519,  0.0224,  0.0030,  0.0316,  0.1302, -0.0523, -0.2758, -0.2461,\n",
      "         0.0756,  0.3605,  0.1823, -0.4558,  0.0769,  0.4936,  0.0839,  0.3710,\n",
      "         0.3057,  0.2600,  0.0540,  0.3662, -0.0982,  0.1639, -0.1565,  0.1387,\n",
      "         0.3394,  0.2306, -0.1907,  0.0010,  0.0501, -0.0566, -0.0474,  0.4020,\n",
      "        -0.3105,  0.0747,  0.1259, -0.4122,  0.1383,  0.0381,  0.4454,  0.1656,\n",
      "        -0.2501,  0.4580,  0.2295, -0.1771, -0.0819, -0.2321,  0.2391,  0.1392,\n",
      "         0.2811, -0.2805, -0.0732, -0.2579,  0.0632, -0.1067, -0.1952, -0.0925,\n",
      "         0.3251, -0.0689, -0.2827,  0.1873,  0.3800, -0.1408, -0.2753,  0.1770,\n",
      "        -0.3481, -0.3171, -0.3622, -0.1454,  0.3970, -0.0428, -0.3074, -0.1250,\n",
      "        -0.1087, -0.4677, -0.0910, -0.3245, -0.1070, -0.3212, -0.0670, -0.0198,\n",
      "        -0.1586, -0.4469,  0.4323, -0.0574,  0.0140,  0.3427,  0.3858,  0.1860,\n",
      "        -0.2453,  0.0726, -0.2926, -0.0152, -0.0865, -0.0365,  0.2388,  0.0231,\n",
      "         0.2283,  0.3084, -0.1369, -0.2373, -0.2136, -0.3894, -0.0911, -0.1624,\n",
      "        -0.0995, -0.1199,  0.0125, -0.2185,  0.1078, -0.1231, -0.0380,  0.0361],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "-------------------------------\n",
      "emb.weight\n",
      "Parameter containing:\n",
      "tensor([[ 1.3883, -0.2476,  0.2552,  ...,  0.0677,  1.3257,  0.8114],\n",
      "        [ 0.9807,  0.1526, -1.8136,  ...,  0.6633, -0.0154, -0.6805],\n",
      "        [ 0.3834,  0.5871,  0.6329,  ..., -0.4487, -0.6847, -0.9418],\n",
      "        ...,\n",
      "        [ 0.1919,  0.3474,  0.2540,  ..., -0.6307, -0.4799, -0.8840],\n",
      "        [ 2.1452,  2.5686, -1.2354,  ..., -0.9120,  0.0647, -0.4639],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "-------------------------------\n",
      "gnn1.conv_layers.0.bias\n",
      "Parameter containing:\n",
      "tensor([ 0.5441, -0.1274, -0.1475, -0.4997, -0.4888, -0.0689, -0.3399,  0.3190,\n",
      "         0.5074, -0.2753,  0.3389,  0.0077,  0.0586,  0.2971, -0.1631,  0.0267,\n",
      "         0.1173,  0.4981, -0.1609, -0.1802, -0.1079, -0.1175, -0.2100, -0.3297,\n",
      "        -0.1085, -0.1109, -0.2616, -0.1254, -0.0560, -0.1336, -0.2538, -0.2216],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "-------------------------------\n",
      "gnn1.conv_layers.0.lin.weight\n",
      "Parameter containing:\n",
      "tensor([[-0.4466,  0.4065,  0.0035,  ...,  0.5093, -0.4217,  0.0915],\n",
      "        [-0.0064, -0.1379, -0.0519,  ...,  0.0722,  0.0545, -0.0437],\n",
      "        [ 0.0424, -0.1487,  0.1261,  ...,  0.1432, -0.1890, -0.0656],\n",
      "        ...,\n",
      "        [-0.0705, -0.1115, -0.0318,  ..., -0.2117,  0.1170,  0.0540],\n",
      "        [-0.0931, -0.2549, -0.0538,  ..., -0.2058, -0.0356, -0.0648],\n",
      "        [-0.0227, -0.2483,  0.0834,  ..., -0.0328, -0.0831,  0.0098]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "-------------------------------\n",
      "gnn1.conv_layers.1.bias\n",
      "Parameter containing:\n",
      "tensor([ 0.1233, -0.0169,  0.1635, -0.1489,  0.5826,  0.3853,  0.1361,  0.3700,\n",
      "        -0.2920,  0.5914, -0.2081, -0.1823,  0.6995, -0.0983, -0.5176,  0.4321],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "-------------------------------\n",
      "gnn1.conv_layers.1.lin.weight\n",
      "Parameter containing:\n",
      "tensor([[ 7.3921e-01,  8.0401e-02,  9.6164e-02,  1.1693e-01,  1.3898e-01,\n",
      "          6.3826e-03, -6.9148e-01,  1.1934e-01, -5.0701e-01, -2.8391e-01,\n",
      "         -2.2284e-01,  7.6438e-01,  2.2994e-01, -3.7407e-02,  1.1986e-02,\n",
      "         -1.0656e+00,  1.2273e-01,  5.4770e-01,  3.7333e-02, -6.9717e-01,\n",
      "          4.1120e-01, -1.3894e-01, -5.9927e-02, -2.4676e-01, -2.2908e-02,\n",
      "          5.6574e-02,  4.8334e-03, -3.3861e-01,  1.4285e-02,  2.7301e-01,\n",
      "         -1.4235e-01,  1.6461e-01],\n",
      "        [-3.1438e-01, -1.2534e-03, -1.7082e-01,  2.1349e-01,  3.8756e-01,\n",
      "          1.8046e-01,  5.2254e-01, -9.0496e-01,  6.9896e-02, -4.0174e-01,\n",
      "         -7.5096e-01, -5.2385e-01, -7.5786e-01, -2.8049e-01, -3.9442e-02,\n",
      "         -1.7875e-01,  1.8550e-01, -5.3546e-01,  4.2984e-02,  3.8160e-02,\n",
      "          2.9358e-01,  2.2427e-02,  1.1793e-01, -9.1235e-02, -5.4997e-02,\n",
      "         -8.9063e-03,  2.8496e-02, -5.4827e-01, -3.0733e-01,  2.1823e-02,\n",
      "         -1.0311e-01, -3.5284e-01],\n",
      "        [ 5.3410e-01,  1.0988e-01, -7.8121e-02, -9.5150e-02, -3.2056e-01,\n",
      "          4.6414e-01, -6.9486e-01, -4.6801e-01, -1.8812e-01, -5.8711e-01,\n",
      "          5.1962e-02, -4.8314e-02,  4.6894e-01,  2.1914e-01,  1.4755e-01,\n",
      "         -7.6775e-01,  2.8849e-01,  1.6976e-01,  1.0807e-03, -1.3989e-01,\n",
      "         -5.0066e-01,  3.1179e-01, -1.7903e-01,  2.1936e-01,  1.7926e-01,\n",
      "         -5.7948e-02, -8.8341e-01,  1.2146e-01, -1.7712e-01, -3.3401e-01,\n",
      "         -3.0706e-01,  1.2551e-01],\n",
      "        [-1.2444e-01,  1.2966e-02, -6.3857e-03, -1.5710e-01, -5.8005e-02,\n",
      "          5.2317e-01,  1.2413e+00,  3.0412e-01,  4.6664e-02, -7.1508e-01,\n",
      "         -1.2153e+00,  1.2942e-01,  1.0146e-01,  7.4320e-01, -1.1575e-02,\n",
      "          7.0565e-01, -1.9180e-01, -1.8311e-01, -1.9737e-01,  4.3902e-03,\n",
      "          4.2647e-01, -1.9779e-01,  3.4778e-01, -3.0305e-01,  2.1429e-01,\n",
      "         -2.6387e-01,  1.4194e-01,  5.4740e-02,  2.4337e-01, -3.8748e-01,\n",
      "         -3.5865e-01, -8.3631e-02],\n",
      "        [-9.2405e-01,  2.5304e-01, -7.8717e-01, -1.9408e-01, -2.7146e-01,\n",
      "          7.2615e-01, -1.7634e-02,  4.5332e-01,  7.5086e-01, -4.9932e-02,\n",
      "          5.6883e-01,  6.7197e-02,  1.1808e-01,  1.3903e+00,  1.0486e-01,\n",
      "          6.7873e-01, -1.5941e-01,  2.2898e-01,  9.2052e-02,  3.9204e-02,\n",
      "         -4.9808e-01, -7.9412e-01, -8.3409e-02,  3.0720e-01, -4.1524e-01,\n",
      "         -4.8868e-01,  1.3480e-01,  5.1590e-01,  1.2041e-01,  7.8341e-02,\n",
      "         -1.2316e+00,  6.1848e-01],\n",
      "        [-2.3583e-01,  2.1048e-02, -3.3259e-01, -3.6816e-01, -6.0172e-01,\n",
      "         -7.8807e-02, -2.2836e-01, -5.4527e-01, -3.3877e-01,  4.4693e-01,\n",
      "          2.5042e-01,  3.9363e-01, -4.1039e-01,  3.7507e-01,  3.5463e-01,\n",
      "          2.0908e-02, -6.4072e-02, -7.3465e-01,  2.1023e-01, -1.7326e-01,\n",
      "          4.5816e-01, -1.0050e-02, -3.1551e-01,  9.9883e-02, -3.8217e-01,\n",
      "          1.4265e-01, -3.1443e-01,  2.6369e-01, -2.1878e-01,  2.5075e-02,\n",
      "         -5.6756e-01, -3.1671e-02],\n",
      "        [ 1.7057e-01,  2.7290e-01, -2.3076e-02, -3.9421e-01, -1.6960e-01,\n",
      "         -7.3303e-01, -1.2720e-01,  5.8756e-01, -3.7053e-01, -9.7661e-02,\n",
      "          3.9390e-01,  1.1233e-01,  6.7292e-01, -5.9117e-01,  4.6522e-02,\n",
      "          2.8442e-01, -3.0212e-01,  9.2882e-01,  9.4795e-02, -7.0662e-03,\n",
      "          1.0163e-01,  1.1804e-02,  8.5922e-02,  1.9429e-01,  4.6548e-01,\n",
      "          3.0269e-01, -1.9104e-02,  3.8762e-02,  4.7291e-01, -1.4614e-01,\n",
      "         -8.0415e-01, -2.9605e-01],\n",
      "        [ 6.1876e-02, -1.6840e-01, -2.2839e-01, -1.3887e-01, -4.5198e-01,\n",
      "         -1.6684e-01, -8.4442e-01,  3.4723e-01,  1.0119e+00, -1.6111e-01,\n",
      "          4.8938e-01,  5.9156e-01, -4.1512e-01,  3.7937e-01,  1.0729e-01,\n",
      "         -3.9997e-03,  1.8248e-01, -2.0140e-01,  1.2980e-01,  1.5706e-01,\n",
      "          3.7435e-01,  2.2827e-01,  2.8964e-02, -4.5516e-01,  6.9291e-02,\n",
      "          5.8693e-02, -3.4499e-01,  1.2686e-01, -1.7155e-01, -2.9165e-01,\n",
      "         -3.6574e-01, -1.4634e-01],\n",
      "        [-4.0153e-01,  3.2781e-02,  1.8573e-01,  2.0838e-01,  2.0269e-01,\n",
      "         -2.6713e-01,  2.9838e-01,  2.6424e-01, -1.9162e-01,  2.5566e-01,\n",
      "         -2.0159e-02, -8.5471e-02, -5.5143e-01, -9.4743e-02,  2.6616e-02,\n",
      "         -5.8740e-02,  1.7138e-01, -2.8301e-01,  3.8936e-01,  3.2664e-01,\n",
      "         -5.9603e-01, -3.6817e-01,  6.2874e-01, -1.2849e-01,  3.3062e-01,\n",
      "          2.7393e-02, -3.0209e-03, -5.3183e-01,  2.2083e-01, -3.2471e-02,\n",
      "          4.0492e-01,  4.3657e-02],\n",
      "        [ 8.2157e-01, -2.7043e-01,  2.6510e-01, -4.6901e-01, -9.8083e-02,\n",
      "         -7.3689e-01,  4.7363e-01, -2.3882e-01, -4.1060e-01, -8.7061e-01,\n",
      "          4.1374e-01,  8.7309e-02,  1.6094e+00,  3.6719e-01,  3.2503e-01,\n",
      "          4.3061e-01,  6.4321e-02,  5.6568e-01, -3.8736e-02, -1.6703e-01,\n",
      "          4.2640e-01, -6.9404e-02,  3.7649e-02, -7.7603e-01,  1.3478e-01,\n",
      "          4.1300e-01, -1.9609e-02, -4.9909e-01, -2.6725e-01, -6.3644e-01,\n",
      "          2.4992e-01,  2.0277e-01],\n",
      "        [-8.4024e-01,  5.3046e-01,  3.9287e-01,  4.3172e-01,  7.3997e-01,\n",
      "         -5.2995e-02, -3.3013e-01, -5.5084e-01, -4.0505e-01,  3.2961e-01,\n",
      "         -1.6189e-02,  1.1099e-02, -1.1275e-02, -2.1415e-01, -2.8096e-01,\n",
      "         -3.8652e-01, -4.3742e-01, -4.6430e-01,  3.9010e-01, -2.2658e-01,\n",
      "          4.1866e-01,  4.0546e-01,  2.7533e-02,  5.0999e-03,  6.0381e-02,\n",
      "         -4.5789e-02,  4.1080e-01,  2.9327e-01,  9.4750e-02,  4.1408e-01,\n",
      "         -5.2894e-02, -6.4483e-02],\n",
      "        [-7.3119e-01,  6.1150e-01, -1.4466e-01, -1.5383e-01,  1.3399e-01,\n",
      "          1.3235e-01, -2.7404e-01, -1.0855e-01, -1.0212e-02,  8.9526e-02,\n",
      "         -1.1046e-01, -1.0031e-01, -3.8588e-01, -1.6469e-01,  3.6727e-01,\n",
      "          3.6447e-01, -5.5739e-01, -2.4321e-01,  4.7274e-01,  3.2179e-01,\n",
      "         -1.7262e-02,  3.1529e-01, -7.0030e-02, -1.2462e-01,  8.9234e-02,\n",
      "         -4.7253e-01, -1.1153e-01,  1.7551e-01, -3.9048e-02,  2.5306e-01,\n",
      "          5.6928e-01, -2.4578e-01],\n",
      "        [ 8.0437e-01, -9.2954e-02,  4.1268e-01, -4.6578e-01, -6.1967e-01,\n",
      "          4.0767e-01, -7.6498e-01,  1.4203e-01, -8.2897e-01, -5.1009e-02,\n",
      "          7.2960e-01,  5.8776e-01, -1.7380e-01,  1.1502e-01,  6.7406e-01,\n",
      "          2.3651e-01, -6.1886e-01,  4.5150e-01, -1.5652e-01, -3.6491e-01,\n",
      "          9.0476e-02, -1.0695e-01,  4.7374e-02, -8.4202e-01, -1.8955e-01,\n",
      "          2.0913e-01, -1.5924e-01,  3.4488e-01, -5.6288e-01,  4.2617e-01,\n",
      "         -5.1843e-01, -4.7687e-01],\n",
      "        [-6.8575e-01, -3.3798e-01,  3.5201e-01,  2.5897e-01,  7.0069e-01,\n",
      "         -2.4845e-01, -4.6252e-01,  1.5202e-02,  1.0093e-01, -3.0437e-01,\n",
      "         -3.0089e-01,  2.2790e-01,  4.0066e-01, -7.0134e-01,  3.5317e-01,\n",
      "         -3.1751e-01, -4.2075e-01, -2.6534e-01, -2.5954e-01,  1.1831e-01,\n",
      "          1.3478e-01,  8.7379e-02,  2.1257e-01, -3.9364e-02, -9.6544e-02,\n",
      "          2.0458e-01, -2.7787e-01,  3.9646e-01,  2.2073e-02,  4.1133e-01,\n",
      "          3.1252e-01, -1.0575e-01],\n",
      "        [-5.8308e-01,  3.5799e-01, -1.8666e-01,  5.6790e-01,  5.9405e-01,\n",
      "          7.4410e-02,  3.2290e-01,  3.0347e-02, -2.1525e-01,  1.2404e-01,\n",
      "         -1.6584e-01, -1.8785e-01,  7.9124e-02, -2.2644e-02, -9.4682e-02,\n",
      "         -1.5852e-01, -5.3903e-01, -1.3294e-02, -4.6049e-01, -5.7145e-02,\n",
      "          1.4095e-01,  3.6689e-01, -9.8300e-02,  5.1437e-01, -1.2000e-01,\n",
      "          3.3197e-01,  4.3341e-01, -1.7449e-01,  7.0858e-02,  3.9673e-01,\n",
      "         -1.0381e-01,  2.0726e-01],\n",
      "        [ 3.3162e-01, -3.0670e-02,  4.7298e-01, -3.2833e-01, -4.2941e-01,\n",
      "         -5.2687e-02,  1.2486e-01,  3.0143e-01,  6.0602e-01, -9.2164e-02,\n",
      "         -1.0470e-01, -4.1246e-02,  1.8795e-01,  3.3252e-01, -1.5968e-01,\n",
      "          4.4555e-01,  4.1408e-01,  4.3781e-01, -2.0452e-01, -5.3779e-01,\n",
      "          2.9637e-01,  8.0916e-02, -2.2573e-01,  1.4666e-01,  2.2277e-01,\n",
      "          2.5888e-01,  3.2880e-01,  4.2204e-01, -2.1908e-01,  1.8281e-01,\n",
      "         -3.3814e-01, -6.2048e-02]], device='cuda:0', requires_grad=True)\n",
      "-------------------------------\n",
      "gnn1.fc.weight\n",
      "Parameter containing:\n",
      "tensor([[-0.1064,  0.2962, -0.3272,  ..., -0.3956, -0.3170, -0.1508],\n",
      "        [ 0.9978, -0.4023,  0.4464,  ...,  0.8097,  0.2290,  0.7378],\n",
      "        [ 0.3153,  0.4825,  0.2214,  ..., -0.6816, -0.1818, -0.3998],\n",
      "        ...,\n",
      "        [ 0.0703, -0.4657,  0.3266,  ...,  0.5410,  0.2019,  0.1017],\n",
      "        [ 0.4771, -0.0420,  0.0462,  ...,  0.5799,  0.3916,  0.8553],\n",
      "        [-0.9560,  0.2579, -0.8024,  ..., -0.4818, -0.1714, -0.1051]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "-------------------------------\n",
      "gnn1.fc.bias\n",
      "Parameter containing:\n",
      "tensor([-0.7023,  1.1815, -0.1078, -0.8061, -0.9809,  0.7810, -0.8642,  0.5309,\n",
      "        -0.6369, -0.7501, -1.1043,  0.8739,  1.0900, -0.4616, -0.5669,  0.3186,\n",
      "        -0.7688, -0.7973,  0.4743, -0.9323,  0.5012,  0.7883,  0.8277,  1.2310,\n",
      "        -0.2681, -0.9026, -0.9564, -1.1321,  0.6872, -0.5526,  0.8992,  0.3645,\n",
      "         1.1683,  0.0391,  0.4344,  0.7071,  1.0174, -0.2470, -0.2350,  1.2544,\n",
      "         1.0752, -0.5351, -0.8249,  0.1025, -1.0000,  0.7567, -0.0823,  0.9115,\n",
      "        -0.8844, -1.1307, -0.2747,  1.0337, -0.3057, -0.2038, -0.8634,  0.0143,\n",
      "        -0.1332,  0.1362, -1.2955,  0.0729,  0.7164,  0.1887,  1.0691, -1.0793,\n",
      "        -0.9462,  0.4907, -1.0461, -0.0207, -0.0240, -1.1488, -0.2316, -0.3733,\n",
      "         1.1496, -0.3541,  1.3116,  0.9499,  0.3051,  1.1903,  1.0704,  0.3213,\n",
      "         1.0663,  1.2076, -0.1685, -0.3426, -0.5818,  0.9503,  0.0073,  1.1203,\n",
      "        -0.2388, -1.1148,  0.6065,  1.2007, -1.0847,  0.8537, -0.8612,  0.5284,\n",
      "        -1.1078, -0.3410, -0.6514, -0.0244, -0.2146,  0.1123,  1.1676, -0.3575,\n",
      "         0.2509, -0.2274,  1.2607,  0.7228, -0.5290,  0.2984, -0.6631,  1.0738,\n",
      "        -0.9819, -0.3958, -1.0216,  1.0779,  1.0361, -0.6915, -1.2223,  0.2516,\n",
      "        -0.3212, -0.0713, -1.1425,  1.0181, -0.9296,  1.0690,  0.8284,  0.4948,\n",
      "         0.3514,  1.1076, -0.3578, -1.2282,  0.1246, -0.5595, -0.8207,  0.8973,\n",
      "        -1.1182, -0.5864,  0.8748, -1.0259, -1.0594,  1.4473, -0.7118,  1.2396,\n",
      "         0.7008, -1.1005, -1.1558,  0.3217, -1.0287, -0.5701, -0.9272,  0.8116,\n",
      "        -0.8085, -1.0745, -0.6993,  0.3177,  0.7717,  1.1465,  0.4921, -1.0654,\n",
      "         0.5786,  1.0215, -0.3902, -0.3084,  0.4012,  0.8240,  0.7950,  0.0429,\n",
      "         0.9325, -0.3478, -0.6936, -1.1162,  0.2040, -0.7625, -0.6748, -0.9757,\n",
      "         0.9549, -0.6335, -0.4210,  0.3681, -1.2235, -0.0813,  0.9789,  0.4709,\n",
      "         0.3142,  0.9618, -1.1668, -0.3990, -0.6927, -0.2475, -0.5967, -0.0323,\n",
      "        -1.3840, -0.4390,  0.9897, -0.4532,  0.0347,  1.0354,  0.3468, -0.5152,\n",
      "         0.1966, -0.9089,  0.4954, -0.2926,  0.2632,  0.5749,  1.2561,  0.2433,\n",
      "        -1.0133, -0.2028, -0.7793,  0.9249,  0.6451,  0.7144, -1.2462,  0.8937,\n",
      "        -0.4239, -0.5879,  0.6967, -0.9288,  0.1840,  0.7685,  1.0562, -0.9185,\n",
      "         0.8358,  0.5376, -0.5155, -0.7643, -0.1695,  0.9768,  0.6628, -0.9565,\n",
      "        -0.6946, -0.0896, -0.6892, -0.5825, -0.7528, -0.2073, -0.8556,  1.0792,\n",
      "        -0.3676,  0.5349, -1.3648, -0.9261, -0.2224, -0.9374,  1.1752,  0.8268,\n",
      "        -0.1246,  1.2488, -1.0189, -0.7420, -1.0354,  0.6445,  1.1519, -1.1535],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "-------------------------------\n",
      "gnn2.conv_layers.0.bias\n",
      "Parameter containing:\n",
      "tensor([-0.0102, -0.3104, -0.5485,  0.2883,  0.3019, -0.1584,  0.2408, -0.0989,\n",
      "        -0.3101, -0.1753,  0.0107, -0.0576, -0.3922,  0.2328, -0.1584, -0.3833,\n",
      "        -0.0864,  0.1109,  0.0148,  0.0598, -0.0970, -0.0696, -0.2963,  0.5353,\n",
      "         0.2232, -0.0517,  0.3256, -0.4224,  0.6543,  0.0842, -0.0437,  0.5710],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "-------------------------------\n",
      "gnn2.conv_layers.0.lin.weight\n",
      "Parameter containing:\n",
      "tensor([[-0.1119,  0.0838, -0.0553,  ..., -0.1337,  0.1118,  0.0619],\n",
      "        [ 0.0711, -0.0511,  0.0706,  ..., -0.3241,  0.0039, -0.0214],\n",
      "        [ 0.0759, -0.3520,  0.0436,  ..., -0.4673, -0.1424, -0.0383],\n",
      "        ...,\n",
      "        [-0.0172,  0.1116,  0.2687,  ..., -0.1738, -0.3364,  0.1284],\n",
      "        [-0.0090, -0.1130, -0.0050,  ..., -0.1676, -0.0659,  0.0365],\n",
      "        [-0.0339,  0.4728, -0.1446,  ...,  0.1696,  0.1208, -0.2909]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "-------------------------------\n",
      "gnn2.conv_layers.1.bias\n",
      "Parameter containing:\n",
      "tensor([ 0.5463,  0.5400,  0.5544,  0.2902,  0.1476,  0.4939,  0.1654,  0.3490,\n",
      "        -0.0466, -0.8971,  0.1531,  0.6859,  0.0596, -0.0267,  0.1256,  0.4700],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "-------------------------------\n",
      "gnn2.conv_layers.1.lin.weight\n",
      "Parameter containing:\n",
      "tensor([[-0.2235, -0.6867, -0.1929,  0.0767, -0.0764,  0.3934,  0.0916,  0.1956,\n",
      "         -0.0283, -0.4496,  0.1442, -0.0199, -0.4729,  0.6508,  0.1557, -0.0843,\n",
      "         -0.2487,  0.4308,  0.0757,  0.2187,  0.0667,  0.2623, -0.0109,  0.6746,\n",
      "          0.3793, -0.2479, -0.3359, -0.3107,  0.6695,  0.1538, -0.1364,  0.9170],\n",
      "        [-0.6231, -0.3667, -0.7027,  0.6584,  0.4733, -0.1660,  0.3865,  0.2890,\n",
      "          0.2214, -0.5281,  0.4626,  0.0017,  0.0270,  0.4602,  0.1847, -0.0292,\n",
      "          0.1465,  0.6901, -0.2819,  0.0666, -0.1126, -0.2672, -0.3673,  0.5875,\n",
      "          0.3291,  0.4715, -0.2594, -0.5730,  0.9647,  0.6235, -0.1517,  0.2309],\n",
      "        [ 0.1225, -0.6120, -0.2029, -0.3044,  0.6083, -0.5015,  0.5416, -0.0607,\n",
      "         -0.3337, -0.0249, -0.2140,  0.0481, -0.6107, -0.2858,  0.3610, -0.7882,\n",
      "          0.1526, -0.1865,  0.1011,  0.3991,  0.0245,  0.0569,  0.3813,  0.8047,\n",
      "          0.3374,  0.1274,  0.3006,  0.2851,  0.1353,  0.5050,  0.1872,  0.3250],\n",
      "        [-0.0089, -0.0941, -0.6629, -0.0861, -0.0971, -0.2617,  0.2623,  0.0619,\n",
      "         -0.5009, -0.1647, -0.1535, -0.3790, -0.5948,  0.8536,  0.2087, -0.2673,\n",
      "          0.2304,  0.0558, -0.0079,  0.1903,  0.1556, -0.1829, -0.2155,  0.2643,\n",
      "          0.0479, -0.4908,  0.1057,  0.2144,  0.2174, -0.1950, -0.0293,  0.3371],\n",
      "        [ 0.0027,  1.1596, -0.4855, -0.1180,  0.1789,  0.3018,  0.1931, -0.0414,\n",
      "         -0.1532, -0.2116, -0.1093,  0.0858, -0.2035, -0.4662,  0.0366,  0.0318,\n",
      "          0.1873, -0.1955,  0.5462,  0.3261, -0.3696,  0.3223,  0.9804, -0.0914,\n",
      "          0.0578,  0.3459, -0.1140, -0.2424, -0.0118, -0.1439, -0.2736, -0.0670],\n",
      "        [-0.4688, -0.4913, -0.4928, -0.3532,  0.5094, -0.2200,  0.1303,  0.3163,\n",
      "         -0.4019, -0.1632,  0.5627, -0.1751,  0.0752, -0.5150,  0.0666,  0.1598,\n",
      "         -0.0515,  0.1953,  0.2379,  0.5696, -0.1376,  0.1404, -0.2303,  0.8909,\n",
      "          0.1834,  0.2641,  0.0748, -0.4712,  0.0104,  0.4082,  0.2129, -0.1765],\n",
      "        [ 0.2689,  0.5670, -0.2247, -0.8134,  0.0790,  0.1348,  0.3594, -0.0479,\n",
      "          0.0780, -0.1445, -0.0386,  0.0446,  0.3932,  0.3037,  0.3028,  0.2052,\n",
      "          0.1518,  0.2603,  0.4496, -0.0331, -0.1249,  0.3753,  0.8547,  0.0190,\n",
      "          0.5305,  0.0622, -0.2628,  0.2177,  0.6714, -0.2774,  0.0042,  0.4436],\n",
      "        [ 0.1545, -0.0907, -0.2247,  0.6788, -0.1693, -0.4179, -0.0947,  0.0439,\n",
      "         -0.0405, -0.2305,  0.4907, -0.2081,  0.0685, -0.1567,  0.1528,  0.1032,\n",
      "         -0.0374, -0.1646,  0.3466,  0.3093,  0.0052, -0.5203, -0.9581,  0.5152,\n",
      "          0.4134,  0.3861, -0.0645, -0.5052,  0.6806,  0.2870,  0.0895,  0.5474],\n",
      "        [ 0.0554, -0.1809,  0.2441,  0.3881, -0.3747, -0.1387, -0.5361,  0.5468,\n",
      "          0.4496,  0.3705, -0.1790, -0.3553,  0.2834, -0.6659,  0.3552,  0.9214,\n",
      "         -0.3634, -0.2639,  0.0677, -0.4106,  0.2269,  0.0928, -0.0362, -0.5435,\n",
      "         -0.0737, -0.2914, -0.1705,  0.4275, -0.2847,  0.1498, -0.0673, -0.2049],\n",
      "        [ 0.1889, -0.3995,  0.7274, -0.5491, -0.8916,  0.0621, -0.4937,  0.0454,\n",
      "          0.5062,  0.5137, -0.6742,  0.4222,  0.5791, -0.1859, -0.1490,  0.3980,\n",
      "          0.1159, -0.8124,  0.1342, -0.4144, -0.1957,  0.4102,  0.2363, -0.2819,\n",
      "         -0.7002, -0.5877, -0.9785,  0.1257, -0.8988, -0.2274,  0.1322, -0.9812],\n",
      "        [-0.2481,  0.5666, -0.4655,  0.3611,  0.5921, -0.1823, -0.0103,  0.0097,\n",
      "          0.0654, -0.3198,  0.5059,  0.2258, -0.4006,  0.2318, -0.3425, -0.1049,\n",
      "         -0.0813,  0.0995,  0.2562,  0.1850,  0.3046, -0.1079,  0.0370,  0.1975,\n",
      "         -0.1983,  0.5319,  0.3066, -0.4497,  0.7398,  0.7553,  0.0532,  0.4999],\n",
      "        [ 0.0726,  0.7510, -0.0933,  0.8084,  0.2991,  0.0363, -0.2196,  0.0172,\n",
      "         -0.4434, -0.0523,  0.7666,  0.0748, -0.3009,  0.7618, -0.3667,  0.3167,\n",
      "         -0.1837,  0.5855, -0.2107, -0.2402,  0.0531, -0.6733,  0.3704, -0.1461,\n",
      "          0.1364,  0.0081,  0.7596,  0.1141,  0.0372,  0.3886, -0.0410,  0.0630],\n",
      "        [ 0.0482, -0.3885, -0.3766, -0.1060,  0.0252,  0.1004,  0.1220, -0.3770,\n",
      "         -0.1971,  0.1313, -0.0941,  0.0987, -0.0788,  0.3919, -0.2745,  0.0404,\n",
      "          0.0077, -0.1493, -0.1070,  0.2752,  0.1739, -0.0381, -0.2168,  0.4356,\n",
      "         -0.0411,  0.2082,  0.1630, -0.0444, -0.1252,  0.1560,  0.3133, -0.5056],\n",
      "        [ 0.1271,  0.8257, -0.2687,  1.0485, -0.5115, -0.0501,  0.1657, -0.3224,\n",
      "         -0.1465, -0.3315,  0.6679,  0.1018,  0.4397,  0.6217,  0.0331,  0.3825,\n",
      "          0.2766,  0.6672, -0.2471,  0.1793,  0.2888, -0.2465,  0.3755,  0.1595,\n",
      "          0.1034,  0.6843,  0.4921,  0.1939,  0.3118,  0.2058, -0.0428,  0.1315],\n",
      "        [ 0.0262,  0.6921, -0.1897,  0.4652, -0.0588,  0.3750,  0.2586,  0.3346,\n",
      "          0.1408, -0.2942,  0.3591, -0.0656, -0.2354,  0.0525, -0.0411,  0.0562,\n",
      "          0.0069,  0.1715,  0.0834,  0.0015,  0.2997, -0.1435, -0.9134, -0.5693,\n",
      "          0.1289,  0.2284,  0.6581, -0.3155,  0.0291, -0.0026,  0.0297,  0.1823],\n",
      "        [-0.3215,  0.2827, -0.5146,  0.3008,  0.5579, -0.3981,  0.2943, -0.2774,\n",
      "         -0.7577, -0.3647,  0.1689, -0.0705, -0.0220,  0.2707,  0.1463, -0.2412,\n",
      "          0.1300, -0.1850,  0.0993, -0.0301, -0.2373, -0.0654,  0.1928,  0.3566,\n",
      "          0.5878,  0.1296,  0.0462,  0.7118,  0.3582,  0.1392, -0.0185,  0.6559]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "-------------------------------\n",
      "gnn2.fc.weight\n",
      "Parameter containing:\n",
      "tensor([[ 0.1463,  0.4287,  0.2541,  ...,  0.2745,  0.5243,  0.3838],\n",
      "        [-0.2409,  0.4722, -0.2256,  ...,  0.0698, -0.1756, -0.1870],\n",
      "        [ 0.3017,  0.5774,  0.4062,  ...,  0.3612, -0.1063,  0.7724],\n",
      "        ...,\n",
      "        [-0.1013,  0.5692,  0.1426,  ..., -0.0602,  0.3718,  0.3449],\n",
      "        [-0.2374,  0.1008, -0.1240,  ...,  0.6580,  0.0740, -0.2790],\n",
      "        [ 1.3020, -0.1483,  0.2375,  ..., -0.1191,  0.1316,  0.2747]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "-------------------------------\n",
      "gnn2.fc.bias\n",
      "Parameter containing:\n",
      "tensor([ 0.7882, -0.5010,  0.7903, -0.9203,  0.6709, -0.4509,  0.3515, -0.5696,\n",
      "        -0.0698, -0.7095, -0.6467, -0.0503,  0.0945,  0.3374,  0.5029, -0.5748,\n",
      "         0.4472,  0.2304, -0.1627, -0.3186,  0.0789, -0.4571, -0.3773, -0.5781,\n",
      "         0.3302,  0.7970, -0.8291,  0.5960, -0.2905, -0.9114, -0.2340, -0.4417,\n",
      "         0.2723,  0.1792, -0.6635,  0.5172, -0.1899, -0.3979, -0.8748, -0.2451,\n",
      "        -0.7158, -0.2374,  1.1261,  0.6840,  0.2881, -1.0622, -0.8555, -0.7131,\n",
      "         0.5469,  0.2954,  0.4535, -0.8714, -0.5062, -0.2041,  0.0074,  0.0644,\n",
      "        -0.7144,  0.7008,  0.0674,  0.6932, -0.1033,  0.4651,  0.1696, -0.6199,\n",
      "         0.0666, -0.9705, -0.0610,  0.0751,  0.0155, -0.0780, -0.1213,  0.8255,\n",
      "         0.4003, -0.3076,  0.1982, -0.3000,  0.6925,  0.4545, -1.2923, -0.1445,\n",
      "        -0.1369, -0.2045,  0.3756,  0.2778, -0.5555,  0.1145,  0.1808,  0.0787,\n",
      "        -0.1328,  0.3823,  0.0104, -0.2688, -0.0730, -0.8822, -0.9866, -0.4080,\n",
      "         0.4337,  0.8011,  0.3413, -0.6517,  0.7027,  0.0775,  0.1532,  0.9083,\n",
      "        -0.0357,  0.0506,  0.0565, -1.0595,  0.7072, -0.6130, -0.0427, -0.0788,\n",
      "         0.4260, -0.2049, -0.4570,  0.3553, -0.8535,  0.5084,  0.7215, -0.9409,\n",
      "        -0.1032, -0.0127,  0.3155, -0.3391, -0.2342,  0.2422,  0.0806,  0.5726,\n",
      "         1.1783, -0.7011, -0.4750, -0.0980,  0.2849,  0.7419, -0.6136,  0.5467,\n",
      "        -0.9184,  0.1571, -0.2247,  0.2987, -0.6629, -0.2866,  0.5681,  0.7717,\n",
      "        -0.7728,  0.3835, -0.5309,  0.6086, -0.8343,  1.0280, -0.2782, -0.4467,\n",
      "        -0.7134,  0.5926,  0.7573, -0.9834,  0.0116,  0.8468,  0.0309, -0.6695,\n",
      "        -0.4306, -0.5217,  0.3820, -0.2085, -0.4588, -0.7366, -1.0942,  0.5045,\n",
      "         0.2449, -0.2326,  0.1080,  0.0882, -0.4261, -1.0122, -0.8513,  0.7432,\n",
      "        -0.0239, -0.1760, -0.4007, -0.7551, -0.0533, -0.9701,  0.7239,  0.6732,\n",
      "        -0.6721, -0.8826, -0.7767, -0.4541, -0.8488,  1.0828, -0.5917,  0.5810,\n",
      "        -0.1705, -0.3379, -0.9868,  0.3830, -0.3016, -0.8597,  0.1488,  0.8109,\n",
      "         0.2762,  0.0997,  0.3144,  0.8267, -0.6648,  0.0891,  0.1148, -0.1116,\n",
      "         0.3255, -0.1345, -0.2147,  0.6278,  0.0660, -0.2416,  0.8588,  0.1933,\n",
      "        -0.8647, -0.6891,  0.4494, -0.9824, -0.6773, -0.2861,  0.5387, -0.2941,\n",
      "        -0.6240, -0.2897, -0.9136, -0.6600,  0.3815, -0.3442, -0.1473,  0.0904,\n",
      "         0.7170,  0.4727, -0.0598, -0.9010,  0.2840, -1.1188, -0.7967, -0.3165,\n",
      "        -1.1147, -0.9466,  0.6604, -0.1414, -0.1254,  0.5244, -0.3148, -0.1995,\n",
      "         0.9489, -0.9266,  0.1185,  0.3734,  0.5310,  0.7773, -0.2408,  0.4115],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "-------------------------------\n",
      "proj1.weight\n",
      "Parameter containing:\n",
      "tensor([[ 4.5760e-02,  4.8801e-01,  3.1782e-01,  ...,  8.0846e-02,\n",
      "          6.6251e-01, -4.7957e-01],\n",
      "        [-3.4596e-02,  1.4466e-01, -1.8671e-01,  ...,  1.1147e-01,\n",
      "          6.2014e-04, -9.8989e-02],\n",
      "        [-2.7205e-01,  1.8229e-01, -4.5828e-01,  ...,  3.9012e-01,\n",
      "          2.4586e-01, -2.7259e-01],\n",
      "        ...,\n",
      "        [ 1.6469e-01, -2.1368e-01,  1.9211e-02,  ..., -1.4138e-01,\n",
      "         -3.6903e-01,  4.0359e-01],\n",
      "        [-1.4727e-01,  9.0504e-02,  2.1084e-01,  ..., -1.0173e-01,\n",
      "          6.3406e-02, -8.3213e-02],\n",
      "        [ 1.7318e-01, -5.3789e-01,  5.2336e-02,  ..., -2.8605e-01,\n",
      "         -5.1493e-01,  3.4842e-01]], device='cuda:0', requires_grad=True)\n",
      "-------------------------------\n",
      "proj1.bias\n",
      "Parameter containing:\n",
      "tensor([-0.0789,  0.0889, -0.1082,  0.2069, -0.5000,  0.3899, -0.1283,  0.0698,\n",
      "         0.1194, -0.0023,  0.1444, -0.0649,  0.2412,  0.1280, -0.2157, -0.2025,\n",
      "        -0.1302, -0.0395, -0.1928, -0.0524, -0.2362,  0.1913, -0.0063,  0.0082,\n",
      "         0.2039, -0.1182,  0.2523, -0.0773, -0.0634,  0.0824, -0.0998,  0.2354,\n",
      "        -0.0906, -0.5385, -0.0650,  0.4495, -0.0438,  0.0341, -0.0055, -0.0316,\n",
      "        -0.0628,  0.4567, -0.1927,  0.0079, -0.5325,  0.0654,  0.1512, -0.5025,\n",
      "        -0.3303,  0.3064, -0.0063, -0.1617, -0.2007,  0.1490,  0.6615,  0.0705,\n",
      "         0.0671,  0.5099, -0.0169,  0.0369,  0.3357,  0.1490, -0.3808, -0.2668,\n",
      "        -0.5718,  0.3305,  0.0984,  0.5039, -0.0631,  0.2193, -0.2788,  0.0600,\n",
      "         0.0788,  0.1685, -0.5232,  0.4273, -0.1328, -0.4416,  0.3246,  0.4846,\n",
      "         0.1573,  0.0511,  0.0717,  0.1505,  0.2790,  0.0115, -0.0915,  0.1695,\n",
      "        -0.0152,  0.0253, -0.3489,  0.2593, -0.1958,  0.5785, -0.1897, -0.3454,\n",
      "         0.4615,  0.2618, -0.0011, -0.0885, -0.2240, -0.2613, -0.1300,  0.0249,\n",
      "         0.3028, -0.4549, -0.1527,  0.1287,  0.1462,  0.1627,  0.0809,  0.0219,\n",
      "        -0.1548, -0.4771,  0.0968, -0.1150,  0.2620,  0.4633, -0.3386,  0.2218,\n",
      "         0.1212,  0.1081,  0.0322, -0.2934,  0.3293,  0.1133,  0.2405, -0.2545],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "-------------------------------\n",
      "proj2.weight\n",
      "Parameter containing:\n",
      "tensor([[-0.0547,  0.2844, -0.1060,  ...,  0.4392, -0.3766, -0.3543],\n",
      "        [-0.3732,  0.4399, -0.2347,  ..., -0.2817,  0.4706,  0.2185],\n",
      "        [-0.1250,  0.3518,  0.1051,  ...,  0.2819,  0.3706,  0.1217],\n",
      "        ...,\n",
      "        [ 0.2112, -0.1865,  0.3260,  ..., -0.1132, -0.4230,  0.6240],\n",
      "        [ 0.1064, -0.0530,  0.4326,  ...,  0.0922,  0.1676, -0.0169],\n",
      "        [ 0.2073, -0.0050,  0.0122,  ...,  0.0203, -0.1315, -0.0179]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "-------------------------------\n",
      "proj2.bias\n",
      "Parameter containing:\n",
      "tensor([ 0.1683,  0.3906,  0.0989,  0.1243, -0.1731, -0.1579, -0.2089, -0.3262,\n",
      "        -0.0661,  0.0844,  0.2367, -0.1594,  0.5942, -0.3155,  0.3276,  0.0221,\n",
      "         0.2790, -0.0321,  0.0522, -0.0699,  0.3179,  0.0517, -0.2821, -0.2514,\n",
      "         0.3218, -0.3589, -0.4419,  0.1597, -0.5316, -0.2839, -0.4184, -0.0605,\n",
      "         0.8819, -0.0547, -0.0009,  0.2749,  0.3576,  0.1108,  0.1713,  0.0343,\n",
      "        -0.1748,  0.0752, -0.0723,  0.0528, -0.0366, -0.0654,  0.0748, -0.6833,\n",
      "        -0.0393,  0.0310,  0.0655,  0.0436,  0.6670, -0.7775,  0.0205, -0.1395,\n",
      "         0.0676, -0.0129,  0.0236,  0.1262, -0.1399, -0.0557,  0.5976,  0.3907,\n",
      "         0.3907,  0.6798,  0.0190,  0.4396, -0.2231,  0.3420, -0.0161,  0.3665,\n",
      "        -0.2217,  0.5018, -0.1292, -0.0268, -0.4221,  0.0520,  0.1223, -0.0200,\n",
      "         0.1126, -0.1226,  0.4391, -0.2058,  0.0009, -0.2181, -0.1360,  0.2733,\n",
      "        -0.2293, -0.0222,  0.0285,  0.0152,  0.5124,  0.0305,  0.6407, -0.1371,\n",
      "         0.4825, -0.0347, -0.1756,  0.1156, -0.2410,  0.0597,  0.1692, -0.0969,\n",
      "         0.1877, -0.0265, -0.1295,  0.0855,  0.1255, -0.0691, -0.1634,  0.4014,\n",
      "        -0.5000, -0.3459, -0.1511,  0.0457,  0.4392,  0.4446, -0.0183,  0.0011,\n",
      "        -0.6429,  0.8151,  0.0485, -0.2178, -0.0626, -0.1963,  0.2615,  0.0460],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "-------------------------------\n",
      "proj1_shortcut.weight\n",
      "Parameter containing:\n",
      "tensor([[-0.0569, -0.0005, -0.0118,  ...,  0.0571, -0.0561,  0.0337],\n",
      "        [-0.0464,  0.0616,  0.0624,  ...,  0.0064,  0.0471,  0.0274],\n",
      "        [ 0.0420, -0.0153,  0.0594,  ..., -0.0328,  0.0407,  0.0434],\n",
      "        ...,\n",
      "        [ 0.0044,  0.0270, -0.0335,  ..., -0.0386,  0.0110,  0.0527],\n",
      "        [ 0.0619,  0.0300, -0.0326,  ...,  0.0266, -0.0340, -0.0525],\n",
      "        [-0.0008,  0.0548, -0.0625,  ..., -0.0241, -0.0433, -0.0107]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "-------------------------------\n",
      "proj1_shortcut.bias\n",
      "Parameter containing:\n",
      "tensor([ 0.0527, -0.0141, -0.0217, -0.0156, -0.0589,  0.0040, -0.0147, -0.0145,\n",
      "        -0.0519,  0.0030,  0.0106, -0.0544,  0.0237, -0.0455,  0.0513,  0.0329,\n",
      "        -0.0470, -0.0153,  0.0268,  0.0069, -0.0247, -0.0221, -0.0258,  0.0253,\n",
      "         0.0247, -0.0371, -0.0054,  0.0044, -0.0370,  0.0553, -0.0369, -0.0301,\n",
      "        -0.0413,  0.0518,  0.0157,  0.0337,  0.0122, -0.0157, -0.0535,  0.0260,\n",
      "        -0.0448, -0.0408,  0.0292, -0.0444,  0.0503, -0.0508, -0.0596, -0.0079,\n",
      "        -0.0110, -0.0174, -0.0120,  0.0471,  0.0044,  0.0228, -0.0516, -0.0183,\n",
      "        -0.0309,  0.0224,  0.0491,  0.0584,  0.0614,  0.0275, -0.0424, -0.0480,\n",
      "         0.0249, -0.0200, -0.0250,  0.0415, -0.0248,  0.0406,  0.0025,  0.0278,\n",
      "        -0.0303, -0.0499,  0.0062, -0.0602, -0.0353,  0.0568, -0.0364,  0.0361,\n",
      "         0.0369, -0.0205,  0.0094,  0.0589,  0.0432,  0.0584,  0.0045,  0.0436,\n",
      "         0.0477, -0.0394, -0.0160,  0.0172,  0.0398,  0.0509,  0.0600, -0.0572,\n",
      "        -0.0594,  0.0301,  0.0374, -0.0404,  0.0094,  0.0460,  0.0323,  0.0286,\n",
      "        -0.0360,  0.0034,  0.0098, -0.0299,  0.0107, -0.0040, -0.0421, -0.0585,\n",
      "        -0.0595,  0.0219, -0.0034, -0.0616,  0.0352, -0.0169,  0.0170,  0.0133,\n",
      "         0.0316,  0.0146, -0.0008, -0.0398, -0.0439, -0.0486,  0.0444,  0.0546],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "-------------------------------\n",
      "proj2_shortcut.weight\n",
      "Parameter containing:\n",
      "tensor([[-0.0136,  0.0553,  0.0440,  ...,  0.0075, -0.0462,  0.0616],\n",
      "        [ 0.0077, -0.0269, -0.0361,  ..., -0.0100,  0.0345, -0.0492],\n",
      "        [ 0.0195,  0.0082,  0.0353,  ...,  0.0401, -0.0392,  0.0174],\n",
      "        ...,\n",
      "        [-0.0316,  0.0430, -0.0526,  ...,  0.0559, -0.0424, -0.0571],\n",
      "        [-0.0304,  0.0382, -0.0308,  ..., -0.0534, -0.0321,  0.0493],\n",
      "        [-0.0539, -0.0553, -0.0065,  ..., -0.0596, -0.0554, -0.0286]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "-------------------------------\n",
      "proj2_shortcut.bias\n",
      "Parameter containing:\n",
      "tensor([-0.0326,  0.0328,  0.0456,  0.0149, -0.0152, -0.0156,  0.0203, -0.0439,\n",
      "        -0.0400, -0.0609,  0.0149,  0.0126, -0.0386,  0.0379, -0.0245, -0.0222,\n",
      "         0.0433,  0.0098, -0.0582, -0.0096,  0.0043,  0.0444,  0.0107, -0.0120,\n",
      "         0.0549, -0.0335,  0.0496, -0.0048,  0.0307,  0.0082,  0.0098,  0.0240,\n",
      "         0.0473, -0.0106,  0.0184, -0.0566, -0.0590,  0.0489, -0.0135, -0.0289,\n",
      "        -0.0529, -0.0297, -0.0547, -0.0042, -0.0451,  0.0584, -0.0371,  0.0082,\n",
      "         0.0440,  0.0607, -0.0111, -0.0040, -0.0576, -0.0144, -0.0037, -0.0346,\n",
      "        -0.0097,  0.0548, -0.0387, -0.0420, -0.0358,  0.0018,  0.0419,  0.0193,\n",
      "         0.0069, -0.0167,  0.0476,  0.0056, -0.0520, -0.0040, -0.0031, -0.0185,\n",
      "        -0.0156, -0.0599,  0.0131, -0.0510,  0.0074, -0.0298, -0.0449, -0.0423,\n",
      "         0.0349, -0.0161,  0.0248,  0.0183,  0.0035,  0.0492, -0.0575, -0.0603,\n",
      "         0.0365,  0.0176,  0.0453, -0.0507, -0.0063,  0.0342, -0.0063,  0.0614,\n",
      "        -0.0346,  0.0408, -0.0063, -0.0083,  0.0287,  0.0232,  0.0277, -0.0215,\n",
      "        -0.0432,  0.0595, -0.0502, -0.0227, -0.0191,  0.0231, -0.0102, -0.0396,\n",
      "        -0.0100,  0.0572, -0.0321,  0.0020, -0.0087,  0.0184,  0.0464, -0.0022,\n",
      "        -0.0576, -0.0604, -0.0010,  0.0131,  0.0573,  0.0084, -0.0325,  0.0247],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "-------------------------------\n",
      "concat.weight\n",
      "Parameter containing:\n",
      "tensor([[ 0.0419,  0.0380, -0.0475,  ...,  0.0594,  0.0442,  0.0131],\n",
      "        [ 0.0103,  0.0271, -0.0452,  ...,  0.0488, -0.0607, -0.0353],\n",
      "        [ 0.0202,  0.0174,  0.0184,  ..., -0.0576,  0.0398, -0.0037],\n",
      "        ...,\n",
      "        [ 0.0052, -0.0537, -0.0275,  ..., -0.0115,  0.0346,  0.0005],\n",
      "        [ 0.0141, -0.0298, -0.0565,  ...,  0.0005, -0.0092, -0.0268],\n",
      "        [-0.0325,  0.0017, -0.0374,  ..., -0.0228,  0.0617,  0.0053]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "-------------------------------\n",
      "concat.bias\n",
      "Parameter containing:\n",
      "tensor([-4.9169e-02, -4.2452e-03,  9.7646e-03, -1.9694e-02, -5.8456e-02,\n",
      "         1.9276e-02,  3.0938e-02,  2.2177e-02, -5.4731e-02, -5.4382e-03,\n",
      "        -6.6650e-03,  2.9778e-02,  1.6521e-03, -4.1789e-02,  2.1486e-02,\n",
      "        -5.6665e-02, -2.6502e-02,  1.1111e-02, -4.6391e-02,  2.0711e-02,\n",
      "         3.6156e-02,  2.5461e-02,  4.3246e-02, -5.7498e-03,  1.3347e-02,\n",
      "        -4.6954e-05,  2.8780e-02,  3.5993e-02, -2.4429e-02, -4.8415e-02,\n",
      "         6.2162e-02, -3.9669e-02, -3.7904e-02, -2.9326e-02, -1.8841e-02,\n",
      "         1.1967e-02,  6.0165e-02, -4.4659e-03,  3.4700e-02,  1.0295e-02,\n",
      "        -2.3530e-02, -7.9934e-03, -5.9537e-02,  1.3232e-02, -3.9808e-02,\n",
      "        -5.4236e-02, -5.0464e-02, -1.3898e-02, -1.3899e-02, -2.3321e-02,\n",
      "         1.3889e-02,  8.4254e-03,  2.5038e-02,  4.9236e-02, -4.1035e-02,\n",
      "         2.3205e-02,  4.1040e-03, -3.8870e-02, -5.0770e-02,  3.1875e-02,\n",
      "         5.5614e-02, -2.1535e-02, -5.3273e-02, -2.3655e-02,  4.9761e-02,\n",
      "         6.6122e-03,  5.2426e-02,  4.3736e-02, -4.3659e-02, -2.0690e-02,\n",
      "        -1.1078e-02, -2.3070e-02,  3.1689e-02, -2.4254e-03, -5.7824e-02,\n",
      "        -4.8503e-02,  1.7027e-02,  4.8375e-02,  2.2080e-02, -1.6304e-02,\n",
      "        -5.8262e-02, -3.9452e-02, -5.0467e-02,  4.9075e-02, -5.1020e-03,\n",
      "        -7.4010e-03,  4.2678e-02,  6.1945e-02,  4.3017e-02, -3.2567e-02,\n",
      "         4.5366e-02,  1.0751e-02,  5.5586e-02, -7.9613e-03, -5.4879e-02,\n",
      "        -1.1334e-02,  2.6827e-02, -6.2858e-03,  1.8905e-02, -6.1046e-03,\n",
      "         1.5377e-02,  5.8768e-02, -3.1753e-02,  3.5535e-02, -3.2581e-04,\n",
      "        -9.6678e-03,  4.1764e-02,  2.5730e-02,  1.6936e-02, -1.5835e-02,\n",
      "        -2.6874e-02,  3.1326e-03, -4.9820e-02,  1.8478e-02, -5.7448e-02,\n",
      "         8.9839e-03, -4.6341e-02, -5.2525e-02, -2.3174e-02,  4.9412e-02,\n",
      "         4.5939e-02, -6.0558e-02,  2.6535e-02, -3.7783e-02,  5.8186e-02,\n",
      "        -3.9835e-03,  1.2522e-02, -6.0788e-02], device='cuda:0',\n",
      "       requires_grad=True)\n",
      "-------------------------------\n",
      "pred.weight\n",
      "Parameter containing:\n",
      "tensor([[ 0.3408,  0.1915, -0.1720,  ...,  0.5348, -0.6069, -0.1173],\n",
      "        [-0.1021,  0.4360,  0.2814,  ..., -0.1842, -0.1057, -0.4428],\n",
      "        [ 0.5111, -0.2813, -0.0297,  ...,  0.0102, -0.0848, -0.2370],\n",
      "        ...,\n",
      "        [-0.1484,  0.2022,  0.3304,  ...,  0.9967,  0.2807,  0.1741],\n",
      "        [-0.1501,  0.1515,  0.2241,  ...,  0.0372,  0.8412,  0.1886],\n",
      "        [ 0.3417,  0.2367, -0.1091,  ...,  0.5930, -0.6188, -0.0999]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "-------------------------------\n",
      "pred.bias\n",
      "Parameter containing:\n",
      "tensor([-0.2812, -0.3209,  0.1718,  0.0515,  0.0260, -0.3485, -0.3183,  0.0174,\n",
      "         0.4632,  0.0688, -0.3547, -0.1003, -0.3406, -0.4605, -0.3291, -0.1761,\n",
      "        -0.2177, -0.3046, -0.2191, -0.2413, -0.2724, -0.3436, -0.1674,  0.0626,\n",
      "        -0.0048,  0.4367, -0.0495, -0.6126,  0.0400, -0.1024,  0.0132, -0.2702,\n",
      "        -0.0072, -0.3125, -0.0562, -0.2489,  0.1296, -0.1819, -0.1833, -0.1314,\n",
      "        -0.2819], device='cuda:0', requires_grad=True)\n",
      "-------------------------------\n"
     ]
    }
   ],
   "source": [
    "for name, param in ae.named_parameters():\n",
    "    print(name)\n",
    "    print(param)\n",
    "    print(\"-------------------------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performance Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 4 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, axs = plt.subplots(2, 2, figsize=(10,6)) \n",
    "x = [i*5 for i in range(len(accu_test))]\n",
    "axs[0,0].plot(loss_train)\n",
    "axs[0,0].set_ylabel(\"loss\")\n",
    "axs[0,0].set_xlabel(\"epochs\")\n",
    "axs[0,0].set_title(\"train\")\n",
    "axs[1,0].plot(accu_train)\n",
    "axs[1,0].set_ylabel(\"Accuracy\")\n",
    "axs[1,0].set_xlabel(\"epochs\")\n",
    "axs[1,0].set_title(\"train\")\n",
    "axs[0,1].plot(x, loss_test)\n",
    "axs[0,1].set_ylabel(\"loss\")\n",
    "axs[0,1].set_xlabel(\"epochs\")\n",
    "axs[0,1].set_title(\"test\")\n",
    "axs[1,1].plot(x, accu_test)\n",
    "axs[1,1].set_ylabel(\"Accuracy\")\n",
    "axs[1,1].set_xlabel(\"epochs\")\n",
    "axs[1,1].set_title(\"test\")\n",
    "plt.tight_layout()\n",
    "plt.savefig('AE_result_1.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a 1\n",
      "b 2\n"
     ]
    }
   ],
   "source": [
    "d = {'a': 1, 'b':2}\n",
    "for key, val in d.items():\n",
    "    print(key, val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pred:\t8\t28\t25\t23\t8\t8\t8\t28\t25\t23\t8\t28\t25\t23\t8\t28\t8\t8\t8\t8\t8\t8\t28\t25\t23\t8\t8\t8\t28\t25\t23\t8\t8\t8\t28\t25\t9\t8\t32\t9\t11\t14\t15\t16\t8\t28\t25\t23\t8\t8\t8\t8\t8\t14\t8\t37\t8\t8\t8\t8\t8\t8\t28\t25\t23\t8\t8\t8\t8\t8\t8\t8\t8\t8\t36\t25\t25\t4\t25\t8\t36\t8\t37\t8\t36\t25\t25\t3\t23\t8\t8\t8\t37\t8\t37\t8\t8\t8\t8\t8\t8\t32\t9\t11\t14\t15\t16\t8\t36\t25\t25\t3\t23\t8\t8\t8\t37\t8\t8\t8\t8\t8\t8\t28\t25\t23\t8\t8\t8\t8\t8\t8\t8\t8\t36\t25\t25\t4\t23\t8\t32\t9\t11\t14\t15\t16\t17\t18\t25\t4\t25\t8\t32\t9\t11\t14\t15\t16\t17\t18\t19\t4\t8\t36\t25\t25\t2\t25\t8\t36\t25\t25\t4\t25\t8\t28\t25\t24\t8\t28\t25\t8\t8\t8\t8\t8\t28\t24\t24\t25\t8\t28\t25\t24\t8\t28\t25\t24\t8\t28\t25\t24\t8\t28\t25\t24\t8\t28\t25\t24\t8\t28\t25\t24\t8\t28\t24\t24\t24\t24\t8\t8\t36\t25\t25\t2\t23\t8\t36\t25\t25\t2\t23\t8\t8\t35\t25\t30\t22\t8\t36\t25\t25\t2\t23\t8\t36\t25\t25\t3\t23\t8\t36\t25\t25\t3\t23\t8\t36\t8\t37\t8\t37\t8\t8\t8\t8\t8\t8\t8\t8\t36\t25\t25\t2\t23\t8\t32\t9\t11\t14\t15\t8\t28\t25\t23\t8\t8\t8\t8\t8\t28\t24\t25\t8\t28\t25\t24\t8\t28\t25\t24\t8\t28\t25\t24\t8\t28\t25\t24\t8\t8\t8\t8\t8\t8\t8\t8\t8\t8\t8\t8\t32\t9\t11\t14\t15\t16\t8\t28\t25\t23\t8\t8\t8\t8\t8\t8\t8\t8\t8\t8\t8\t32\t9\t11\t14\t15\t16\t8\t28\t25\t23\t8\t8\t8\t8\t8\t8\t8\t8\t8\t8\t32\t9\t11\t14\t15\t16\t17\t18\t19\t8\t8\t8\t8\t32\t9\t11\t14\t15\t16\t17\t18\t25\t25\t23\t8\t9\t11\t25\t8\t28\t25\t9\t11\t14\t15\t8\t28\t25\t23\t8\t32\t9\t11\t14\t15\t16\t8\t8\t8\t8\t8\t8\t39\t30\t26\t25\t8\t39\t8\t39\t30\t26\t25\t8\t39\t8\t28\t25\t23\t8\t8\t8\t8\t8\t8\t37\t8\t8\t8\t8\t8\t8\t8\t8\t8\t8\t8\t8\t8\t32\t9\t11\t14\t15\t16\t8\t28\t25\t23\t8\t8\t8\t8\t8\t8\t8\t8\t8\t8\t32\t9\t11\t14\t15\t16\t8\t28\t25\t23\t8\t8\t8\t8\t8\t8\t36\t36\t25\t7\t23\t8\t8\t36\t25\t25\t3\t23\t8\t36\t25\t25\t3\t23\t8\t32\t9\t9\t11\t14\t15\t14\t14\t14\t15\t16\t17\t18\t19\t20\t8\t37\t8\t8\t8\t8\t8\t8\t28\t25\t23\t8\t8\t8\t8\t8\t8\t8\t37\t8\t8\t8\t8\t8\t8\t8\t8\t8\t8\t8\t8\t8\t32\t9\t11\t14\t15\t16\t8\t28\t25\t23\t8\t8\t8\t8\t8\t8\t8\t8\t8\t8\t32\t9\t11\t14\t15\t16\t8\t28\t25\t23\t8\t8\t8\t8\t28\t25\t23\t8\t36\t25\t25\t3\t23\t8\t8\t8\t8\t8\t8\t8\t8\t8\t8\t8\t8\t8\t8\t8\t8\t8\t8\t8\t8\t8\t8\t8\t8\t23\t8\t8\t8\t8\t23\t8\t8\t8\t8\t8\t8\t8\t8\t39\t30\t26\t25\t8\t39\t30\t26\t25\t8\t28\t8\t28\t25\t6\t8\t32\t9\t11\t14\t15\t16\t17\t18\t8\t8\t8\t8\t8\t8\t8\t8\t8\t8\t8\t23\t8\t8\t8\t8\t37\t8\t36\t25\t25\t3\t23\t8\t8\t8\t8\t8\t8\t8\t8\t8\t8\t8\t8\t8\t8\t8\t8\t8\t8\t8\t8\t39\t30\t26\t25\t8\t39\t30\t8\t28\t25\t23\t8\t8\t8\t37\t8\t37\t9\t11\t8\t28\t25\t23\t8\t8\t8\t8\t37\t8\t8\t8\t8\t8\t8\t8\t37\t8\t8\t8\t8\t8\t8\t8\t8\t8\t8\t8\t8\t32\t9\t11\t14\t15\t16\t8\t28\t25\t23\t8\t8\t8\t8\t8\t8\t8\t8\t8\t8\t8\t8\t8\t8\t8\t8\t8\t8\t8\t8\t8\t8\t8\t8\t8\t8\t8\t8\t8\t8\t37\t8\t8\t8\n",
      "actu:\t8\t28\t25\t23\t8\t8\t8\t28\t25\t23\t8\t28\t25\t23\t8\t8\t8\t8\t8\t8\t8\t8\t28\t25\t23\t8\t8\t8\t28\t25\t23\t8\t8\t8\t37\t8\t28\t25\t25\t8\t32\t9\t11\t14\t15\t16\t8\t36\t25\t25\t3\t23\t8\t8\t8\t37\t8\t8\t8\t8\t8\t8\t28\t25\t23\t8\t8\t8\t8\t8\t8\t8\t8\t8\t36\t25\t25\t2\t25\t8\t8\t8\t37\t8\t36\t25\t25\t3\t23\t8\t8\t8\t37\t8\t37\t8\t8\t8\t8\t8\t8\t32\t9\t11\t14\t15\t16\t8\t36\t25\t25\t3\t23\t8\t8\t8\t37\t8\t8\t8\t8\t8\t8\t28\t25\t23\t8\t8\t8\t8\t8\t8\t8\t8\t36\t25\t25\t4\t23\t8\t32\t9\t11\t14\t15\t8\t36\t25\t25\t4\t23\t8\t32\t9\t11\t14\t15\t8\t36\t25\t25\t2\t25\t8\t36\t25\t25\t4\t23\t8\t32\t9\t11\t14\t15\t8\t28\t25\t23\t8\t8\t8\t8\t8\t8\t8\t28\t25\t24\t8\t28\t25\t24\t8\t28\t25\t24\t8\t28\t25\t24\t8\t28\t25\t24\t8\t28\t25\t24\t8\t8\t28\t25\t23\t8\t28\t25\t23\t8\t8\t8\t8\t36\t25\t25\t2\t25\t8\t36\t25\t25\t3\t25\t8\t36\t25\t25\t7\t25\t8\t32\t9\t11\t14\t15\t8\t36\t25\t25\t3\t25\t8\t36\t25\t25\t3\t23\t8\t8\t8\t37\t8\t37\t8\t8\t8\t8\t8\t8\t8\t36\t25\t25\t3\t25\t8\t32\t9\t11\t14\t8\t8\t36\t25\t25\t2\t25\t8\t36\t25\t25\t3\t25\t8\t36\t25\t25\t2\t25\t8\t36\t25\t25\t7\t25\t8\t28\t25\t25\t8\t8\t8\t8\t8\t8\t8\t8\t8\t8\t8\t8\t8\t32\t9\t11\t14\t15\t16\t8\t28\t25\t23\t8\t8\t8\t8\t8\t8\t8\t8\t8\t8\t8\t32\t9\t11\t14\t15\t16\t8\t28\t25\t23\t8\t8\t8\t8\t8\t8\t8\t8\t8\t8\t36\t25\t25\t3\t23\t8\t8\t8\t32\t9\t11\t14\t15\t16\t17\t18\t8\t8\t36\t25\t25\t3\t25\t8\t36\t25\t25\t4\t25\t8\t36\t25\t25\t2\t25\t8\t32\t9\t11\t14\t15\t8\t8\t8\t8\t8\t8\t8\t8\t8\t8\t8\t39\t30\t26\t25\t8\t8\t8\t39\t30\t26\t23\t8\t8\t8\t28\t25\t23\t8\t8\t8\t8\t8\t8\t37\t8\t8\t8\t8\t8\t8\t8\t8\t8\t8\t8\t8\t8\t32\t9\t11\t14\t15\t16\t8\t28\t25\t23\t8\t8\t8\t8\t8\t8\t8\t8\t8\t8\t32\t9\t11\t14\t15\t16\t8\t28\t25\t23\t8\t8\t8\t8\t8\t8\t8\t8\t8\t8\t8\t36\t25\t25\t4\t25\t8\t8\t8\t28\t25\t23\t8\t8\t8\t8\t8\t32\t9\t11\t14\t15\t8\t36\t25\t25\t3\t23\t8\t8\t8\t37\t8\t8\t8\t8\t8\t8\t28\t25\t23\t8\t8\t8\t8\t8\t8\t8\t37\t8\t8\t8\t8\t8\t8\t8\t8\t8\t8\t8\t8\t8\t32\t9\t11\t14\t15\t16\t8\t28\t25\t23\t8\t8\t8\t8\t8\t8\t8\t8\t8\t8\t32\t9\t11\t14\t15\t16\t8\t28\t25\t23\t8\t8\t8\t8\t28\t25\t23\t8\t28\t25\t23\t8\t8\t8\t8\t8\t8\t8\t8\t8\t36\t25\t25\t3\t23\t8\t8\t8\t8\t8\t8\t8\t8\t8\t8\t28\t25\t23\t8\t8\t8\t8\t8\t8\t8\t8\t8\t8\t8\t8\t8\t39\t30\t26\t25\t8\t28\t25\t23\t8\t8\t8\t8\t28\t25\t9\t8\t8\t8\t8\t8\t36\t25\t25\t4\t25\t8\t8\t8\t8\t8\t32\t9\t11\t14\t15\t16\t17\t8\t8\t8\t37\t8\t36\t25\t25\t3\t23\t8\t8\t8\t8\t8\t8\t8\t8\t8\t8\t8\t8\t8\t8\t8\t8\t8\t8\t8\t8\t8\t39\t30\t26\t25\t8\t8\t8\t28\t25\t23\t8\t8\t8\t37\t8\t32\t9\t11\t8\t28\t25\t25\t8\t8\t8\t8\t37\t8\t8\t8\t8\t8\t8\t8\t37\t8\t8\t8\t8\t8\t8\t8\t8\t8\t8\t8\t8\t32\t9\t11\t14\t15\t16\t8\t28\t25\t23\t8\t8\t8\t8\t8\t8\t8\t8\t8\t8\t8\t36\t25\t25\t4\t25\t8\t8\t8\t8\t28\t25\t25\t8\t8\t8\t8\t8\t8\t8\t37\t8\t8\t8\n",
      "----------------------------------------------------------------------------------------\n",
      "pred:\t8\t28\t25\t23\t8\t8\t8\t28\t25\t23\t8\t28\t25\t23\t8\t28\t8\t8\t8\t8\t8\t8\t28\t25\t23\t8\t8\t8\t28\t25\t23\t8\t8\t8\t28\t25\t9\t8\t32\t9\t11\t14\t15\t16\t8\t28\t25\t23\t8\t8\t8\t8\t8\t14\t8\t37\t8\t8\t8\t8\t8\t8\t28\t25\t23\t8\t8\t8\t8\t8\t8\t8\t8\t8\t36\t25\t25\t4\t25\t8\t36\t8\t37\t8\t36\t25\t25\t3\t23\t8\t8\t8\t37\t8\t37\t8\t8\t8\t8\t8\t8\t32\t9\t11\t14\t15\t16\t8\t36\t25\t25\t3\t23\t8\t8\t8\t37\t8\t8\t8\t8\t8\t8\t28\t25\t23\t8\t8\t8\t8\t8\t8\t8\t8\t36\t25\t25\t4\t23\t8\t32\t9\t11\t14\t15\t16\t17\t18\t25\t4\t25\t8\t32\t9\t11\t14\t15\t16\t17\t18\t19\t4\t8\t36\t25\t25\t2\t25\t8\t36\t25\t25\t4\t25\t8\t28\t25\t24\t8\t28\t25\t8\t8\t8\t8\t8\t28\t24\t24\t25\t8\t28\t25\t24\t8\t28\t25\t24\t8\t28\t25\t24\t8\t28\t25\t24\t8\t28\t25\t24\t8\t28\t25\t24\t8\t28\t24\t24\t24\t24\t8\t8\t36\t25\t25\t2\t23\t8\t36\t25\t25\t2\t23\t8\t8\t35\t25\t30\t22\t8\t36\t25\t25\t2\t23\t8\t36\t25\t25\t3\t23\t8\t36\t25\t25\t3\t23\t8\t36\t8\t37\t8\t37\t8\t8\t8\t8\t8\t8\t8\t8\t36\t25\t25\t2\t23\t8\t32\t9\t11\t14\t15\t8\t28\t25\t23\t8\t8\t8\t8\t8\t28\t24\t25\t8\t28\t25\t24\t8\t28\t25\t24\t8\t28\t25\t24\t8\t28\t25\t24\t8\t8\t8\t8\t8\t8\t8\t8\t8\t8\t8\t8\t32\t9\t11\t14\t15\t16\t8\t28\t25\t23\t8\t8\t8\t8\t8\t8\t8\t8\t8\t8\t8\t32\t9\t11\t14\t15\t16\t8\t28\t25\t23\t8\t8\t8\t8\t8\t8\t8\t8\t8\t8\t32\t9\t11\t14\t15\t16\t17\t18\t19\t8\t8\t8\t8\t32\t9\t11\t14\t15\t16\t17\t18\t25\t25\t23\t8\t9\t11\t25\t8\t28\t25\t9\t11\t14\t15\t8\t28\t25\t23\t8\t32\t9\t11\t14\t15\t16\t8\t8\t8\t8\t8\t8\t39\t30\t26\t25\t8\t39\t8\t39\t30\t26\t25\t8\t39\t8\t28\t25\t23\t8\t8\t8\t8\t8\t8\t37\t8\t8\t8\t8\t8\t8\t8\t8\t8\t8\t8\t8\t8\t32\t9\t11\t14\t15\t16\t8\t28\t25\t23\t8\t8\t8\t8\t8\t8\t8\t8\t8\t8\t32\t9\t11\t14\t15\t16\t8\t28\t25\t23\t8\t8\t8\t8\t8\t8\t36\t36\t25\t7\t23\t8\t8\t36\t25\t25\t3\t23\t8\t36\t25\t25\t3\t23\t8\t32\t9\t9\t11\t14\t15\t14\t14\t14\t15\t16\t17\t18\t19\t20\t8\t37\t8\t8\t8\t8\t8\t8\t28\t25\t23\t8\t8\t8\t8\t8\t8\t8\t37\t8\t8\t8\t8\t8\t8\t8\t8\t8\t8\t8\t8\t8\t32\t9\t11\t14\t15\t16\t8\t28\t25\t23\t8\t8\t8\t8\t8\t8\t8\t8\t8\t8\t32\t9\t11\t14\t15\t16\t8\t28\t25\t23\t8\t8\t8\t8\t28\t25\t23\t8\t36\t25\t25\t3\t23\t8\t8\t8\t8\t8\t8\t8\t8\t8\t8\t8\t8\t8\t8\t8\t8\t8\t8\t8\t8\t8\t8\t8\t8\t23\t8\t8\t8\t8\t23\t8\t8\t8\t8\t8\t8\t8\t8\t39\t30\t26\t25\t8\t39\t30\t26\t25\t8\t28\t8\t28\t25\t6\t8\t32\t9\t11\t14\t15\t16\t17\t18\t8\t8\t8\t8\t8\t8\t8\t8\t8\t8\t8\t23\t8\t8\t8\t8\t37\t8\t36\t25\t25\t3\t23\t8\t8\t8\t8\t8\t8\t8\t8\t8\t8\t8\t8\t8\t8\t8\t8\t8\t8\t8\t8\t39\t30\t26\t25\t8\t39\t30\t8\t28\t25\t23\t8\t8\t8\t37\t8\t37\t9\t11\t8\t28\t25\t23\t8\t8\t8\t8\t37\t8\t8\t8\t8\t8\t8\t8\t37\t8\t8\t8\t8\t8\t8\t8\t8\t8\t8\t8\t8\t32\t9\t11\t14\t15\t16\t8\t28\t25\t23\t8\t8\t8\t8\t8\t8\t8\t8\t8\t8\t8\t8\t8\t8\t8\t8\t8\t8\t8\t8\t8\t8\t8\t8\t8\t8\t8\t8\t8\t8\t37\t8\t8\t8\n",
      "actu:\t8\t28\t25\t23\t8\t8\t8\t28\t25\t23\t8\t28\t25\t23\t8\t8\t8\t8\t8\t8\t8\t8\t28\t25\t23\t8\t8\t8\t28\t25\t23\t8\t8\t8\t37\t8\t28\t25\t25\t8\t32\t9\t11\t14\t15\t16\t8\t36\t25\t25\t3\t23\t8\t8\t8\t37\t8\t8\t8\t8\t8\t8\t28\t25\t23\t8\t8\t8\t8\t8\t8\t8\t8\t8\t36\t25\t25\t2\t25\t8\t8\t8\t37\t8\t36\t25\t25\t3\t23\t8\t8\t8\t37\t8\t37\t8\t8\t8\t8\t8\t8\t32\t9\t11\t14\t15\t16\t8\t36\t25\t25\t3\t23\t8\t8\t8\t37\t8\t8\t8\t8\t8\t8\t28\t25\t23\t8\t8\t8\t8\t8\t8\t8\t8\t36\t25\t25\t4\t23\t8\t32\t9\t11\t14\t15\t8\t36\t25\t25\t4\t23\t8\t32\t9\t11\t14\t15\t8\t36\t25\t25\t2\t25\t8\t36\t25\t25\t4\t23\t8\t32\t9\t11\t14\t15\t8\t28\t25\t23\t8\t8\t8\t8\t8\t8\t8\t28\t25\t24\t8\t28\t25\t24\t8\t28\t25\t24\t8\t28\t25\t24\t8\t28\t25\t24\t8\t28\t25\t24\t8\t8\t28\t25\t23\t8\t28\t25\t23\t8\t8\t8\t8\t36\t25\t25\t2\t25\t8\t36\t25\t25\t3\t25\t8\t36\t25\t25\t7\t25\t8\t32\t9\t11\t14\t15\t8\t36\t25\t25\t3\t25\t8\t36\t25\t25\t3\t23\t8\t8\t8\t37\t8\t37\t8\t8\t8\t8\t8\t8\t8\t36\t25\t25\t3\t25\t8\t32\t9\t11\t14\t8\t8\t36\t25\t25\t2\t25\t8\t36\t25\t25\t3\t25\t8\t36\t25\t25\t2\t25\t8\t36\t25\t25\t7\t25\t8\t28\t25\t25\t8\t8\t8\t8\t8\t8\t8\t8\t8\t8\t8\t8\t8\t32\t9\t11\t14\t15\t16\t8\t28\t25\t23\t8\t8\t8\t8\t8\t8\t8\t8\t8\t8\t8\t32\t9\t11\t14\t15\t16\t8\t28\t25\t23\t8\t8\t8\t8\t8\t8\t8\t8\t8\t8\t36\t25\t25\t3\t23\t8\t8\t8\t32\t9\t11\t14\t15\t16\t17\t18\t8\t8\t36\t25\t25\t3\t25\t8\t36\t25\t25\t4\t25\t8\t36\t25\t25\t2\t25\t8\t32\t9\t11\t14\t15\t8\t8\t8\t8\t8\t8\t8\t8\t8\t8\t8\t39\t30\t26\t25\t8\t8\t8\t39\t30\t26\t23\t8\t8\t8\t28\t25\t23\t8\t8\t8\t8\t8\t8\t37\t8\t8\t8\t8\t8\t8\t8\t8\t8\t8\t8\t8\t8\t32\t9\t11\t14\t15\t16\t8\t28\t25\t23\t8\t8\t8\t8\t8\t8\t8\t8\t8\t8\t32\t9\t11\t14\t15\t16\t8\t28\t25\t23\t8\t8\t8\t8\t8\t8\t8\t8\t8\t8\t8\t36\t25\t25\t4\t25\t8\t8\t8\t28\t25\t23\t8\t8\t8\t8\t8\t32\t9\t11\t14\t15\t8\t36\t25\t25\t3\t23\t8\t8\t8\t37\t8\t8\t8\t8\t8\t8\t28\t25\t23\t8\t8\t8\t8\t8\t8\t8\t37\t8\t8\t8\t8\t8\t8\t8\t8\t8\t8\t8\t8\t8\t32\t9\t11\t14\t15\t16\t8\t28\t25\t23\t8\t8\t8\t8\t8\t8\t8\t8\t8\t8\t32\t9\t11\t14\t15\t16\t8\t28\t25\t23\t8\t8\t8\t8\t28\t25\t23\t8\t28\t25\t23\t8\t8\t8\t8\t8\t8\t8\t8\t8\t36\t25\t25\t3\t23\t8\t8\t8\t8\t8\t8\t8\t8\t8\t8\t28\t25\t23\t8\t8\t8\t8\t8\t8\t8\t8\t8\t8\t8\t8\t8\t39\t30\t26\t25\t8\t28\t25\t23\t8\t8\t8\t8\t28\t25\t9\t8\t8\t8\t8\t8\t36\t25\t25\t4\t25\t8\t8\t8\t8\t8\t32\t9\t11\t14\t15\t16\t17\t8\t8\t8\t37\t8\t36\t25\t25\t3\t23\t8\t8\t8\t8\t8\t8\t8\t8\t8\t8\t8\t8\t8\t8\t8\t8\t8\t8\t8\t8\t8\t39\t30\t26\t25\t8\t8\t8\t28\t25\t23\t8\t8\t8\t37\t8\t32\t9\t11\t8\t28\t25\t25\t8\t8\t8\t8\t37\t8\t8\t8\t8\t8\t8\t8\t37\t8\t8\t8\t8\t8\t8\t8\t8\t8\t8\t8\t8\t32\t9\t11\t14\t15\t16\t8\t28\t25\t23\t8\t8\t8\t8\t8\t8\t8\t8\t8\t8\t8\t36\t25\t25\t4\t25\t8\t8\t8\t8\t28\t25\t25\t8\t8\t8\t8\t8\t8\t8\t37\t8\t8\t8\n",
      "----------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "for (padded_seq, padded_seq_dec, lengths, edge_index) in test_gpu:\n",
    "    j_test += np.sum(lengths)\n",
    "    cntBatch_test += 1\n",
    "    out = ae(padded_seq, padded_seq_dec, lengths, edge_index, mode=\"recursive\", ratio=1, ratio_mix=1)\n",
    "    pred = out.flatten(0).reshape(-1,N_max).argmax(dim=1).to(\"cpu\").tolist()\n",
    "    actu = padded_seq.flatten().to(\"cpu\").tolist()\n",
    "    pred_f = []\n",
    "    actu_f = []\n",
    "    for i in range(len(actu)):\n",
    "        if (actu[i]!=40):\n",
    "            pred_f.append(pred[i])\n",
    "            actu_f.append(actu[i])\n",
    "    print(\"pred:\", *pred_f, sep='\\t')\n",
    "    print(\"actu:\", *actu_f, sep='\\t')\n",
    "    print(\"----------------------------------------------------------------------------------------\")\n",
    "    break\n",
    "for (padded_seq, padded_seq_dec, lengths, edge_index) in test_gpu:\n",
    "    j_test += np.sum(lengths)\n",
    "    cntBatch_test += 1\n",
    "    out = ae(padded_seq, padded_seq_dec, lengths, edge_index, mode=\"recursive\", ratio=0, ratio_mix=0)\n",
    "    pred = out.flatten(0).reshape(-1,N_max).argmax(dim=1).to(\"cpu\").tolist()\n",
    "    actu = padded_seq.flatten().to(\"cpu\").tolist()\n",
    "    pred_f = []\n",
    "    actu_f = []\n",
    "    for i in range(len(actu)):\n",
    "        if (actu[i]!=40):\n",
    "            pred_f.append(pred[i])\n",
    "            actu_f.append(actu[i])\n",
    "    print(\"pred:\", *pred_f, sep='\\t')\n",
    "    print(\"actu:\", *actu_f, sep='\\t')\n",
    "    print(\"----------------------------------------------------------------------------------------\")\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.2.2+cu118'"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for (padded_seq, padded_seq_dec, lengths, edge_index) in train_gpu:\n",
    "    j_test += np.sum(lengths)\n",
    "    cntBatch_test += 1\n",
    "    out = ae(padded_seq, padded_seq_dec, lengths, edge_index, mode=\"recursive\")\n",
    "    print(\"pred:\", out.flatten(0).reshape(-1,N_max).argmax(dim=1).to(\"cpu\").tolist())\n",
    "    print(\"actu:\",padded_seq.flatten().to(\"cpu\").tolist())\n",
    "    print(\"----------------------------------------------------------------------------------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LSTM Only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "bidir          = True\n",
    "dir            = 2 if bidir else 1 \n",
    "num_layers_enc = 2\n",
    "hidden_dim_enc = 64\n",
    "num_layers_dec = 2\n",
    "hidden_dim_dec = 64\n",
    "emb_dim        = 64\n",
    "N_max          = len(word_to_idx)+1\n",
    "\n",
    "\n",
    "ae = AutoEncoder_rnn(batch_size     = batch_size,\n",
    "            bidir          = True,\n",
    "            num_layers_enc = num_layers_enc,\n",
    "            hidden_dim_enc = hidden_dim_enc,\n",
    "            num_layers_dec = num_layers_dec,\n",
    "            hidden_dim_dec = hidden_dim_dec,\n",
    "            emb_dim        = emb_dim,\n",
    "            N_max          = N_max)\n",
    "\n",
    "#device = torch.device(\"cpu\")\n",
    "ae.to(device)\n",
    "\n",
    "\n",
    "criterion = nn.CrossEntropyLoss(ignore_index=len(word_to_idx), weight=weight)\n",
    "#data_emb_device = [(edge_index.to(device), [bb.to(device) for bb in node_embs ]) for (edge_index, node_embs) in data_emb] \n",
    "\n",
    "optimizer = optim.Adam(ae.parameters(), lr=0.01, weight_decay=0.001)\n",
    "#optimizer = optim.Adam(ae.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For 50878 Tokens List in Train set: Epoch 1/100, Average Loss: 2.59627, Acuuracy: 7.45515\n",
      "For 16845 Tokens List in Test set: Epoch 1/100, Average Loss: 2.40912, Acuuracy: 8.98945\n",
      "-----------------------------------------------------------------------------------\n",
      "For 50878 Tokens List in Train set: Epoch 6/100, Average Loss: 1.50313, Acuuracy: 22.24330\n",
      "For 16845 Tokens List in Test set: Epoch 6/100, Average Loss: 1.58158, Acuuracy: 20.56495\n",
      "-----------------------------------------------------------------------------------\n",
      "For 50878 Tokens List in Train set: Epoch 11/100, Average Loss: 1.30184, Acuuracy: 27.20299\n",
      "For 16845 Tokens List in Test set: Epoch 11/100, Average Loss: 1.54396, Acuuracy: 21.35328\n",
      "-----------------------------------------------------------------------------------\n",
      "For 50878 Tokens List in Train set: Epoch 16/100, Average Loss: 1.33898, Acuuracy: 26.21122\n",
      "For 16845 Tokens List in Test set: Epoch 16/100, Average Loss: 1.31035, Acuuracy: 26.97261\n",
      "-----------------------------------------------------------------------------------\n",
      "For 50878 Tokens List in Train set: Epoch 21/100, Average Loss: 1.32736, Acuuracy: 26.51758\n",
      "For 16845 Tokens List in Test set: Epoch 21/100, Average Loss: 1.34810, Acuuracy: 25.97333\n",
      "-----------------------------------------------------------------------------------\n",
      "For 50878 Tokens List in Train set: Epoch 26/100, Average Loss: 1.27362, Acuuracy: 27.98179\n",
      "For 16845 Tokens List in Test set: Epoch 26/100, Average Loss: 1.68797, Acuuracy: 18.48940\n",
      "-----------------------------------------------------------------------------------\n",
      "For 50878 Tokens List in Train set: Epoch 31/100, Average Loss: 1.17801, Acuuracy: 30.78909\n",
      "For 16845 Tokens List in Test set: Epoch 31/100, Average Loss: 1.31923, Acuuracy: 26.73403\n",
      "-----------------------------------------------------------------------------------\n",
      "For 50878 Tokens List in Train set: Epoch 36/100, Average Loss: 1.17930, Acuuracy: 30.74952\n",
      "For 16845 Tokens List in Test set: Epoch 36/100, Average Loss: 1.43333, Acuuracy: 23.85123\n",
      "-----------------------------------------------------------------------------------\n",
      "For 50878 Tokens List in Train set: Epoch 41/100, Average Loss: 1.11318, Acuuracy: 32.85122\n",
      "For 16845 Tokens List in Test set: Epoch 41/100, Average Loss: 1.33000, Acuuracy: 26.44774\n",
      "-----------------------------------------------------------------------------------\n",
      "For 50878 Tokens List in Train set: Epoch 46/100, Average Loss: 1.22359, Acuuracy: 29.41736\n",
      "For 16845 Tokens List in Test set: Epoch 46/100, Average Loss: 1.21698, Acuuracy: 29.61226\n",
      "-----------------------------------------------------------------------------------\n",
      "For 50878 Tokens List in Train set: Epoch 51/100, Average Loss: 1.04649, Acuuracy: 35.11690\n",
      "For 16845 Tokens List in Test set: Epoch 51/100, Average Loss: 1.16403, Acuuracy: 31.22243\n",
      "-----------------------------------------------------------------------------------\n",
      "For 50878 Tokens List in Train set: Epoch 56/100, Average Loss: 1.03167, Acuuracy: 35.64130\n",
      "For 16845 Tokens List in Test set: Epoch 56/100, Average Loss: 1.10849, Acuuracy: 33.00573\n",
      "-----------------------------------------------------------------------------------\n",
      "For 50878 Tokens List in Train set: Epoch 61/100, Average Loss: 1.05751, Acuuracy: 34.73211\n",
      "For 16845 Tokens List in Test set: Epoch 61/100, Average Loss: 1.29655, Acuuracy: 27.34734\n",
      "-----------------------------------------------------------------------------------\n",
      "For 50878 Tokens List in Train set: Epoch 66/100, Average Loss: 1.07514, Acuuracy: 34.12506\n",
      "For 16845 Tokens List in Test set: Epoch 66/100, Average Loss: 1.22036, Acuuracy: 29.51246\n",
      "-----------------------------------------------------------------------------------\n",
      "For 50878 Tokens List in Train set: Epoch 71/100, Average Loss: 1.08670, Acuuracy: 33.73262\n",
      "For 16845 Tokens List in Test set: Epoch 71/100, Average Loss: 1.32807, Acuuracy: 26.49869\n",
      "-----------------------------------------------------------------------------------\n",
      "For 50878 Tokens List in Train set: Epoch 76/100, Average Loss: 1.00711, Acuuracy: 36.52741\n",
      "For 16845 Tokens List in Test set: Epoch 76/100, Average Loss: 1.33437, Acuuracy: 26.33241\n",
      "-----------------------------------------------------------------------------------\n",
      "For 50878 Tokens List in Train set: Epoch 81/100, Average Loss: 1.17153, Acuuracy: 30.98924\n",
      "For 16845 Tokens List in Test set: Epoch 81/100, Average Loss: 1.14606, Acuuracy: 31.78878\n",
      "-----------------------------------------------------------------------------------\n",
      "For 50878 Tokens List in Train set: Epoch 86/100, Average Loss: 0.93979, Acuuracy: 39.07090\n",
      "For 16845 Tokens List in Test set: Epoch 86/100, Average Loss: 1.08931, Acuuracy: 33.64500\n",
      "-----------------------------------------------------------------------------------\n",
      "For 50878 Tokens List in Train set: Epoch 91/100, Average Loss: 1.08008, Acuuracy: 33.95674\n",
      "For 16845 Tokens List in Test set: Epoch 91/100, Average Loss: 1.84329, Acuuracy: 15.82950\n",
      "-----------------------------------------------------------------------------------\n",
      "For 50878 Tokens List in Train set: Epoch 96/100, Average Loss: 0.95179, Acuuracy: 38.60489\n",
      "For 16845 Tokens List in Test set: Epoch 96/100, Average Loss: 1.11697, Acuuracy: 32.72685\n",
      "-----------------------------------------------------------------------------------\n",
      "For 50878 Tokens List in Train set: Epoch 100/100, Average Loss: 1.06916, Acuuracy: 34.32981\n",
      "For 16845 Tokens List in Test set: Epoch 100/100, Average Loss: 1.16991, Acuuracy: 31.03934\n",
      "-----------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "epoch_num = 100\n",
    "loss_train = []\n",
    "accu_train = []\n",
    "loss_test = []\n",
    "accu_test = []\n",
    "for epoch in range(epoch_num):\n",
    "    total_loss = 0\n",
    "    j = 0\n",
    "    cntBatch = 0\n",
    "    for (padded_seq, padded_seq_dec, lengths, edge_index) in train_gpu:\n",
    "        cntBatch += 1\n",
    "        #print(\"seq ->\", padded_seq.shape)\n",
    "        #print(\"lengths -> \", min(lengths), \":\", max(lengths))\n",
    "        out = ae(padded_seq, padded_seq_dec, lengths, edge_index, mode=\"teaching\", ratio=0.25, ratio_mix=0.8)\n",
    "        #print(out[:,-1,:])\n",
    "        loss = criterion(out.flatten(0).reshape(-1,N_max), padded_seq.flatten())\n",
    "        #print(out.flatten(0).reshape(-1,N_max).argmax(dim=1).to(\"cpu\").tolist())\n",
    "        #print(padded_seq.flatten().to(\"cpu\").tolist())\n",
    "        #print(\"-------------------------------------------------\")\n",
    "        total_loss  += loss.item()\n",
    "        j += np.sum(lengths)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    if epoch%5==0 or (epoch+1)==epoch_num:\n",
    "        print(f'For {j} Tokens List in Train set: Epoch {epoch+1}/{epoch_num}, Average Loss: {total_loss/cntBatch:.5f}, Acuuracy: {np.exp(-total_loss/cntBatch)*100:.5f}', end='\\n')\n",
    "        cntBatch_test = 0\n",
    "        total_loss_test = 0\n",
    "        j_test = 0\n",
    "        for (padded_seq, padded_seq_dec, lengths, edge_index) in test_gpu:\n",
    "            j_test += np.sum(lengths)\n",
    "            cntBatch_test += 1\n",
    "            out = ae(padded_seq, padded_seq_dec, lengths, edge_index, mode=\"recursive\", ratio=1)\n",
    "            loss = criterion(out.flatten(0).reshape(-1,N_max), padded_seq.flatten())\n",
    "            total_loss_test  += loss.item()\n",
    "        loss_test.append(total_loss_test/cntBatch_test)\n",
    "        accu_test.append(np.exp(-total_loss_test/cntBatch_test)*100)\n",
    "        print(f'For {j_test} Tokens List in Test set: Epoch {epoch+1}/{epoch_num}, Average Loss: {total_loss_test/cntBatch_test:.5f}, Acuuracy: {np.exp(-total_loss_test/cntBatch_test)*100:.5f}', end='\\n')\n",
    "        print(\"-----------------------------------------------------------------------------------\")\n",
    "    else:\n",
    "        print(f'For {j} Tokens List in Train set: Epoch {epoch+1}/{epoch_num}, Average Loss: {total_loss/cntBatch:.5f}, Acuuracy: {np.exp(-total_loss/cntBatch)*100:.5f}', end='\\r')\n",
    "    loss_train.append(total_loss/cntBatch)\n",
    "    accu_train.append(np.exp(-total_loss/cntBatch)*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GAT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "bidir          = False\n",
    "dir            = 2 if bidir else 1 \n",
    "num_layers_enc = 2\n",
    "hidden_dim_enc = 64\n",
    "num_layers_dec = 2\n",
    "hidden_dim_dec = 64\n",
    "num_layers_gnn = 16\n",
    "emb_dim        = 8\n",
    "N_max          = len(word_to_idx)+1\n",
    "\n",
    "\n",
    "ae = AutoEncoder_gnngatrnn(batch_size     = batch_size,\n",
    "            bidir          = True,\n",
    "            num_layers_enc = num_layers_enc,\n",
    "            hidden_dim_enc = hidden_dim_enc,\n",
    "            num_layers_dec = num_layers_dec,\n",
    "            hidden_dim_dec = hidden_dim_dec,\n",
    "            num_layers_gnn = num_layers_gnn,\n",
    "            emb_dim        = emb_dim,\n",
    "            N_max          = N_max)\n",
    "\n",
    "#device = torch.device(\"cpu\")\n",
    "ae.to(device)\n",
    "\n",
    "\n",
    "criterion = nn.CrossEntropyLoss(ignore_index=len(word_to_idx), weight=weight)\n",
    "#data_emb_device = [(edge_index.to(device), [bb.to(device) for bb in node_embs ]) for (edge_index, node_embs) in data_emb] \n",
    "\n",
    "#optimizer = optim.Adam(ae.parameters(), lr=0.01, weight_decay=0.001)\n",
    "optimizer = optim.Adam(ae.parameters(), lr=0.01)\n",
    "optimizer = optim.AdamW(ae.parameters(), lr=0.001, weight_decay=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For 1043216 Tokens List in Train set: Epoch 1/100, Average Loss: 3.51706, Acuuracy: 2.96865\n",
      "For 261758 Tokens List in Test set: Epoch 1/100, Average Loss: 3.26159, Acuuracy: 3.83275\n",
      "-----------------------------------------------------------------------------------\n",
      "For 1043216 Tokens List in Train set: Epoch 6/100, Average Loss: 2.16485, Acuuracy: 11.47673\n",
      "For 261758 Tokens List in Test set: Epoch 6/100, Average Loss: 2.36327, Acuuracy: 9.41120\n",
      "-----------------------------------------------------------------------------------\n",
      "For 1043216 Tokens List in Train set: Epoch 7/100, Average Loss: 2.03243, Acuuracy: 13.10167\r"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [35], line 23\u001b[0m\n\u001b[1;32m     21\u001b[0m     j \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39msum(lengths)\n\u001b[1;32m     22\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m---> 23\u001b[0m     \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     24\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m     25\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m epoch\u001b[38;5;241m%\u001b[39m\u001b[38;5;241m5\u001b[39m\u001b[38;5;241m==\u001b[39m\u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m (epoch\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m==\u001b[39mepoch_num:\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/_tensor.py:522\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    512\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    513\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    514\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    515\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    520\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    521\u001b[0m     )\n\u001b[0;32m--> 522\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    523\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    524\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/autograd/__init__.py:266\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    261\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    263\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[1;32m    264\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    265\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 266\u001b[0m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    267\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    268\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    269\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    270\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    271\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    272\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    273\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    274\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "epoch_num = 100\n",
    "loss_train = []\n",
    "accu_train = []\n",
    "loss_test = []\n",
    "accu_test = []\n",
    "for epoch in range(epoch_num):\n",
    "    total_loss = 0\n",
    "    j = 0\n",
    "    cntBatch = 0\n",
    "    for (padded_seq, padded_seq_dec, lengths, edge_index) in train_gpu:\n",
    "        cntBatch += 1\n",
    "        #print(\"seq ->\", padded_seq.shape)\n",
    "        #print(\"lengths -> \", min(lengths), \":\", max(lengths))\n",
    "        out = ae(padded_seq, padded_seq_dec, lengths, edge_index, mode=\"teaching\", ratio=0.25, ratio_mix=0.8)\n",
    "        #print(out[:,-1,:])\n",
    "        loss = criterion(out.flatten(0).reshape(-1,N_max), padded_seq.flatten())\n",
    "        #print(out.flatten(0).reshape(-1,N_max).argmax(dim=1).to(\"cpu\").tolist())\n",
    "        #print(padded_seq.flatten().to(\"cpu\").tolist())\n",
    "        #print(\"-------------------------------------------------\")\n",
    "        total_loss  += loss.item()\n",
    "        j += np.sum(lengths)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    if epoch%5==0 or (epoch+1)==epoch_num:\n",
    "        print(f'For {j} Tokens List in Train set: Epoch {epoch+1}/{epoch_num}, Average Loss: {total_loss/cntBatch:.5f}, Acuuracy: {np.exp(-total_loss/cntBatch)*100:.5f}', end='\\n')\n",
    "        cntBatch_test = 0\n",
    "        total_loss_test = 0\n",
    "        j_test = 0\n",
    "        for (padded_seq, padded_seq_dec, lengths, edge_index) in test_gpu:\n",
    "            j_test += np.sum(lengths)\n",
    "            cntBatch_test += 1\n",
    "            out = ae(padded_seq, padded_seq_dec, lengths, edge_index, mode=\"recursive\", ratio=1)\n",
    "            loss = criterion(out.flatten(0).reshape(-1,N_max), padded_seq.flatten())\n",
    "            total_loss_test  += loss.item()\n",
    "        loss_test.append(total_loss_test/cntBatch_test)\n",
    "        accu_test.append(np.exp(-total_loss_test/cntBatch_test)*100)\n",
    "        print(f'For {j_test} Tokens List in Test set: Epoch {epoch+1}/{epoch_num}, Average Loss: {total_loss_test/cntBatch_test:.5f}, Acuuracy: {np.exp(-total_loss_test/cntBatch_test)*100:.5f}', end='\\n')\n",
    "        print(\"-----------------------------------------------------------------------------------\")\n",
    "    else:\n",
    "        print(f'For {j} Tokens List in Train set: Epoch {epoch+1}/{epoch_num}, Average Loss: {total_loss/cntBatch:.5f}, Acuuracy: {np.exp(-total_loss/cntBatch)*100:.5f}', end='\\r')\n",
    "    loss_train.append(total_loss/cntBatch)\n",
    "    accu_train.append(np.exp(-total_loss/cntBatch)*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Are you sure? yes/no\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "yes\n"
     ]
    },
    {
     "ename": "PicklingError",
     "evalue": "Can't pickle <class 'model.AutoEncoder_gnngatrnn'>: it's not the same object as model.AutoEncoder_gnngatrnn",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mPicklingError\u001b[0m                             Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [27], line 5\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124myes\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      4\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mae_gat.pickle\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwb\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[0;32m----> 5\u001b[0m         \u001b[43mpickle\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdump\u001b[49m\u001b[43m(\u001b[49m\u001b[43mae\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mf\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m      7\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mno\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mPicklingError\u001b[0m: Can't pickle <class 'model.AutoEncoder_gnngatrnn'>: it's not the same object as model.AutoEncoder_gnngatrnn"
     ]
    }
   ],
   "source": [
    "print(\"Are you sure? yes/no\")\n",
    "if input()=='yes':\n",
    "    print('yes')\n",
    "    with open('ae_gat.pickle', 'wb') as f:\n",
    "        pickle.dump(ae, f)\n",
    "else:\n",
    "    print('no')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_cnt = -1\n",
    "for (padded_seq, padded_seq_dec, lengths, edge_index) in test_gpu:\n",
    "        batch_cnt+=1\n",
    "        out, (edge_index_gat, alpha_gat) = ae(padded_seq, padded_seq_dec, lengths, edge_index, mode=\"recursive\", ratio=0.25, ratio_mix=0.8, return_attention_weights=True)\n",
    "        save_edge_attr_graph(edge_index_gat, alpha_gat, batch_cnt)\n",
    "        if batch_cnt>1:\n",
    "                break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'save_graph' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [16], line 9\u001b[0m\n\u001b[1;32m      7\u001b[0m edge_attrs \u001b[38;5;241m=\u001b[39m [\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m4\u001b[39m]  \u001b[38;5;66;03m# Just random attributes for demonstration\u001b[39;00m\n\u001b[1;32m      8\u001b[0m filename \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEdge_alpha/edge.png\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m----> 9\u001b[0m \u001b[43msave_graph\u001b[49m(edge_index, edge_attrs, filename)\n\u001b[1;32m     10\u001b[0m \u001b[38;5;66;03m# Create a graph\u001b[39;00m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msave_graph\u001b[39m(edge_index, edge_attrs, filename):\n",
      "\u001b[0;31mNameError\u001b[0m: name 'save_graph' is not defined"
     ]
    }
   ],
   "source": [
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Example edge index\n",
    "edge_index = [(0, 1), (1, 2), (2, 3), (3, 0)]\n",
    "# Example edge attributes\n",
    "edge_attrs = [1, 2, 3, 4]  # Just random attributes for demonstration\n",
    "filename = 'Edge_alpha/edge.png'\n",
    "save_graph(edge_index, edge_attrs, filename)\n",
    "# Create a graph\n",
    "def save_graph(edge_index, edge_attrs, filename):\n",
    "    G = nx.Graph()\n",
    "\n",
    "    # Add edges with attributes\n",
    "    for i, (src, dst) in enumerate(edge_index):\n",
    "        G.add_edge(src, dst, weight=edge_attrs[i])\n",
    "\n",
    "    # Visualization\n",
    "    pos = nx.spring_layout(G)  # Layout for visualization\n",
    "    nx.draw(G, pos, with_labels=True, node_color='skyblue', node_size=1500, font_size=10, font_weight='bold')\n",
    "\n",
    "    # Adding edge labels\n",
    "    labels = nx.get_edge_attributes(G, 'weight')\n",
    "    nx.draw_networkx_edge_labels(G, pos, edge_labels=labels)\n",
    "\n",
    "    plt.savefig()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{0, 1, 2, 3}, {4, 5, 6}]\n",
      "[[(0, 1), (1, 2), (2, 3)], [(4, 5), (5, 6)]]\n"
     ]
    }
   ],
   "source": [
    "import networkx as nx\n",
    "\n",
    "def get_disconnected_subgraphs(edge_index):\n",
    "    # Create a graph from the edge index\n",
    "    G = nx.Graph()\n",
    "    G.add_edges_from(edge_index)\n",
    "\n",
    "    # Get the disconnected subgraphs\n",
    "    disconnected_subgraphs = list(nx.connected_components(G))\n",
    "    print(disconnected_subgraphs)\n",
    "\n",
    "    # Convert each subgraph to edge indices\n",
    "    disconnected_edge_indices = []\n",
    "    for subgraph_nodes in disconnected_subgraphs:\n",
    "        subgraph = G.subgraph(subgraph_nodes)\n",
    "        subgraph_edge_index = list(subgraph.edges())\n",
    "        disconnected_edge_indices.append(subgraph_edge_index)\n",
    "\n",
    "    return disconnected_edge_indices\n",
    "\n",
    "# Example usage:\n",
    "edge_index = [(0, 1), (1, 2), (2, 3), (4, 5), (5, 6)]\n",
    "disconnected_subgraphs = get_disconnected_subgraphs(edge_index)\n",
    "print(disconnected_subgraphs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Linear.forward() missing 1 required positional argument: 'x'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [81], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mae\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgnn1\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlin_src\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[0;31mTypeError\u001b[0m: Linear.forward() missing 1 required positional argument: 'x'"
     ]
    }
   ],
   "source": [
    "with torch.no_Grad():\n",
    "    model(x)\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gnn2.att_src\n",
      "torch.Size([1, 1, 256])\n",
      "min tensor(-0.8647, device='cuda:0', grad_fn=<MinBackward1>)\n",
      "max tensor(0.9604, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "Parameter containing:\n",
      "tensor([[[ 0.0380, -0.6224, -0.3401, -0.0409,  0.2148, -0.0699, -0.0282,\n",
      "          -0.2588, -0.3933, -0.2451, -0.0504, -0.1446,  0.5270, -0.1163,\n",
      "           0.3794,  0.4475, -0.1785,  0.0813,  0.8437,  0.6428, -0.4473,\n",
      "           0.4335,  0.7778, -0.1382, -0.0149, -0.0450, -0.1412,  0.2145,\n",
      "          -0.2329,  0.2704,  0.4642,  0.3545, -0.3245, -0.5189,  0.2327,\n",
      "           0.0099,  0.1821,  0.1375,  0.4034,  0.0968,  0.1682,  0.4240,\n",
      "           0.0655, -0.0078, -0.0556,  0.3160,  0.3039, -0.2118,  0.4743,\n",
      "           0.1550,  0.2273,  0.4690, -0.1279,  0.5365, -0.0078, -0.1361,\n",
      "           0.4644,  0.5937,  0.0484,  0.2602,  0.5636, -0.1079, -0.0307,\n",
      "           0.2517, -0.1038, -0.3210, -0.2267, -0.4912,  0.1787,  0.7502,\n",
      "          -0.2820,  0.0038, -0.2124, -0.0328,  0.2463,  0.0312,  0.3132,\n",
      "           0.1073,  0.4648,  0.7873,  0.1821, -0.4048,  0.3654,  0.3821,\n",
      "           0.1663, -0.0176, -0.0115,  0.0678,  0.5668,  0.7072,  0.2448,\n",
      "          -0.2576, -0.5003,  0.3498, -0.3679, -0.2850,  0.6707,  0.3351,\n",
      "           0.3010, -0.1076,  0.1210,  0.0352,  0.1758,  0.3056, -0.3484,\n",
      "          -0.0356,  0.1992, -0.0778, -0.7877, -0.1422, -0.1725,  0.2135,\n",
      "           0.3328, -0.0591,  0.2177, -0.0206, -0.1257,  0.5814,  0.4152,\n",
      "           0.2343, -0.0245,  0.1536, -0.0687, -0.3354,  0.3358, -0.1461,\n",
      "           0.4834,  0.2275,  0.1783,  0.0771, -0.2709,  0.4596,  0.1405,\n",
      "          -0.3263,  0.2236,  0.0754,  0.4021, -0.0617,  0.2657, -0.3549,\n",
      "          -0.2061,  0.3671,  0.0876,  0.1242, -0.8647, -0.2637, -0.1249,\n",
      "           0.2723,  0.0259,  0.2518,  0.4709,  0.4777,  0.4850, -0.0865,\n",
      "          -0.2591,  0.5694,  0.3520,  0.1883,  0.5369,  0.0942, -0.0615,\n",
      "           0.3412, -0.2278, -0.0169,  0.0371,  0.6089, -0.1805, -0.4520,\n",
      "          -0.1762,  0.0501,  0.2580,  0.0152,  0.0534,  0.1815, -0.4971,\n",
      "           0.5096,  0.9604, -0.2343,  0.1224, -0.1727,  0.1759,  0.3292,\n",
      "          -0.0818,  0.2597,  0.1895, -0.1814, -0.4056, -0.0387,  0.1443,\n",
      "          -0.0462, -0.2705,  0.0280, -0.1814,  0.0228,  0.1654,  0.4847,\n",
      "           0.1578, -0.1701, -0.3038, -0.0229, -0.2601, -0.1037, -0.2546,\n",
      "          -0.0870, -0.0970,  0.2402,  0.0412, -0.4798, -0.0091,  0.0943,\n",
      "           0.7214,  0.2190,  0.5725, -0.1960,  0.2803,  0.2222, -0.2309,\n",
      "           0.1330, -0.1519,  0.0436, -0.2660, -0.0018,  0.6881,  0.2469,\n",
      "          -0.1869,  0.0415, -0.2802,  0.0076,  0.2084,  0.2518,  0.7474,\n",
      "           0.1254,  0.1019, -0.2850,  0.3123, -0.3929,  0.0739,  0.0284,\n",
      "          -0.6069,  0.1817,  0.0375,  0.3732, -0.0424,  0.5786,  0.2724,\n",
      "          -0.0527,  0.0958, -0.3956,  0.0096, -0.1456, -0.1794, -0.0501,\n",
      "           0.1771,  0.1360,  0.3347,  0.0611]]], device='cuda:0',\n",
      "       requires_grad=True)\n",
      "-------------------------------\n",
      "gnn2.att_dst\n",
      "torch.Size([1, 1, 256])\n",
      "min tensor(-0.3957, device='cuda:0', grad_fn=<MinBackward1>)\n",
      "max tensor(0.4488, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "Parameter containing:\n",
      "tensor([[[-1.0451e-01, -8.3119e-02,  3.5770e-02, -2.7237e-02, -1.5807e-01,\n",
      "          -8.9284e-02, -5.5120e-03,  3.4311e-03,  1.3226e-01,  6.7270e-03,\n",
      "          -6.5963e-03, -2.0518e-01,  1.7441e-01, -1.0636e-01, -9.1496e-03,\n",
      "           5.3779e-03,  1.8858e-01,  1.9100e-01,  1.6067e-02, -1.1468e-01,\n",
      "           9.2235e-02,  1.5011e-02,  1.0520e-01, -5.5557e-02,  1.6708e-01,\n",
      "           1.9844e-01,  2.7410e-03, -1.2876e-01, -2.6239e-02, -7.6746e-02,\n",
      "           1.2654e-01,  1.3779e-01,  1.0263e-01, -9.0749e-02,  6.3958e-02,\n",
      "          -5.7973e-02,  1.1109e-01,  4.0111e-02,  1.1271e-01, -2.1836e-01,\n",
      "           3.0072e-01, -1.0564e-01, -1.4611e-02,  3.1259e-01, -7.1175e-02,\n",
      "          -1.0754e-01,  9.7434e-02, -9.9146e-02, -7.3989e-02,  1.3413e-01,\n",
      "          -1.0154e-01, -4.9658e-02, -7.3744e-02, -9.3008e-02, -1.0494e-01,\n",
      "          -2.5076e-01,  8.4109e-02, -8.7021e-02,  2.2489e-03,  8.9757e-02,\n",
      "          -1.6531e-02, -9.2375e-02, -6.3078e-02,  1.2290e-01,  9.4819e-02,\n",
      "          -2.3238e-03,  1.0580e-01, -3.9574e-01,  8.8864e-02,  2.2852e-01,\n",
      "          -1.2428e-01, -1.0166e-01, -1.0430e-01,  1.5243e-01,  1.6455e-01,\n",
      "          -1.1197e-01,  1.1789e-01,  1.1024e-01,  8.1991e-02, -1.1987e-01,\n",
      "          -8.4690e-02,  3.8888e-02,  1.3027e-01,  5.0750e-02,  1.0160e-01,\n",
      "          -7.2760e-02, -1.2284e-01, -1.8988e-02,  9.3874e-03, -6.9348e-02,\n",
      "           1.5875e-03, -9.4792e-02,  1.8885e-02, -5.5385e-02,  2.0392e-02,\n",
      "          -8.7718e-02, -4.4186e-02,  1.5790e-01,  2.0222e-01,  6.7156e-02,\n",
      "           7.5005e-02, -2.2769e-02, -4.4146e-02,  3.6895e-02, -1.7978e-01,\n",
      "          -7.0849e-04,  2.5674e-02,  4.8260e-02, -6.7969e-02,  4.2782e-02,\n",
      "          -1.0578e-01,  1.1881e-01,  1.7884e-01,  7.4570e-02,  1.2531e-01,\n",
      "           6.2677e-02,  1.3694e-01, -9.2158e-02,  9.1363e-03, -3.0036e-02,\n",
      "           1.1837e-01, -4.4033e-02, -4.0058e-02,  2.5737e-02,  1.7244e-01,\n",
      "          -8.7741e-02, -6.6654e-02,  1.8010e-01,  4.0398e-02,  7.7564e-03,\n",
      "          -1.2316e-01,  1.6497e-01,  9.9514e-03, -1.5524e-01,  7.9172e-02,\n",
      "           2.0391e-02,  1.0852e-01, -1.4470e-01, -6.5877e-02,  3.4635e-02,\n",
      "           1.3533e-01,  1.0432e-02,  1.0795e-02, -6.3572e-02,  9.4969e-02,\n",
      "           4.4931e-02,  1.5658e-01,  5.1712e-02, -7.2767e-03,  5.2678e-02,\n",
      "          -1.1911e-02,  1.5825e-01, -5.3938e-02,  8.6482e-02, -2.7022e-01,\n",
      "          -3.7664e-02,  4.8131e-02,  1.3621e-01, -9.1729e-02,  1.3161e-01,\n",
      "          -1.2610e-01, -1.5494e-01, -2.4774e-04,  1.1025e-01,  1.3105e-01,\n",
      "           1.1326e-01,  2.0001e-03,  1.8457e-02, -2.3416e-01, -5.4342e-02,\n",
      "           4.4881e-01, -1.3855e-01,  2.6007e-02,  7.4408e-04, -1.9361e-01,\n",
      "          -4.7937e-02,  1.6865e-02,  5.9796e-02, -3.9588e-02,  6.7734e-02,\n",
      "          -1.3429e-01, -3.0722e-01, -1.5703e-01, -2.2977e-02,  8.1064e-02,\n",
      "           7.6454e-02,  1.2149e-01, -1.0600e-01, -5.5853e-02,  1.4244e-01,\n",
      "           1.1376e-01, -2.4624e-01,  1.5663e-01,  6.4808e-02,  3.1600e-02,\n",
      "           1.3925e-01,  1.1551e-01, -2.4043e-01, -1.3511e-02,  5.9046e-02,\n",
      "           3.2263e-01, -1.3926e-01,  1.6603e-01, -7.2278e-02, -1.4789e-01,\n",
      "          -1.5902e-02,  5.5283e-02, -2.0971e-01,  4.7318e-02,  6.9566e-02,\n",
      "           1.8737e-02,  5.9516e-02,  1.1858e-01,  7.7732e-02, -4.3642e-02,\n",
      "           3.1305e-02,  1.2454e-01, -1.2816e-01, -7.8896e-02,  6.1299e-03,\n",
      "           5.6466e-02, -5.7557e-02, -5.5338e-02,  7.9494e-02, -9.3320e-02,\n",
      "           8.8310e-02, -4.9471e-02,  1.0967e-01,  9.8856e-02, -1.0253e-01,\n",
      "          -3.5700e-02,  8.3236e-02,  2.3487e-02, -2.4920e-01,  1.8000e-01,\n",
      "           3.1580e-02, -2.4906e-02, -1.4036e-01, -1.2466e-01,  8.8702e-02,\n",
      "           2.5723e-02,  3.3970e-01,  2.6701e-03,  2.6201e-02, -7.2902e-02,\n",
      "           1.4955e-01, -1.4336e-01, -5.2213e-02,  6.9649e-02,  2.3738e-02,\n",
      "          -3.5640e-02, -1.1383e-01, -8.8380e-02, -4.3568e-02,  1.3675e-01,\n",
      "           1.4014e-01]]], device='cuda:0', requires_grad=True)\n",
      "-------------------------------\n",
      "gnn2.bias\n",
      "torch.Size([256])\n",
      "min tensor(-1.2314, device='cuda:0', grad_fn=<MinBackward1>)\n",
      "max tensor(1.4139, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "Parameter containing:\n",
      "tensor([-0.7778,  0.2392,  0.7186, -0.6004, -0.7979, -0.2242, -0.1187, -0.3109,\n",
      "         0.3500, -0.0089, -0.6139,  0.1013, -0.4660,  0.9550, -0.0808, -0.2692,\n",
      "        -0.3242, -0.4898, -0.1550, -0.4507,  0.5509, -0.2413, -0.7139,  0.1134,\n",
      "         0.4699, -0.0298,  0.9820, -0.1417,  0.3229, -0.1469, -0.3393, -0.0618,\n",
      "         0.1054,  0.1240,  0.4474, -0.1486,  0.1511, -0.2787, -0.1326, -0.7616,\n",
      "        -0.2229, -0.3986,  0.2708, -0.1814, -0.2724, -0.2633, -0.1725,  1.0717,\n",
      "        -0.5806,  0.4409,  0.1818, -0.2502, -0.7776, -0.6255,  0.1828,  0.2854,\n",
      "        -0.8731, -0.3938, -1.0584, -0.2820, -0.1749,  0.3279,  0.7746, -0.4145,\n",
      "        -1.2314,  0.6595, -0.3354,  0.4909, -0.8275, -0.2763,  0.5403,  0.9420,\n",
      "         0.1524, -0.8811,  0.2440, -0.3275, -0.3009, -0.8537, -0.3932, -0.4536,\n",
      "        -0.6386,  0.0360, -0.5539, -0.2146,  0.8108,  1.4139,  0.3978, -0.3530,\n",
      "        -0.2158, -0.3040, -0.3765,  0.2949,  0.1465, -0.0662,  0.4868,  0.1938,\n",
      "        -0.2676, -0.5366, -0.0061, -0.6704, -0.1050,  0.4878,  0.3234, -0.0634,\n",
      "         0.6845, -0.5030, -0.4961, -0.3247,  0.4894, -0.2808,  1.2994,  0.2624,\n",
      "        -0.0899,  0.8342,  0.3783, -0.5370,  0.9139, -0.6486, -0.4041, -0.8297,\n",
      "         0.3677, -0.7039, -0.2926, -0.3331, -0.6895,  0.1298, -0.4820, -0.6665,\n",
      "        -0.2704, -0.5143, -0.4877, -0.7643,  0.1201,  0.3955, -0.3488, -0.3786,\n",
      "         0.0758,  0.0805, -0.9285,  0.3702,  0.4762, -0.5791,  0.3065,  0.3145,\n",
      "         0.3591, -0.1511,  1.0636, -0.4947, -0.5252,  0.8751, -0.3061, -0.4383,\n",
      "        -0.9256,  0.5883,  0.3412, -0.9211, -0.9799, -0.8937, -0.4852, -0.0083,\n",
      "         0.3076, -0.1909,  0.0619, -0.1185, -0.6309, -0.2479, -0.0271,  1.0386,\n",
      "         0.4841, -0.1963, -0.1957,  0.2881, -0.1871, -0.1412,  0.2975, -0.6263,\n",
      "        -0.3841, -0.2975, -0.2238,  0.7191, -0.3405, -0.2618,  0.4840, -0.4436,\n",
      "        -0.5095, -0.1815, -0.1161, -0.1508,  0.4332,  0.1311,  1.1291,  0.7438,\n",
      "         0.1765,  0.5583,  0.4478, -0.9991,  0.6307, -0.0946,  0.2406, -0.1532,\n",
      "        -0.5375, -0.1486, -0.0924,  0.0667,  0.4213, -0.1035, -0.4953,  0.0675,\n",
      "         0.5672, -0.1224, -1.0545,  0.1771, -0.4486,  0.3129, -0.5146,  0.9200,\n",
      "         0.0184,  0.6752,  0.1918, -0.4441,  0.3853,  0.7645,  0.0068,  0.3184,\n",
      "         1.1313,  0.2592, -0.2301,  0.1563,  0.5164, -0.4780,  0.0051,  0.1821,\n",
      "        -0.2496,  0.4031, -0.7341,  0.0103, -0.0970,  0.6363,  0.5428,  0.3814,\n",
      "         0.9299, -0.1164,  0.3708, -0.1746, -0.7169, -0.4128, -0.2160,  0.1437,\n",
      "        -0.4544,  0.4445, -0.2333, -0.8958, -0.4090,  0.9523,  0.0861,  0.1879],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "-------------------------------\n",
      "gnn2.lin_src.weight\n",
      "torch.Size([256, 256])\n",
      "min tensor(-1.8532, device='cuda:0', grad_fn=<MinBackward1>)\n",
      "max tensor(1.8898, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "Parameter containing:\n",
      "tensor([[-0.2477,  0.6754,  0.1747,  ...,  0.5596,  0.0220, -0.3586],\n",
      "        [-0.4712,  0.3276,  0.7241,  ..., -0.5918,  0.3650,  0.1456],\n",
      "        [ 0.2626,  0.0605,  0.1345,  ..., -0.7603,  0.3173,  0.9136],\n",
      "        ...,\n",
      "        [ 0.1544, -0.1960, -0.3508,  ..., -0.1209, -0.3751,  0.5109],\n",
      "        [-0.3282, -0.2092, -0.0495,  ...,  0.4823,  0.2848,  0.1216],\n",
      "        [-1.0946, -0.3162,  1.0536,  ..., -0.2608,  0.1581,  0.2408]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "-------------------------------\n"
     ]
    }
   ],
   "source": [
    "for name, param in ae.named_parameters():\n",
    "    if 'gnn2' in name:\n",
    "        print(name)\n",
    "        print(param.shape)\n",
    "        print(\"min\", param.min())\n",
    "        print(\"max\", param.max())\n",
    "        print(param)\n",
    "        print(\"-------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.nn import GATConv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = GATConv(in_channels=3, out_channels=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "in_channels=3\n",
    "isinstance(in_channels, int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/reza/.local/lib/python3.10/site-packages/torch_geometric/nn/conv/gat_conv.py'"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import inspect\n",
    "inspect.getfile(GATConv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
